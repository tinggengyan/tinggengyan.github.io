[{"categories":null,"content":"今日所学 ","date":"2023-06-24","objectID":"/daily_notes/2023-06-24/:1:0","tags":null,"title":"2023-06-24","uri":"/daily_notes/2023-06-24/"},{"categories":null,"content":"今日学思 ","date":"2023-06-24","objectID":"/daily_notes/2023-06-24/:2:0","tags":null,"title":"2023-06-24","uri":"/daily_notes/2023-06-24/"},{"categories":null,"content":"今日发现 ","date":"2023-06-24","objectID":"/daily_notes/2023-06-24/:3:0","tags":null,"title":"2023-06-24","uri":"/daily_notes/2023-06-24/"},{"categories":["OS"],"content":"概述 总结自己的操作系统的知识，按照编码 -\u003e 运行，画了一张图，xmind 导出的图比较大，目前这部分的内容还比较少，后续持续更新，迭代这部分的内容。 下面是一些常见的知识,将会慢慢补充进思维导图内 linux 整体结构图 makelinux：makelinux 解释器 \u0026 编译器 \u0026 JIT \u0026 AOT 参考链接1 参考链接2 JIT(Just In Time)和 AOT(Ahead Of Time)是两种不同的编译方式: JIT: 编译时,将源代码编译成字节码(bytecode),运行时再将字节码编译成机器码。 优点是运行时可以进行更多优化,生成更高质量的机器码。 缺点是编译时需要额外的编译步骤,会增加程序启动时间。 第一次运行时编译时间较长,后续运行时间短。运行时性能较AOT略差。 AOT: 编译时,将源代码直接编译成机器码。 优点是编译只有一次,程序启动更快。 编译器在程序运行前完成编译,生成机器代码。运行时直接执行机器代码。 编译时间较长,运行时性能好。 改动源代码需要重新编译。 缺点是编译时难以进行复杂的优化,生成的机器码质量可能较低。 典型的AOT编译语言有C、C++等。 总结: JIT 的运行性能更高,但启动时间长。适合长时间运行的程序。 AOT 的启动时间短,但运行性能可能略低。适合启动频繁的程序。 在实际使用中,也可以二者结合,采用 AOT 先编译成机器码,再运行时由 JIT 进一步优化,以兼顾启动时间和运行性能。许多语言(如 Java、C#)的编译器都支持这两种模式。 ![[Pasted image 20230407143623.png]] 解释器：Java源程序编译成字节码，然后由运行环境对字节码解释执行，提供解释功能的 JVM 组件为解释器。它能执行 JVM 规范的字节码，执行方式是一遍翻译一遍执行，所以效率低，但是简单并易于实现。主要实现是在 Interpreter 模块。 ![[Pasted image 20230407143647.png]] 即时编译器：能够将运行时的热点代码，编译成运行效率高的及时代码。 判断一段代码是不是热点代码，是不是需要触发JIT编译，这样的行为称为：热点探测（Hot Spot Detection），有几种主流的探测方式： 基于计数器的热点探测（Counter Based Hot Spot Detection）：虚拟机会为每个方法（或每个代码块）建立计数器，统计执行次数，如果超过阀值那么就是热点代码。缺点是维护计数器开销。 基于采样的热点探测（Sample Based Hot Spot Detection）：虚拟机会周期性检查各个线程的栈顶，如果某个方法经常出现在栈顶，那么就是热点代码。缺点是不精确。 基于踪迹的热点探测（Trace Based Hot Spot Detection）：Dalvik中的JIT编译器使用这种方式 JIT 是可以回退到解释器执行的 inlining 内联(最关键的优化手段) inlining 指在编译时，识别 call site (持有 method handle 的对象) 的目标方法，将其方法体 加入当前方法的编译范围，并将其结果替换掉原 call site，比如 getter 和 setter 就会优化为一条访问内存的指令。 通过谨慎地使用 AOT 编译代码加快应用程序启动，因为虽然这种代码通常比 JIT 编译代码慢，但是却比解释代码快很多倍。此外，因为加载和绑定AOT 编译代码的时间通常比检测和动态编译一个重要方法的时间少，所以能够在程序执行的早期达到那样的性能。类似地，交互式应用程序可以很快地从本地代码中获益，无需使用引起较差响应能力的动态编译。 AOT的核心原理是:编译时将源代码编译成机器代码,然后在运行时直接执行机器代码。具体来说,主要分为以下几个步骤: 编译:这个过程通常较慢,开发者编写的源代码会被编译器编译成机器代码,并链接成完整的可执行文件。 运行:此时运行可执行文件,直接执行机器代码,不需要额外的编译步骤,所以运行速度很快。 优化:编译器可以充分利用编译期的时间来对机器代码进行优化,如删除冗余代码、循环展开等,这也是AOT性能好的原因之一。 缓存:由于机器代码是预先编译好的,所以编译的中间结果(如AST)可以被缓存下来重复使用,这也提高了性能。 静态分析:编译器可以在编译期对源代码进行静态分析,发现潜在的bug或安全隐患,这是AOT的另一大优势。 所以AOT的关键就是将程序的编译过程前置到运行之前,生成机器代码,这样运行时只需要简单执行机器代码即可,省去编译的开销,这也是AOT能达到运行性能较高的原因。 但也因此,AOT语言在开发调试阶段的体验稍差,因为每次修改源代码都需要重新编译。 总体来说,AOT通过提前编译,牺牲部分编译的开销和开发体验,换取运行期的高性能表现。这也使其非常适合在生产环境部署。 JIT的核心原理是:编译器在程序运行时对源代码进行编译,生成机器代码,然后直接执行。具体来说,主要分为以下几个步骤: 解释:程序首次运行时,解释器逐行解释源代码,并执行。这一步编译开销较大,运行较慢。 profiling:解释器会检测程序的热点代码(频繁执行的代码),并选择优化它们。 编译:解释器会将热点代码编译成机器代码,然后缓存起来。 运行:第二次运行热点代码时,直接执行缓存的机器代码,省去解释的开销,运行速度明显提高。 优化:JIT编译器会对热点代码进行进一步的优化,如内联扩展、去虚拟化等,提高性能。 缓存分享:不同运行实例之间可以共享JIT缓存,减少编译工作,这也是JIT的优化手段之一。 所以JIT的关键是将编译过程推迟到程序运行时,并只编译热点代码,其他代码继续由解释器解释。这使得JIT在第一次运行时有一定开销,但可以达到较好的运行性能,且编译结果可以在多次运行间重复使用。 JIT的优点是开发体验好,修改代码后无需重新编译,直接运行即可。但运行时会有一定的编译开销,性能也比AOT略差。 所以,JIT更适用于开发调试阶段,以及对运行性能要求不高的场景。 总之,JIT通过将编译过程推迟到程序运行时,在保证开发体验的同时,通过热点代码编译和优化,获得还可以的运行性能,这就是JIT的核心原理。 Android 中使用的是 JIT 还是 AOT ？ Android使用的启动方式是把JIT和AOT混合使用: JIT部分: Android程序通常使用Java语言编写,运行在Dalvik/ART虚拟机上。 Dalvik/ART会在程序第一次运行时将Java字节码解释执行(解释器方式)。 然后它会检测热点代码,并利用JIT编译器将热点代码编译成机器码缓存并执行。 这部分属于典型的JIT方式。 AOT部分: 从Android 7.0 开始,Google 推出了一种新的 AOT 编译模式，一般称为 *profile-guided *。 开发者可以让ART AOT编译器在安装应用时提前编译应用的Java字节码为机器码。 然后在每次运行应用时,直接执行预编译好的机器码,而不是先解释Java字节码。 这部分属于典型的AOT方式,可以减少运行时的性能开销,提高应用启动速度。 混合使用: 在Android的大部分时间里,仍然是采用JIT方式运行Java字节码和机器码的混合方式。 JIT方式适合开发调试,AOT方式适合生产环境APP。 从Android 7.0开始,开发者可以根据需要选择JIT,AOT或混合的方式来启动自己的应用。 所以,总体来说,虽然Android运行环境本质上是一种JIT虚拟机,但是从Android 7.0开始,Google为了追求更高的运行性能,允许开发者选择AOT方式启动APP。这使得Android可以很好的适用JIT和AOT各自的优势,是一种非常灵活的设计。 所以答案是:Android既使用JIT,也使用AOT,并可以根据需要选择两种方式或混合使用。 动态链接、静态链接 动态链接和静态链接都是程序中调用库文件的方式,但有以下主要区别: 链接时间: 静态链接:在编译时将库文件链接到可执行文件中,产生完整的可执行文件。 动态链接:在运行时将库文件链接到可执行文件中。 空间占用: 静态链接:库文件代码被复制到每个可执行文件中,空间占用较大。 动态链接:库文件只有一份,被多个可执行文件共享,空间占用较小。 依赖性: 静态链接:可执行文件不依赖于库文件,可以独立运行。 动态链接:可执行文件依赖于库文件,需将库文件与可执行文件放在一起才能运行。 版本问题: 静态链接:可执行文件使用的是链接时库文件的代码,Even if库文件更新,可执行文件还是使用原来的代码。 动态链接:可执行文件使用的都是最新的库文件代码,如果库文件更新,可执行文件自动使用最新代码。 总的来说, 静态链接产生的可执行文件更独立和稳定,但空间占用更大; 动态链接产生的可执行文件更灵活和节省空间,但依赖性更强。 动态链接还可以进一步细分为运行时链接和装载时链接,这是实现层面的细节差异。 本质上,它们都是动态链接,在程序运行期将库文件的代码装入进程地址空间。 大部分情况下,我们选择动态链接来利用库文件。 Linux的软链接和硬链接吗？ Linux链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。默认情况下，ln命令产生硬链接。 硬连接 硬连接指通过索引节点来进行连接。在Linux的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在Linux中，多个文件名指向同一索引节点是存在的。","date":"2022-07-17","objectID":"/2022/07/os_summary/:0:0","tags":["OS"],"title":"一张思维导图看操作系统 【持续迭代】","uri":"/2022/07/os_summary/"},{"categories":["OS"],"content":"mmap 的应用 - 日志库 由于内存Cache的存在，在写入数据的过程中一旦发生意外（Crash、后台被系统杀死，等），都可能会发生数据丢失的情况。而如果将写操作设计成同步的，数据丢失的情况会有所改善，但写操作的耗时会大大提升。mmap 的引入恰到好处的在这两者之间找到了一个平衡。mmap 对文件的读取操作跨过了页缓存，减少了数据的拷贝次数，用内存读写取代I/O读写，提高了文件读取效率； 对 mmap 内存的写操作，会直接进入系统page-cache；msync调用负责把脏的page-cache持久化到硬盘。当然对发生系统级错误和设备异常导致系统挂掉的情况，mmap 也是保证不了数据完整性的。 这里需要特别说明一下：MMKV 实现的本质上跟前面讨论的KV方案是没有区别的，其最大的改进是利用 mmap 来代替 File 和 Database 的操作，利用 mmap I/O 操作的优势对数据丢失问题进行改善。但由于“内存-文件”两级缓存的存在，MMKV 也是无法彻底解决数据丢失问题的。当然对于终端设备的场景来看，这种丢失在很大程度上是可以忽略的。 微信团队在封装 xlog 和 mmap 时采用了CPP代码来实现，主要是为了做到 Android 和 iOS 端的通用。实际上如果不考虑跨平台，则可以考虑使用 Java NIO 中的 FileChannel 或者 Android 中的 MemoryFile 代替。 FileChannel 底层其实通过 mmap 实现的。而 MemoryFile 则是 Android 中匿名共享内存在 Java 层的接口，至于 Android 匿名共享内存底层实现也利用了mmap。所以，FileChannel 和 MemoryFile 本质上与直接调用 mmap 是一样的。利用这些接口也可以降低大部分 Android 程序员的开发和维护成本，毕竟大家对 Java 相对更为熟悉。 下面是在 KV 设计中另一种 Key 的设计方案： 我们在数据存储时，以32位的 Int 作为作为 Key ， 其中： 低位 24 位来定义 Key 的长度； 最高位，第 32 位表示 Key 是否有效：为 1 时表示 Key 无效，读取时跳过 第 31 位 表示是否加密：为 1 时表示未加密，不需要解密处理； 第 30 位表示是否需要编码：为 1 时表示保存明文，不进行转码处理； 中间 25 - 29 位预留，以后扩展用 这样设计Key的优点： 在加载的时候只根据 Key 就可以判断数据是否有效，无效数据不需要加载到内存；MMKV 则是依靠 相同 Key 在 put 到 map 中时先后顺序的覆盖实现的，对于无效数据需要根据 Key 进一步得到 Value，判断 Value 的长度是否为 0 。 可以一定程度实现空间重用，当更新后的 Value 长度不超过旧值的长度时，可以直接复用原来的空间，在 Value 长度超过旧值时将 Key 的有效位置 1 ，然后再在尾部 append Key-Value即可。当然这里只是“一定程度”上改善，要想进一步做到空间重用，还可以考虑： 对字符串等经常变长的 Value 在第一次 写入的时候就留有一定的空间冗余度； 通过一个内存的堆栈对无效空间进行管理，甚至你可以模仿内存的分配策略做的更加完善 因此，这里如何做是一个“度”的问题，而这个“度”的把握则取决于对设备和产品的理解。对微信来说，他们的理解是 append 就够了，个人理解是可以做一定程度（“简单”）复用策略的，通过复用减缓到达空间上限的时间，因为每次加载时 Key 的去重以及回写都是有一定的性能开销的。 这样设计 Key 相对更加灵活，可以对数据加密、编码等根据需要搭配，做到不同形式数据的混存 直接 IO 与 非直接 IO 我们都知道磁盘 I/O 是非常慢的，所以 Linux 内核为了减少磁盘 I/O 次数，在系统调用后，会把用户数据拷贝到内核中缓存起来，这个内核缓存空间也就是「页缓存」，只有当缓存满足某些条件的时候，才发起磁盘 I/O 的请求。 那么，根据是「否利用操作系统的缓存」，可以把文件 I/O 分为直接 I/O 与非直接 I/O： 直接 I/O，不会发生内核缓存和用户程序之间数据复制，而是直接经过文件系统访问磁盘。 非直接 I/O，读操作时，数据从内核缓存中拷贝给用户程序，写操作时，数据从用户程序拷贝给内核缓存，再由内核决定什么时候写入数据到磁盘。 如果你在使用文件操作类的系统调用函数时，指定了 O_DIRECT 标志，则表示使用直接 I/O。如果没有设置过，默认使用的是非直接 I/O。 如果用了非直接 I/O 进行写数据操作，内核什么情况下才会把缓存数据写入到磁盘 以下几种场景会触发内核缓存的数据写入磁盘： 在调用 write 的最后，当发现内核缓存的数据太多的时候，内核会把数据写到磁盘上； 用户主动调用 sync，内核缓存会刷到磁盘上； 当内存十分紧张，无法再分配页面时，也会把内核缓存的数据刷到磁盘上； 内核缓存的数据的缓存时间超过某个时间时，也会把数据刷到磁盘上； 阻塞与非阻塞 I/O VS 同步与异步 I/O IO 整体分为两个过程 数据准备的过程； 数据从内核空间拷贝到用户进程缓冲区的过程； 阻塞 I/O 会阻塞在「过程 1 」和「过程 2」，而非阻塞 I/O 和基于非阻塞 I/O 的多路复用只会阻塞在「过程 2」，所以这三个都可以认为是同步 I/O。 异步 I/O 则不同，「过程 1 」和「过程 2 」都不会阻塞。 进程和线程 ","date":"2022-07-17","objectID":"/2022/07/os_summary/:1:0","tags":["OS"],"title":"一张思维导图看操作系统 【持续迭代】","uri":"/2022/07/os_summary/"},{"categories":["OS"],"content":"区别联系 进程和线程的主要差别在于它们是不同的操作系统资源管理方式。 进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响， 而线程只是一个进程中的不同执行路径。 线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮， 但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。 简而言之,一个程序至少有一个进程,一个进程至少有一个线程。 线程的划分尺度小于进程，使得多线程程序的并发性高。 另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。 线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。 【重要】从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。 ","date":"2022-07-17","objectID":"/2022/07/os_summary/:2:0","tags":["OS"],"title":"一张思维导图看操作系统 【持续迭代】","uri":"/2022/07/os_summary/"},{"categories":["OS"],"content":"进程的调度算法 参考链接1 参考链接2 先来先服务调度算法，（First Come First Severd, FCFS） 先来后到，每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。 FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。 最短作业优先（Shortest Job First, SJF）调度算法 优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。 这显然对长作业不利，很容易造成一种极端现象。长作业一直得不到执行。 高响应比优先 （Highest Response Ratio Next, HRRN）调度算法 主要是权衡了短作业和长作业。 每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式： 时间片轮转（Round Robin, RR）调度算法。 每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程； 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换； 时间片的长度就是一个很关键的点： 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率； 如果设得太长又可能引起对短作业进程的响应时间变长； 通常时间片设为 20ms~50ms 通常是一个比较合理的折中值。 最高优先级（Highest Priority First，HPF）调度算法。 从就绪队列中选择最高优先级的进程进行运行。 进程的优先级可以分为，静态优先级或动态优先级： 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化； 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。 该算法也有两种处理优先级高的方法，非抢占式和抢占式： 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。 但是依然有缺点，可能会导致低优先级的进程永远不会运行。 多级反馈队列（Multilevel Feedback Queue）调度算法 「多级」表示有多个队列，每个队列都有一个优先级，队列按照优先级从高到低排列，同时优先级越高时间片越短。 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列； 工作流程 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短； 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成； 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行； 可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。 ","date":"2022-07-17","objectID":"/2022/07/os_summary/:3:0","tags":["OS"],"title":"一张思维导图看操作系统 【持续迭代】","uri":"/2022/07/os_summary/"},{"categories":["OS"],"content":"死锁和死锁避免 死锁产生的原因有以下几个: 互斥条件:一个资源一次只能被一个进程使用； 请求和保持条件:一个进程因为获得了一个资源而阻塞时,仍然保持对其他资源的请求； 不可剥夺条件:进程已经获得的资源,不能被其他进程强行剥夺,直到该进程使用完毕为止； 循环等待条件:若干进程之间形成一种头尾相接的等待资源关系,造成循环等待。 避免死锁,主要是破坏4个必备条件即可，可以采取以下措施: 破坏互斥条件:不做 破坏请求和保持条件:进程在请求资源时,不保持对其他资源的请求。 Release所有资源后再请求其他资源。 破坏不可剥夺条件:允许进程在等待期间,被其他进程剥夺资源。 但这可能影响运行正确性,不太可取。 破坏循环等待条件:按某种顺序获取多个资源,避免循环等待。如按资源标号顺序获取资源。 使用资源继承线程:让每个资源都只有一个线程可以获取,其他线程必须等待。 此时多个线程竞争同一资源时不会发生死锁。 设置资源请求超时时间:如果在一定时间内不能获取资源,则放弃请求。避免一直等待下去。 减少对资源的请求数目:合理分配和调度资源,避免过多进程同时请求少量资源。 ","date":"2022-07-17","objectID":"/2022/07/os_summary/:4:0","tags":["OS"],"title":"一张思维导图看操作系统 【持续迭代】","uri":"/2022/07/os_summary/"},{"categories":["OS"],"content":"线程的状态以及转换 *进程的状态图 线程状态图 参考链接1 线程调度的原则，考虑的就是速度快，需要考量的因素如下 CPU 利用率：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率； 系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量； 周转时间：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好； 等待时间：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意； 响应时间：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。 Java 线程的状态，有六种 NEW RUNNABLE BLOCKED WAITING TIMED_WAITING TERMINATED 经典的线程五态模型，有五种状态 创建 就绪 执行 阻塞 终止 Java 将五态模型中的 就绪和执行，都统一成 RUNNABLE， 将阻塞（即不可能得到 CPU 运行机会的状态）细分为了 BLOCKED、WAITING、TIMED_WAITING，这里我们不去评价好坏。 调用 jdk 的 Lock 接口中的 lock，如果获取不到锁，线程将挂起，此时线程的状态是什么呢？ 有多少同学觉得应该和 synchronized 获取不到锁的效果一样，是变成 BLOCKED 状态？ 不过如果你仔细看我上面的文章，有一句话提到了，jdk 中锁的实现，是基于 AQS 的，而 AQS 的底层，是用 park 和 unpark 来挂起和唤醒线程，所以应该是变为 WAITING 或 TIMED_WAITING 状态。 调用阻塞 IO 方法，线程变成什么状态？ 比如 socket 编程时，调用如 accept()，read() 这种阻塞方法时，线程处于什么状态呢？ 答案是处于 RUNNABLE 状态，但实际上这个线程是得不到运行权的，因为在操作系统层面处于阻塞态，需要等到 IO 就绪，才能变为就绪态。 但是在 Java 层面，JVM 认为等待 IO 与等待 CPU 执行权，都是一样的。 ","date":"2022-07-17","objectID":"/2022/07/os_summary/:5:0","tags":["OS"],"title":"一张思维导图看操作系统 【持续迭代】","uri":"/2022/07/os_summary/"},{"categories":["OS"],"content":"重开线程 Java 中的线程是不可以重开的； 进程和线程内存地址空间的区别 进程的地址空间是私有的,互不共享。 线程共享进程的地址空间,可以访问进程内所有变量和资源。 不同进程的线程不能共享地址空间。 线程同步机制 锁(Lock)。锁是最基本的线程同步机制,它允许线程对共享资源的访问进行互斥,从而保证同一时间只有一个线程可以访问该资源。常见的锁有互斥锁、读写锁等。 条件变量(Condition Variable)。条件变量允许线程等待某个条件满足后再继续执行。它通常与锁一起使用,锁保证访问共享资源的互斥,条件变量允许等待某个条件。 信号量(Semaphore)。信号量是一个计数器,它允许多个线程访问一个资源,但是同一时间访问的线程数量不可以超过计数器的值。它主要用于控制对资源的访问数量。 事件(Event)。事件允许一个线程通知其他线程某个事件已经发生,当事件发生时,Those等待线程会被唤醒。它主要用于线程间的通信和同步。 屏障(Barrier)。屏障允许多个线程在某个点汇集,当某个数量的线程到达屏障点后,这些线程才会继续执行。它主要用于多个线程同步执行。 自旋锁(Spinlock)。自旋锁是一种忙等待的锁,获取锁的线程会循环检测锁的状态,而不是睡眠,这可以减少线程上下文切换的开销,但是会占用更多的CPU资源。它主要用于同步对共享资源的访问。 所以总体来说,线程同步机制为我们提供了控制多个线程对共享资源访问的工具,保证数据的一致性和正确性。 同步机制中的锁和信号量的区别是什么？ 锁和信号量都是用于线程同步的机制,但是它们之间有以下主要区别: 锁是一种互斥机制,它允许同一时间只有一个线程访问共享资源。信号量是一种计数器,它允许多个线程访问共享资源,但是访问的线程数量不可以超过信号量的计数值。 锁通常只有两个状态:锁定和未锁定。信号量的计数器可以是任意非负整数。 想要访问共享资源的线程首先要获取锁,获取后该线程独占该资源,其他线程无法访问。想要访问共享资源的线程首先要获取信号量,获取将信号量的计数器减1,释放会让计数器加1,只要计数器的值大于0,线程就可以访问资源。 锁由调用 lock() 方法获取,调用 unlock() 方法释放。信号量由调用 acquire() 方法获取,调用 release() 方法释放。 锁可以用于同步任何类型的资源。信号量主要用于控制对资源的访问数量,通常用于实现资源池等。 锁的实现通常更轻量级,性能开销较小。信号量的实现相对复杂一些,性能开销较大。 所以总体来说,虽然锁和信号量都是用于线程同步的机制,但是锁是一种互斥的同步方式,而信号量是一种控制访问数量的同步机制。根据不同的需求,可以选择使用锁或者信号量来实现线程同步。 ","date":"2022-07-17","objectID":"/2022/07/os_summary/:6:0","tags":["OS"],"title":"一张思维导图看操作系统 【持续迭代】","uri":"/2022/07/os_summary/"},{"categories":["OS"],"content":"读写锁的原理 读写锁是操作系统中用于保护共享资源的一种锁机制。它允许多个读线程同时访问一个资源,但在写线程访问时会阻塞所有读线程和其他写线程。读写锁的主要原理是: 维护一个读计数器和一个写标志。读计数器记录当前有多少个读线程正在访问资源,写标志表示是否有写线程正在访问资源。 当一个读线程请求访问资源时,如果写标志是False,则读计数器加1,并允许读线程访问资源。如果写标志是True,则读线程等待。 当一个写线程请求访问资源时,如果读计数器和写标志都是False,则将写标志设置为True,并允许写线程访问资源。如果读计数器不为0或写标志为True,则写线程等待。 当一个读线程退出时,将读计数器减1。当写线程退出时,将写标志设置为False。 只有当读计数器和写标志都是False时,才允许下一个待命的写线程访问资源。 这样就可以实现多个读线程并发访问,而写线程互斥访问的效果。这样可以最大限度地提高资源的并发访问效率。这就是读写锁的基本原理。读写锁是相比互斥锁更细粒度的锁机制,在许多场景下可以实现更高的并发效率,所以在操作系统和许多程序中得到广泛应用。 Java 中的读写锁 JUC 中 有 ReentrantReadWriteLock 和 StampedLock 这两个类，都是读写锁。 区别在于 StampedLock 是读乐观的锁。 原子操作原理 https://zhuanlan.zhihu.com/p/33445834 从用户角度，可以用原子操作来替换重量级的锁同步，从而提高程序性能。 底层实现角度，原子操作可以用于构建各种更重量级的同步操作，比如锁或屏障之类的。 原子操作的原理是利用CPU的原子指令来确保操作的原子性。通常有两种方式: 硬件支持的原子指令,如CMPXCHG指令。这些指令本身就是原子的,可以直接实现原子操作。 锁定总线,使其他CPU无法访问共享内存。这种方式会临时锁定系统总线,使当前CPU独占总线,其他CPU无法访问内存。从而确保操作的原子性。这通常是通过获取一个锁来实现的。但这个方式的性能较低,现代CPU一般不采用这种方式。 原子操作的四个要素: 原子性:操作必须是不可中断的,要么全部完成,要么全部不完成,不会结束在中间某个状态。 可见性:当一个线程修改了共享数据的值,其他线程可以立即得知这个修改。 有序性:代码执行的顺序与程序顺序相同。 互斥性:在任意时刻,只能有一个线程修改共享数据。 常见的实现方式： CAS(Compare And Swap)指令是最常用的实现原子操作的指令,它可以比较内存中一个位置的值,如果相等则更新为新值,否则不做任何操作。CAS是CPU提供的原子指令,可以直接实现原子操作。 许多CPU提供的原子指令,如xchg指令、xadd指令,这些都可以实现简单的原子操作。 锁是实现原子操作的一种重要方式。对某个锁对象上锁,执行一系列操作,然后释放锁,这整个过程是其他线程不可分割的,可以保证原子性。这需要使用互斥锁等同步原语。 有时候需要借助操作系统的帮助。例如,可以使用临界区(critical section)的方式,让操作系统在进入和退出临界区时禁止中断或者调度,从而实现原子操作。 实现原子操作有软硬件多种手段,但本质上都是利用CPU的原子指令或锁总线的方式来确保一系列操作的原子性 CAS 为什么可以保证原子性？ CAS是CPU的原子指令,不会被编译器优化或重排序。CPU会确保CAS整个操作过程不被中断,要么全部完成,要么全部不完成,不会中间被中断导致只完成一半。这就保证了操作的原子性。 CAS操作包含三个步骤:读取内存值A,比较A与预期值B,如果相等则写入新值C。这三个步骤是连续的,不会被其他线程的操作插入或重排序。所以从其他线程的视角来看,这三个步骤要么全部完成,要么都不完成,这也确保了原子性。 CAS操作在多处理器下需要锁总线,使当前CPU独占内存总线,其他CPU无法访问内存。这可以防止多个CPU同时执行CAS操作,导致某个CPU只完成了部分步骤就被中断,破坏原子性。锁总线可以确保任意时刻只有一个CPU可以执行CAS指令。 CAS保证了操作的互斥性,在任意时刻只能有一个CPU成功执行CAS指令,其他CPU会一直循环重试。这也是实现原子性的条件之一。 成功执行CAS指令的CPU可以确保其他CPU可以看到修改的值(可见性)。并且各个CPU看到的CAS操作的顺序跟代码中的顺序是一致的(有序性)。 总之,CAS能够保证原子操作的原子性、可见性、有序性和互斥性这四个要素。这些特性共同确保了CAS的原子操作正确性,使其可以实现线程同步等功能。 所以,CAS之所以可以保证原子性,关键在于它是CPU提供的原子指令,内部可以锁总线并包含连续的三步原子操作,这些特征共同满足原子操作的四个要素,从而实现了原子性。 字符编码 Unicode 和 ANSI 的区别 Unicode 和 ANSI 是两种字符编码标准,主要区别如下: 字符集范围不同: Unicode 表示的字符范围更广,包含了绝大多数世界上的文字,可以表示几乎所有的字符。Unicode 的最新版本支持超过 136,000 个字符。 ANSI 只支持 256 个字符,主要是西欧语言的字符。 编码方式不同: Unicode 使用 2 个字节表示一个字符,所以每个字符有 65,536 个值可用。这种编码方式叫做 UTF-16。 ANSI 使用 1 个字节表示一个字符,每个字符只有 256 个值可用。 兼容性不同: Unicode 建立的初衷就是为了解决不同语言字符之间的兼容问题,所以具有很好的兼容性。可以同时支持多种语言。 ANSI 由于只支持 256 个字符,兼容性较差,不适合 Internationalization(国际化)应用。 Processing 不同: Unicode 需要专门的文本处理方式,比如 Unicode 字符串比较、搜索等都需要专门的算法和函数来实现。 ANSI 可以直接使用字符串的默认处理函数,更简单。 所以总体来说,Unicode 比 ANSI 更加强大和通用。现代应用越来越多采用 Unicode 标准来支持多语言。但 ANSI 由于简单易用,在一些场景下也还是有应用。 字符编码和字符编码方式是什么关系？ 字符编码:指为一组字符指定的数字值,它决定了每个字符被存储或传输时对应的二进制代码。常见的字符编码有 ASCII、ISO-8859-1、GBK、Unicode 等。 字符编码方式:是指对字符编码的具体实现方式。一种字符编码可以有多种编码方式。例如: Unicode 字符编码可以通过 UTF-8、UTF-16、UTF-32 等编码方式来实现。 GBK 字符编码就对应一种 GBK 编码方式。 两者的关系可以简单理解为:字符编码 = 字符集 + 编码方式 字符集定义了包含哪些字符,比如 ASCII 的字符集 just 包含英文字符,Unicode 包含全球大多数的字符。 编码方式则定义了如何使用比特位来表示字符集中的每个字符,比如 UTF-8 使用 1-4 个字节,UTF-16 一般使用 2 个字节。 所以,编码方式是实现字符编码的具体方法。一种字符编码可以有多种编码方式,但一种编码方式只对应一种字符编码。 编码方式的不同会导致在存储、传输和兼容性上产生影响: 存储:不同编码方式的字符可能对应不同数量的字节,会影响文件大小或数据库存储空间。 传输:字节数量的不同会影响传输的带宽要求。 兼容性:只有使用相同的字符编码和编码方式的系统或软件之间才具有良好的兼容性。所以选择恰当的字符编码方式对实现字符编码非常重要。 虚拟内存(Virt) \u0026 常驻内存(Resident) \u0026 共享内存 (Shared) 虚拟内存(Virt):进程地址空间的大小,包括实际使用的物理内存以及交换空间。虚拟内存的值通常比实际的物理内存和交换空间之和要大。 常驻内存(Resident):进程正在使用的物理内存大小。常驻内存是实际分配给进程的物理内存,用于存储进程当前正在使用的数据和指令。 共享内存(Shared):多个进程共享的内存大小。当几个进程共享同一块物理内存时,这个内存既属于其中一个进程的常驻内存,也属于其他进程的共享内存。 所以,我们可以得出: 虚拟内存(Virt) \u003e= 常驻内存(Resident) + 共享内存(Shared) 常驻内存(Resident) = 非共享的物理内存 + 共享内存(Shared) 简而言之: 虚拟内存是进程地址空间的大小,包含实际使用的内存和交换空间。 常驻内存是进程实际正在使用的物理内存大小,包括共享内存和非共享内存。 共享内存是被多个进程共享使用的内存部分。 所以这三者之间存在包含关系和部分重叠的关系。 Free \u0026 Available “Free\"表示当前没有被分配使用的内存空间大小。也就是说，这是操作系统内存管理系统中未被分配给任何进程使用的内存。 “Available\"则表示当前可用于分配给进程使用的内存空间大小，其中包括空闲的、未被分配的内存以及被分配但未被进程使用的内存。这意味着，“Available\"并不只是指未被使用的内存，而是可以被操作系统分配给进程使用的内存空间。 空闲内存：操作系统中未被分配给任何进程使用的内存空间。 操作系统缓存：操作系统使用的缓存，用于加速系统性能。这些缓存通常包括文件系统缓存、页面缓存等。 被回收内存：已经被进程占用但是已经释放的内存空间，这些内存可以被重新分配给其他进程使用。 虚拟内存：系统中使用的虚拟内存，其中包括已经被分配但当前未被使用的虚拟内存空间。 Buffer \u0026 Cached “Bu","date":"2022-07-17","objectID":"/2022/07/os_summary/:7:0","tags":["OS"],"title":"一张思维导图看操作系统 【持续迭代】","uri":"/2022/07/os_summary/"},{"categories":["Network"],"content":"概述 受到《计算机网络-自顶向下方法》 的启发，按照网络请求的过程，总结自己的网络知识，按照时间线，画了一张图，xmind 导出的图比较大，后续持续更新，迭代这部分的内容。 下面是一些常见的知识,将会慢慢补充进思维导图内 输入 url 到页面展示，经历的过程 参考链接1 参考链接2 url 解析，提取 host； DNS 解析 匹配浏览器的 DNS 的缓存； 匹配 Host 文件； 匹配系统的 DNS 缓存； 系统向本地 DNS 服务器发送请求； 联网时候，系统会自动发送 DHCP Request，路由器收到这个广播后，会向电脑分配一个地址，这个地址就是 DNS 服务器的地址； 可以通过抓包看； 通过设置中心； 通过生成的临时文件查看； DNS 通过 DNS 迭代查询 查询域名的 ip 地址； DNS 服务器返回多个地址组合，浏览器根据 DNS 轮转策略 选择一个 IP 地址进行请求； 这个过程在各个 socket 库中都有系统实现； 委托系统网络协议栈发送请求数据 创建 socket 套接字； 套接字是内存中的一块内存，其中保存了通信的控制信息； 一个套接字对应了一个端口，用以区分不同的 socket 套接字； 将 socket 连接到 server；三次握手 发送数据； 协议栈不关心应用程序传来的数据内容。在它看来，要发送的数据就是一段二进制字节序列而已。 协议栈并不会在收到数据后马上发出，而是需要判断几个要素后决定是否发出： 当协议栈缓冲区中存在的数据长度超过或接近 MSS 时会将包发出。 在收到一段数据后缓冲区会开启一个计时器，经过一定时间后仍未有新数据包产生则将缓冲区内容发出。 如果应用程序指定了“立刻发出”，那么协议栈就会按照要求直接发送数据。（一般像浏览器这种会话型的应用程序在向服务器发送数据时，等待填满缓冲区会导致延迟影响用户体验，因此一般会要求协议栈直接发出） MTU：一个网络包的最大长度，以太网中一般为1500字节。 MSS：除去头部之后，一个网络包所能容纳的TCP数据的最大长度。 接收数据 首先，协议栈尝试从接收缓冲区中取出数据并传递给应用程序，但这个时候请求消息刚刚发送出去，响应消息可能还没返回。响应消息的返回还需要等待一段时间，因此这时接收缓冲区中并没有数据，那么接收数据的操作也就无法继续。这时，协议栈会将应用程序的委托，也就是从接收缓冲区中取出数据并传递给应用程序的工作暂时挂起，等服务器返回的响应消息到达之后再继续执行接收操作。 协议栈接收到数据会会检查收到的数据块和 TCP 头部的内容，判断包是否合法可用，如果没问题则返回 ACK 确认号。然后将数据块暂存到缓冲区中，并拼接数据还原原始数据。 数据包恢复原样后将会将数据复制到应用程序指定内存地址后将控制流程转交回应用程序。然后再寻找合适时机进行窗口更新。 断开连接；四次挥手 删除套接字 DNS ","date":"2022-05-17","objectID":"/2022/05/net-process/:0:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"作用 域名解析，将网址中的域名解析成协议栈的 IP 地址。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:1:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"过程 DNS 域名解析的过程蛮有意思的，整个过程就和我们日常生活中找人问路的过程类似，只指路不带路。 浏览器首先看一下自己的缓存里有没有，如果没有就向操作系统的缓存要，还没有就检查本机域名解析文件 hosts，如果还是没有，就会 DNS 服务器进行查询，查询的过程如下： 客户端首先会发出一个 DNS 请求，问www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。 根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。” 本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我www.server.com的 IP 地址吗？” 顶级域名服务器说：“我给你负责www.server.com区域的权威 DNS 服务器的地址，你去问它应该能问到”。 本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。 Http HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。 HTTP 的名字「超文本传输协议」，它可以拆成三个部分： 超文本 传输 协议 ","date":"2022-05-17","objectID":"/2022/05/net-process/:2:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"HTTP 常见的 header 在 HTTP 中，header 是用于描述请求或响应的元数据，提供了有关请求或响应的信息。以下是一些常见的 HTTP 请求和响应头: 通用 Headers (适用于请求和响应): Cache-Control: 指示缓存策略，如 max-age、no-cache、no-store 等。 Connection: 控制是否保持网络连接，值可以为 keep-alive 或 close。 Content-Encoding: 表示已对实体内容使用的编码方法(例如 gzip)。 Content-Length: 描述实体内容的数据大小（单位：字节）。 Content-Type: 描述实体内容的 MIME 类型(如：application/json、text/html)。 Date: 表示消息创建的时间。 Pragma: 提供向后兼容性的缓存控制。 Transfer-Encoding: 描述应用于消息主体的传输编码方式，如 chunked。 请求 Headers: Accept: 指示客户端可以处理的 MIME 类型。 Accept-Charset: 指示客户端可以接受的字符集。 Accept-Encoding: 指示客户端可以处理的内容编码。 Accept-Language: 列出客户端可以理解的自然语言。 Authorization: 提供了用于身份验证的凭据。 Host: 指定请求的目标服务器和端口号。 If-Modified-Since: 请求的资源在指定日期之后更新时才返回。 If-None-Match: 指定资源的 ETag 与目标资源的 ETag 匹配时才返回。 User-Agent: 描述客户端的软件信息。 响应 Headers: Allow: 指示支持的 HTTP 方法，如 GET、POST 等。 Content-Disposition: 附加说明信息，如对下载文件的文件名进行描述。 Content-Language: 实体内容使用的自然语言。 ETag: 资源的版本标识，用于缓存验证。 Expires: 指定资源过期的时间。 Last-Modified: 指示资源最后一次被修改的时间。 Location: 用于重定向，指向新的 URL。 Server: 描述服务器软件信息。 Set-Cookie: 设置 Cookie。 WWW-Authenticate: 要求客户端进行身份验证。 这只是 HTTP header 的一部分，实际上有更多的 header 用于定制和控制 HTTP 请求和响应。每个应用程序和服务器可能会使用不同的 header。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:3:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"keep-alive 的原理 keep-alive 机制：若开启后，在一次 http 请求中，服务器进行响应后，不再直接断开 TCP 连接，而是将 TCP 连接维持一段时间。在这段时间内，如果同一客户端再次向服务端发起 http 请求，便可以复用此 TCP 连接，向服务端发起请求，并重置 timeout 时间计数器，在接下来一段时间内还可以继续复用。这样无疑省略了反复创建和销毁 TCP 连接的损耗。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:3:1","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"常见问题 GET 和 POST 有什么区别？ 根据 RFC 规范，GET 的语义是从服务器获取指定的资源，这个资源可以是静态的文本、页面、图片视频等。GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）。 根据 RFC 规范，POST 的语义是根据请求负荷（报文body）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中，body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。 GET 和 POST 方法都是安全和幂等的吗？ 安全和幂等的概念： 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。 结论 GET 方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。 POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。 但是，实际应用过程中，不一定按照 RFC 的规范实现。 Get 请求可以带 body 吗？ RFC 并没有规定 Get 请求不可以带 body，看具体的网络库的实现。 HTTP的缓存实现方式 强制缓存：只要缓存没过期，浏览器就适用缓存中的数据； 强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期： Cache-Control， 是一个相对时间； Expires，是一个绝对时间； 协商缓存： 协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存。 强制缓存是基于时间实现的，协商缓存是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。 H1 和 H2 的区别联系 ","date":"2022-05-17","objectID":"/2022/05/net-process/:4:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"H1 的优缺点 优点 简单。header + body，header 还是 kv 形式； 灵活易扩展。https 就是 http + tls；http3 就是将 tcp 改成了 UDP 方案； 应用广泛。 缺点 无状态。无状态可以减轻资源消耗，但是关联操作时，会非常麻烦。针对这个问题，提出了 cookie 技术。 明文传输、不安全。可以方便阅读，为调试提供了便利性。但是，带来了信息泄露的风险。 【性能】通信开销大。http1.0 每个连接都需要进行三次握手，消耗很大。http1.1 提出了长连接通信。 【性能】队头阻塞。虽然可以采用管道的方式进行 HTTP 的请求，但是服务器还是需要按照请求的顺序对管道中的请求进行响应的。所以，如果不采用管道，那么请求和响应都有队头阻塞的问题，如果采用管道，那么可以解决请求的队头阻塞，但是响应的队头阻塞没办法解决。而且，管道默认是关闭的。（造成了队列是顺序请求的，前面的请求 block，就会影响后面的请求。 【效率】请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分； 【效率】发送冗长的首部。每次互相发送相同的首部造成的浪费较多； 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞； 没有请求优先级控制； 请求只能从客户端开始，服务器只能被动响应。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:5:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"H2 优化点 ","date":"2022-05-17","objectID":"/2022/05/net-process/:6:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"头部压缩 H1 是明文的，多个请求发送的 header 可能存在大量的重复，header 越多，越大，浪费越严重； H2 通信的双方共同维护索引表，传输的 header 只需要发送索引表中的索引即可； HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你消除重复的部分。 这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。 双方维护一张头信息表； 各自只发送信息表中的索引号； ","date":"2022-05-17","objectID":"/2022/05/net-process/:6:1","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"二进制格式 H1 是明文传输，传输的报文更大，增加了传输成本。 H2 改成了二进制格式，传输的报文更小，降低了传输的成本。 HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧（Headers Frame）和数据帧（Data Frame）。 这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这增加了数据传输的效率。 比如状态码 200 ，在 HTTP/1.1 是用 ‘2’‘0’‘0’ 三个字符来表示（二进制：00110010 00110000 00110000），共用了 3 个字节。 在 HTTP/2 对于状态码 200 的二进制编码是 10001000，只用了 1 字节就能表示，相比于 HTTP/1.1 节省了 2 个字节。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:6:2","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"并发传输 我们都知道 HTTP/1.1 的实现是基于请求-响应模型的。同一个连接中，HTTP 完成一个事务（请求与响应），才能处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了队头阻塞的问题。 HTTP/2 就很牛逼了，引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接。1 个 TCP 连接包含多个 Stream，Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）。 针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应。 服务端并行交错地发送了两个响应： Stream 1 和 Stream 3，这两个 Stream 都是跑在一个 TCP 连接上，客户端收到后，会根据相同的 Stream ID 有序组装成 HTTP 消息。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:6:3","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"服务器推送 HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以主动向客户端发送消息。 客户端和服务器双方都可以建立 Stream， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:6:4","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"H2 的缺点 H2 解决了 H1 的 HTTP 层面的队头阻塞； 但是依旧面临 TCP 的队头阻塞； HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。 一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。 H3 HTTP/3 的核心原理是基于 UDP 而不是 TCP,它采用 QUIC 协议。QUIC 是 Google 开发的一种传输层网络协议,用于优化网络延迟,提高网络连接利用率。QUIC 协议相比 TCP 主要有以下几点改进: 基于 UDP。QUIC 协议基于 UDP 而不是 TCP,可以避开 TCP 的拥塞控制和流量管理机制,获得更低的延迟和更高的吞吐量。 连接迅速建立。QUIC 协议的连接可以在 1 个 RTT(往返时延)内完成,比 TCP 快很多。这可以加速 HTTP/3 的连接建立和资源请求。 多路复用。QUIC 支持在一个连接上并行传输多条数据流,并且每个数据流都有自己的流量控制,相互不影响。这进一步提高了连接的利用率。 无头部压缩。QUIC 协议本身不定义头部压缩机制,直接使用 HPACK 算法对 HTTP/3 的头部信息进行压缩。 重传机制。QUIC 协议定义了自己的重传和流量控制机制来最小化网络拥塞和包丢失的影响。 零延迟 resumed 的连接。QUIC 允许连接处于静默状态一段时间后快速恢复,而不需要像 TCP 那样重新完成三次握手。这可以进一步减少延迟。 总之,HTTP/3 基于 UDP 和 QUIC 协议,在减少延迟,提高网络利用率和连接迅速建立等方面有很大提高,这使得基于 HTTP/3 的应用可以获得很好的性能提升和用户体验。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:7:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"quic QUIC 有以下 3 个特点。 无队头阻塞； 更快的连接建立； 连接迁移； QUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过连接 ID 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了连接迁移的功能。 QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于 UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP包，然后被丢弃。 HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。 Https 区别 HTTP 是明文传输，HTTPS 是密文传输。 HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。 二者端口不一样，80 和 443 端口； https 还需要向 CA 申请证书； 解决的问题 窃听风险； 篡改风险； 冒充风险； 通过 信息加密； 校验机制； 身份证书； 安全保证 混合加密，防止被窃听； 摘要算法，防止被篡改； 数字证书，防止被伪造； 混合加密 在通信建立前采用非对称加密的方式交换会话秘钥，后续就不再使用非对称加密。 在通信过程中全部使用对称加密的会话秘钥的方式加密明文数据。 采用「混合加密」的方式的原因： - 对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。 - 非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。 摘要算法+数字签名 用摘要算法（哈希函数）来计算出内容的哈希值，也就是内容的「指纹」，这个哈希值是唯一的，且无法通过哈希值推导出内容，指纹和内容一起发送给接收方。 对方收到后，先是对内容也计算出一个「指纹」，然后跟发送方发送的「指纹」做一个比较，如果「指纹」相同，说明内容没有被篡改，否则就可以判断出内容被篡改了。 通过哈希算法可以确保内容不会被篡改，但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明。 那为了避免这种情况，计算机里会用非对称加密算法来解决，共有两个密钥： 一个是公钥，这个是可以公开给所有人的； 一个是私钥，这个必须由本人管理，不可泄露。 这两个密钥可以双向加解密的，比如可以用公钥加密内容，然后用私钥解密，也可以用私钥加密内容，公钥解密内容。流程的不同，意味着目的也不相同： 公钥加密，私钥解密。这个目的是为了保证内容传输的安全，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容； 私钥加密，公钥解密。这个目的是为了保证消息不会被冒充，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。 所以非对称加密的用途主要在于通过「私钥加密，公钥解密」的方式，来确认消息的身份，我们常说的数字签名算法，就是用的是这种方式，不过私钥加密内容不是内容本身，而是对内容的哈希值加密。 数字证书 由 CA 签发的证书，通信的时候，不仅会发送签名、公钥，还会发送证书。接收方会去 CA 校验证书的合法性。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:8:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"https 连接建立过程 SSL/TLS 协议基本流程： 客户端向服务器索要并验证服务器的公钥。 双方协商生产「会话秘钥」。 双方采用「会话秘钥」进行加密通信。 前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。 TLS 协议建立的详细流程： 1. ClientHello 首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。 在这一步，客户端主要向服务器发送以下信息： （1）客户端支持的 TLS 协议版本，如 TLS 1.2 版本。 （2）客户端生产的随机数（Client Random），后面用于生成「会话秘钥」条件之一。 （3）客户端支持的密码套件列表，如 RSA 加密算法。 2. SeverHello 服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello。服务器回应的内容有如下内容： （1）确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信。 （2）服务器生产的随机数（Server Random），也是后面用于生产「会话秘钥」条件之一。 （3）确认的密码套件列表，如 RSA 加密算法。 （4）服务器的数字证书。 3.客户端回应 客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。 如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息： （1）一个随机数（pre-master key）。该随机数会被服务器公钥加密。 （2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。 （3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。 上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。 服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。 4. 服务器的最后回应 服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。 然后，向客户端发送最后的信息： （1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。 （2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。 至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。 总结下 TLS 三次握手； 身份验证 + 预生成密钥； 确认会话密钥； 用 HTTP 协议传输加密的数据； TLS 的目的就在于获取那个会话密钥。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:9:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"证书校验 CA 签发证书的过程，如上图左边部分： 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值； 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名； 最后将 Certificate Signature 添加在文件证书上，形成数字证书； 客户端校验服务端的数字证书的过程，如上图右边部分： 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1； 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ； 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。 多级证书 向上溯源到最后的根证书，现校验根证书，再向下一级一级校验。 为何不全由根证书签名 应该是为了分摊风险。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:10:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"HTTPS 如何保证数据的完整性 TLS 在实现上分为握手协议和记录协议两层： TLS 握手协议就是我们前面说的 TLS 四次握手的过程，负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）； TLS 记录协议负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议； TLS 记录协议主要负责消息（HTTP 数据）的压缩，加密及数据的认证。 具体过程如下： 首先，消息被分割成多个较短的片段,然后分别对每个片段进行压缩。 接下来，经过压缩的片段会被加上消息认证码（MAC 值，这个是通过哈希算法生成的），这是为了保证完整性，并进行数据的认证。通过附加消息认证码的 MAC 值，可以识别出篡改。与此同时，为了防止重放攻击，在计算消息认证码时，还加上了片段的编码。 再接下来，经过压缩的片段再加上消息认证码会一起通过对称密码进行加密。 最后，上述经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据。 记录协议完成后，最终的报文数据将传递到传输控制协议 (TCP) 层进行传输。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:11:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"HTTPS 安全吗？ 目前 https 是安全的，除非是用户 client 端，自己接受了中间人的证书。协议自身是安全的。 为何抓包工具可以 很多抓包工具 之所以可以明文看到 HTTPS 数据，工作原理与中间人一致的。 对于 HTTPS 连接来说，中间人要满足以下两点，才能实现真正的明文代理: 中间人，作为客户端与真实服务端建立连接这一步不会有问题，因为服务端不会校验客户端的身份； 中间人，作为服务端与真实客户端建立连接，这里会有客户端信任服务端的问题，也就是服务端必须有对应域名的私钥； 中间人要拿到私钥只能通过如下方式： 去网站服务端拿到私钥； 去CA处拿域名签发私钥； 自己签发证书，切要被浏览器信任； 不用解释，抓包工具只能使用第三种方式取得中间人的身份。 使用抓包工具进行 HTTPS 抓包的时候，需要在客户端安装 Fiddler 的根证书，这里实际上起认证中心（CA）的作用。 抓包工具能够抓包的关键是客户端会往系统受信任的根证书列表中导入抓包工具生成的证书，而这个证书会被浏览器信任，也就是抓包工具给自己创建了一个认证中心 CA，客户端拿着中间人签发的证书去中间人自己的 CA 去认证，当然认为这个证书是有效的。 可靠连接 数据不会损坏； 数据按照顺序传输交付； TCP 可靠性由三个机制保证：1. 序号（TCP 报文的序号）2. 确认（ACK 机制）3. 重传（超时或者冗余的 ACK） TCP ![[Pasted image 20230517204640.png]] 滑动窗口、慢启动 TCP 是面向连接的、可靠的、基于字节流的传输层通信协议。 面向连接：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的； 可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端； 字节流：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:12:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"TCP 和 UDP 的区别联系 连接 TCP 是面向连接的传输层协议，传输数据前先要建立连接。 UDP 是不需要连接，即刻传输数据。 服务对象 TCP 是一对一的两点服务，即一条连接只有两个端点。 UDP 支持一对一、一对多、多对多的交互通信 可靠性 TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。 UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议。 TCP 可靠性由三个机制保证：1. 序号（TCP 报文的序号）2. 确认（ACK 机制）3. 重传（超时或者冗余的 ACK） 拥塞控制、流量控制 TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。 UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。 首部开销 TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。 UDP 首部只有 8 个字节，并且是固定不变的，开销较小。 传输方式 TCP 是流式传输，没有边界，但保证顺序和可靠。 UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。 分片不同 TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。 UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。 https://mp.weixin.qq.com/s/ZMV2izeYkBIqjPhsv_-wdw MTU 最大传输单元（Maximum Transmission Unit，MTU）用来通知对方所能接受数据服务单元的最大尺寸，说明发送方能够接受的有效载荷大小。是包或帧的最大长度，一般以字节记。如果MTU过大，在碰到路由器时会被拒绝转发，因为它不能处理过大的包。MSS的英文全称叫Max Segment Size，是TCP最大段大小。在建立TCP连接的同时，也可以确定发送数据包的单位，我们称为MSS，这个MSS正好是IP中不会被分片处理的最大数据长度。 总结： TCP 是面向连接的、可靠的、有序的、速度慢的协议；UDP 是无连接的、不可靠的、无序的、速度快的协议。 TCP 开销比 UDP 大，TCP 头部需要 20 字节，UDP 头部只要 8 个字节。 TCP 无界有拥塞控制，UDP 有界无拥塞控制。 应用场景的区别 由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于： FTP 文件传输； HTTP / HTTPS； 由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于： 包总量较少的通信，如 DNS 、SNMP 等； 视频、音频等多媒体通信； 广播通信； 为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？ 原因是 TCP 有可变长的「选项」字段，而 UDP 头部长度则是不会变化的，无需多一个字段去记录 UDP 的首部长度。 为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？ 参考链接1 TCP Data的长度= IP总长度 - IP Header长度 - TCP Header长度。 UDP Data的长度= IP总长度 - IP Header长度 - UDP Header长度。 所以 UDP 的长度是多余的。有可能是UDP和IP协议并行发展的结果。或者说，UDP并不是等IP完全占领主导地位之后才开发的协议。 TCP 和 UDP 可以使用同一个端口吗？ 可以的。 在数据链路层中，通过 MAC 地址来寻找局域网中的主机。在网际层中，通过 IP 地址来寻找网络中互连的主机或路由器。在传输层中，需要通过端口进行寻址，来识别同一计算机中同时通信的不同应用程序。 所以，传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。 传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块。 当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP，所以可以根据这个信息确定送给哪个模块（TCP/UDP）处理，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:13:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"建连 简单来说就是，用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 Socket、序列号和窗口大小称为连接。 TCP 四元组可以唯一的确定一个连接，四元组包括如下： 源地址 源端口 目的地址 目的端口 一个服务端在监听一个端口，那它能持有的连接数量？ 因为连接是个四元组，server 的 ip 和端口号已经固定，但是客户端的 ip 以及 端口号是可以变的， 那么数量的公式为 ： 客户端的 ip 数量 * 端口数量； 对 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数，约为 2 的 48 次方。 当然，服务端最大并发 TCP 连接数远不能达到理论上限，会受以下因素影响： 文件描述符限制，每个 TCP 连接都是一个文件，如果文件描述符被占满了，会发生 Too many open files。Linux 对可打开的文件描述符的数量分别作了三个方面的限制： 系统级：当前系统可打开的最大数量，通过 cat /proc/sys/fs/file-max 查看； 用户级：指定用户可打开的最大数量，通过 cat /etc/security/limits.conf 查看； 进程级：单个进程可打开的最大数量，通过 cat /proc/sys/fs/nr_open 查看； 内存限制，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。 建连的过程，以及对应的状态 这个所谓的「连接」，只是双方计算机里维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像这样。 从上图可以看出，前两次握手是不可以携带数据的，第三次是可以携带数据的。第三次握手可以包含数据，通过 TCP 快速打开（TFO）技术。其实只要涉及到握手的协议，都可以使用类似 TFO 的方式，客户端和服务端存储相同 cookie，下次握手时发出 cookie 达到减少 RTT 的目的。 握手是三次的原因 三次握手的目的：同步 Sequence 序列号；交换 TCP 通讯参数，比如 MSS、窗口比例因子、选择性确认、指定校验和算法等。 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号； 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。 三次握手才能保证双方具有接收和发送的能力。体现在以下几个方面。 【最重要的原因】防止历史连接触发初始化造成混乱； 我们考虑一个场景，客户端先发送了 SYN（seq = 90）报文，然后客户端宕机了，而且这个 SYN 报文还被网络阻塞了，服务端并没有收到，接着客户端重启后，又重新向服务端建立连接，发送了 SYN（seq = 100）报文（注意！不是重传 SYN，重传的 SYN 的序列号是一样的）。 在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费。 三次握手为何可以解决这个问题？客户端连续发送多次 SYN（都是同一个四元组）建立连接的报文，在网络拥堵情况下： 一个「旧 SYN 报文」比「最新的 SYN」 报文早到达了服务端，那么此时服务端就会回一个 SYN + ACK 报文给客户端，此报文中的确认号是 91（90+1）。 客户端收到后，发现自己期望收到的确认号应该是 100 + 1，而不是 90 + 1，于是就会回 RST 报文。 服务端收到 RST 报文后，就会释放连接。 后续最新的 SYN 抵达了服务端后，客户端与服务端就可以正常的完成三次握手了。 同步双方初始序列号 TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用： 接收方可以去除重复的数据； 接收方可以根据数据包的序列号按序接收； 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）； 可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样一来一回，才能确保双方的初始序列号能被可靠的同步。 避免资源浪费 如果只有「两次握手」，当客户端发生的 SYN 报文在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN ，由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 ACK 报文，所以服务端每收到一个 SYN 就只能先主动建立一个连接，这会造成什么情况呢？如果客户端发送的 SYN 报文在网络中阻塞了，重复发送多次 SYN 报文，那么服务端在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。 为何要求初始化的序列号都不一样 起始 ISN 是基于时钟的，每 4 微秒 + 1，转一圈要 4.55 个小时。 RFC793 提到初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。 M 是一个计时器，这个计时器每隔 4 微秒加 1。 F 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证 Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择。 可以看到，随机数是会基于时钟计时器递增的，基本不可能会随机成一样的初始化序列号。 【主要原因】为了防止历史报文被下一个相同四元组的连接接收； 客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，然后超时重传了这个数据包，而此时服务端设备断电重启了，之前与客户端建立的连接就消失了，于是在收到客户端的数据包的时候就会发送 RST 报文。 紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接； 在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。 如果每次建立连接客户端和服务端的初始化序列号都「不一样」，就有大概率因为历史报文的序列号「不在」对方接收窗口，从而很大程度上避免了历史报文。 所以，每次初始化序列号不一样很大程度上能够避免历史报文被下一个相同四元组的连接接收，注意是很大程度上，并不是完全避免了（因为序列号会有回绕的问题，所以需要用时间戳的机制来判断历史报文） 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收； 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？ MTU：一个网络包的最大长度，以太网中一般为 1500 字节； MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度； 如果没有 MSS，则交由 ip 层进行分片处理，则效率很低丢包后，重传都是以 IP 包（MTU）为维度进行重传； 当 IP 层有一个超过 MTU 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。 反之，丢包后，重传的维度是以 TCP 包，MSS 大小为维度的； 经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。 第一次握手丢失了，会发生什么？ 在 Linux 里，客户端的 SYN 报文最大重传次数由 tcp_syn_retries内核参数控制，这个参数是可以自定义的，默认值一般是 5。 当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就不再发送 SYN 包，然后断开 TCP 连接。 第二次握手丢失了，会发生什么？ 第二次握手的 SYN-ACK 报文其实有两个目的 ： 第二次握手里的 ACK， 是对第一次握手的确认报文； 第二次握手里的 SYN，是服务端发起建立 TCP 连接的报文； 当第二次握手丢失了，客户端和服务端都会重传： 客户端会重传 SYN 报文，也就是第一次握手，最大重传次数由 tcp_syn_retries内核参数决定； 服务端会重传 SYN-ACK 报文，也就是第二次握手，最大重传次数由 tcp_synack_retries 内核参数决定。 具体过程： 当客户端超时重传 1 次 SYN 报文后，由于 tcp_syn_retries 为 1，已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到服务端的第二次握手（SYN-ACK 报文），那么客户端就会断开连接。 当服务端超时重传 2 次 SYN-ACK 报文后，由于 tcp_synack_retries 为 2，已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第三次握手（ACK 报文），那么服务端就会断开连接。 第三次握手丢失了，会发生什么？ 客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 ESTABLISH 状态。 注意，ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文。 具体过","date":"2022-05-17","objectID":"/2022/05/net-process/:14:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"断连 客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSE_WAIT 状态。 客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。 客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态 服务端收到了 ACK 应答报文后，就进入了 CLOSE 状态，至此服务端已经完成连接的关闭。 客户端在经过 2MSL 一段时间后，自动进入 CLOSE 状态，至此客户端也完成连接的关闭。 你可以看到，每个方向都需要一个 FIN 和一个 ACK，因此通常被称为四次挥手。 这里一点需要注意是：主动关闭连接的，才有 TIME_WAIT 状态。 为什么需要四次 因为 TCP 是全双工的，两个方向的关闭是独立确认的； 再来回顾下四次挥手双方发 FIN 包的过程，就能理解为什么需要四次了。 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。 服务端收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。 从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，因此是需要四次挥手。 第一次挥手丢失了，会发生什么 当客户端（主动关闭方）调用 close 函数后，就会向服务端发送 FIN 报文，试图与服务端断开连接，此时客户端的连接进入到 FIN_WAIT_1 状态。 正常情况下，如果能及时收到服务端（被动关闭方）的 ACK，则会很快变为 FIN_WAIT2状态。 如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，重传 FIN 报文，重发次数由 tcp_orphan_retries 参数控制。 当客户端重传 FIN 报文的次数超过 tcp_orphan_retries 后，就不再发送 FIN 报文，则会在等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到第二次挥手，那么直接进入到 close 状态。 第二次挥手丢失了，会发生什么？ ACK 报文是不会重传的，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。 当客户端超时重传 2 次 FIN 报文后，由于 tcp_orphan_retries 为 2，已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到服务端的第二次挥手（ACK 报文），那么客户端就会断开连接。 这个过程和丢失一次的挥手的效果基本类似。 第三次挥手丢失了，会发生什么？ 具体过程： 当服务端重传第三次挥手报文的次数达到了 3 次后，由于 tcp_orphan_retries 为 3，达到了重传最大次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第四次挥手（ACK报文），那么服务端就会断开连接。 客户端因为是通过 close 函数关闭连接的，处于 FIN_WAIT_2 状态是有时长限制的，如果 tcp_fin_timeout 时间内还是没能收到服务端的第三次挥手（FIN 报文），那么客户端就会断开连接。 第四次挥手丢失，会发生什么？ 重点在于，time-wait 的计时器会被重置，time wait 的时间会被延长。 当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 TIME_WAIT 状态。 在 Linux 系统，TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态。 如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制。 具体过程： 当服务端重传第三次挥手报文达到 2 时，由于 tcp_orphan_retries 为 2， 达到了最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第四次挥手（ACK 报文），那么服务端就会断开连接。 客户端在收到第三次挥手后，就会进入 TIME_WAIT 状态，开启时长为 2MSL 的定时器，如果途中再次收到第三次挥手（FIN 报文）后，就会重置定时器，当等待 2MSL 时长后，客户端就会断开连接。 为什么需要 time-wait 状态 存在TIME_WAIT状态有两个理由: 实现终止TCP全双工连接的可靠性； 假设最终的ACK丢丢失,服务器将重发最终的FIN,因此客户必须维护状态信息以允许它重发最终的ACK。如果不维护状态信息,它将响应以 RST(另外一个类型的TCP分节),而服务器则把该分节解释成一个错误。如果TCP打算执行所有必要的工作以彻底终止某个连接上两个方向的数据流(即全双工关闭),那么它必须正确处理连接终止序列四个分节中任何一个分节的丢失情况。本例子也说明执行主动关闭的一端为何进入TIME_WAIT状态.因为它可能不得不重发最终的ACK。 允许老的重复分节在网络中消逝； 要理解存在TIME_WAIT状态的第二个理由,我们假设206.62.226.33端口1500和 198.69.10.2端口21之间有一个TCP连接。我们关闭这个连接后,在以后某个时候又重新建立起相同的IP地址和端口之间的TCP连接。后一个连接称为前一个连接的化身(incar-nation),因为它们的IP地址和端口号都相同。TCP必须防止来自某个连接的老重复分组在连接终止后再现,从而被误解成属于同一连接的化身。要实现这种功能,TCP不能给处于TIME_WAIT状态的连接启动新的化身。既然TIME_WAIT状态的持续时间是2MLS,这就足够让某个方向上的分组最多存活MSL秒即被丢弃,另一个方向上的应答最多存活MSL秒也被丢弃。通过实施这个规则,我们就能保证当成功建立一个TCP连接时,来自该连接先前化身的老重复分组都已在网络中消逝。 过多 time-wait 的危害 第一是占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等； 第二是占用端口资源，端口资源也是有限的，一般可以开启的端口为 32768～61000，也可以通过 net.ipv4.ip_local_port_range参数指定范围。 大量 TIME_WAIT 状态的原因有哪些？ 第一个场景：HTTP 没有使用长连接； 第二个场景：HTTP 长连接超时； 第三个场景：HTTP 长连接的请求数量达到上限； 为什么 time_wait 状态为何是 2msl 参考链接1 等待 2MSL 的真正目的是为了避免前后两个使用相同四元组的连接中的前一个连接的报文干扰后一个连接，换句话说，就是为了让此次 TCP 连接中的所有报文在网络中消失。 假如现在 A 发送 ACK 后，最坏情况下，这个 ACK 在 1MSL 时到达 B；此时 B 在收到这个 ACK 的前一刹那，一直在重传 FIN，这个 FIN 最坏会在 1MSL 时间内消失。因此从 A 发送 ACK 的那一刹那开始，等待 2MSL 可以保证 A 发送的最后一个 ACK，和 B 发送的最后一个 FIN 都在网络中消失 这样可以保证 fin 不会造成对后续的新的四元组的数据伤害。 服务器出现大量 CLOSE_WAIT 状态的原因有哪些？ 我们先来分析一个普通的 TCP 服务端的流程： 创建服务端 socket，bind 绑定端口、listen 监听端口 将服务端 socket 注册到 epoll epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket 将已连接的 socket 注册到 epoll epoll_wait 等待事件发生 对方连接关闭时，我方调用 close 第一个原因：第 2 步没有做，没有将服务端 socket 注册到 epoll，这样有新连接到来时，服务端没办法感知这个事件，也就无法获取到已连接的 socket，那服务端自然就没机会对 socket 调用 close 函数了。 第二个原因：第 3 步没有做，有新连接到来时没有调用 accpet 获取该连接的 socket，导致当有大量的客户端主动断开了连接，而服务端没机会对这些 socket 调用 close 函数，从而导致服务端出现大量 CLOSE_WAIT 状态的连接。 第三个原因：第 4 步没有做，通过 accpet 获取已连接的 socket 后，没有将其注册到 epoll，导致后续收到 FIN 报文的时候，服务端没办法感知这个事件，那服务端就没机会调用 close 函数了。 第四个原因：第 6 步没有做，当发现客户端关闭连接后，服务端没有执行 close 函数，可能是因为代码漏处理，或者是在执行 close 函数之前，代码卡在某一个逻辑，比如发生死锁等等。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:15:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"TCP 保活机制 如果已经建立了连接，但是客户端突然出现故障了怎么办？ 客户端出现故障指的是客户端的主机发生了宕机，或者断电的场景。发生这种情况的时候，如果服务端一直不会发送数据给客户端，那么服务端是永远无法感知到客户端宕机这个事件的，也就是服务端的 TCP 连接将一直处于 ESTABLISH 状态，占用着系统资源。 为了避免这种情况，TCP 搞了个保活机制。这个机制的原理是这样的： 定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。 在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值： net.ipv4.tcp_keepalive_time=7200 net.ipv4.tcp_keepalive_intvl=75 net.ipv4.tcp_keepalive_probes=9 tcp_keepalive_time=7200：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制 tcp_keepalive_intvl=75：表示每次检测间隔 75 秒； tcp_keepalive_probes=9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。 也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。 如果已经建立了连接，但是服务端的进程崩溃会发生什么？ TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:16:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"重传机制 常见的重传机制： 超时重传 快速重传 SACK D-SACK ","date":"2022-05-17","objectID":"/2022/05/net-process/:17:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"超时重传 需要超时重传的情况 数据包丢失； 确认的应答丢失； 几个专业术语 RTT 发送信号所花费的时间加上确认已接收该信号所花费的时间，也就是包的往返时间。 RTO - Retransmission TimeOut 称为重传的超时时间。 RTO 的选择 RTO 较大时，重发变慢，效率低，性能差； RTO 较小时，重发很快，频率很高，网络拥塞，浪费带宽，效率低； 理想的 RTO：比 RTT 略大；但是 RTT 是经常波动的，是一个动态变化的值； 如果产生超时重传，TCP 会将 RTO 加倍。 存在的问题 和时间相关，超时的周期可能相对较长。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:17:1","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"快速重传：摆脱时间因素 快速重传（Fast Retransmit）机制，它不以时间为驱动，而是以数据驱动重传。 快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。 存在的问题 快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是重传的时候，是重传之前的一个，还是重传所有的问题。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:17:2","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"SACK：selective acknowledge 这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它可以将缓存的地图发送给发送方，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。 如果要支持 SACK，必须双方都要支持。在 Linux 下，可以通过 net.ipv4.tcp_sack 参数打开这个功能（Linux 2.4 后默认打开）。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:17:3","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"DSACK Duplicate SACK 又称 D-SACK，其主要使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。 两个很像 ack 大于 sack：有重复的包被发送； ack 小于 sack：有丢失的包； ","date":"2022-05-17","objectID":"/2022/05/net-process/:17:4","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"滑动窗口 为什么引入 如果以数据包为维度进行发送和确认应答，那么效率会很低，RTT 越长，效率越低。 故而 TCP 引入了窗口的概念。 窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。 如何生效：累计确认 图中的 ACK 600 确认应答报文丢失，也没关系，因为可以通话下一个确认应答进行确认，只要发送方收到了 ACK 700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫累计确认或者累计应答。 窗口大小 那么有了窗口，就可以指定窗口大小，窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值。所以，通常窗口的大小是由接收方的决定的。 TCP 头里有一个字段叫 Window，也就是窗口大小。这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。 发送方的滑动窗口 当收到 32-45 中的 ack，则滑动窗口向右移动对应大小的窗口距离。 发送方程序中的窗口 SND.WND：表示发送窗口的大小（大小是由接收方指定的）； SND.UNA：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一个字节。 SND.NXT：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个字节。 指向 #4 的第一个字节是个相对指针，它需要 SND.UNA 指针加上 SND.WND 大小的偏移量，就可以指向 #4 的第一个字节了。 那么可用窗口大小的计算就可以是：可用窗口大 = SND.WND -（SND.NXT - SND.UNA） 接收方的滑动窗口 这部分的内容存疑，涉及累计确认信息。个人认为这里合理的说法应该是累计确认的窗口。 ![[Pasted image 20230412193237.png]] 关于窗口滑动的几个术语 称窗口左边沿向右边沿靠近为窗口合拢。这种现象发生在数据被发送和确认时。 当窗口右边沿向右移动时将允许发送更多的数据，我们称之为窗口张开。这种现象发 生在另一端的接收进程读取已经确认的数据并释放了 T C P 的接收缓存时。 当右边沿向左移动时，我们称之为窗口收缩。 Host Requirements RFC强烈建议不要使 用这种方式。但 T C P 必须能够在某一端产生这种情况时进行处理。第 2 2 . 3 节 给 出 了 这 样 的 一 个 例子，一端希望向左移动右边沿来收缩窗口，但没能够这样做。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:18:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"拥塞控制 参考连接1 TCP 还会做拥塞控制，对于真正的通路堵车不堵车，它无能为力，唯一能做的就是控制自己，也即控制发送的速度。不能改变世界，就改变自己嘛。 为什么需要 在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大…. 前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。流量控制是控制的量，拥塞控制，是控制的速度。 所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。 控制的目的就是避免「发送方」的数据填满整个网络。 拥塞窗口？ 拥塞窗口 cwnd 是发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的，用以调节发送方要发送的量。 拥塞窗口与发送窗口的关系 由于入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。 拥塞窗口 cwnd 变化的规则： 只要网络中没有出现拥塞，cwnd 就会增大； 但网络中出现了拥塞，cwnd 就减少 如何识别拥塞 其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是发生了超时重传，就会认为网络出现了用拥塞。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:19:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"慢启动 TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？ 慢启动的算法记住一个规则就行：当发送方每收到一个 ACK，就拥塞窗口 cwnd 的大小就会加 1。 虽然叫慢启动，但是发包的个数是指数性地增长。 慢启动门限 ssthresh 当 cwnd \u003c ssthresh 时，使用慢启动算法。 当 cwnd \u003e= ssthresh 时，就会使用「拥塞避免算法」 一般来说 ssthresh 的大小是 65535 字节。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:19:1","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"拥塞避免 那么进入拥塞避免算法后，它的规则是：每当收到一个 ACK 时，cwnd 增加 1/cwnd。 拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:19:2","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"发生拥塞如何是好? 拥塞窗口一直增长的话，下个阶段就可能触发拥塞，出现丢包现象，这时候就会进行数据包的重传。 重传的机制有两个 超时重传； 快速重传； 拥塞发生算法 - 超时重传对应的算法 sshresh 和 cwnd 的值会发生变化： ssthresh 设为 cwnd/2 ； cwnd 重置为 1 ； 接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。 快速恢复算法 - 快速重传对应的算法 TCP 认为你还能收到 3 个重复 ACK 说明网络也不那么糟糕，这种情况不严重，因为大部分没丢，只丢了一小部分，所以没有必要像 RTO 超时那么强烈，则 ssthresh 和 cwnd 变化如下： cwnd = cwnd/2 ，也就是设置为原来的一半; ssthresh = cwnd; 快速重传和快速恢复算法一般同时使用。 也就是没有像「超时重传」一夜回到解放前，而是还在比较高的值，后续呈线性增长。 从当前的一半位置开始线性增长尝试，但是最高不超过当前拥塞的状态。 ","date":"2022-05-17","objectID":"/2022/05/net-process/:19:3","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"流量控制 TCP 要做流量控制，通信双方各声明一个窗口（缓存大小），标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。 如果无脑发送数据，接收方处理不及时，就会触发重传机制，浪费带宽，降低效率，同时性能也降低。 TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。 系统缓冲区和滑动窗口的关系 两个例子 系统的缓存大小决定了发送和接收窗口的大小； 为了防止减少缓存和收缩窗口同时进行造成的丢包问题，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间在减少缓存，这样就可以避免了丢包情况。 窗口关闭 如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。 接收方向发送方通告窗口大小时，是通过 ACK 报文来通告的。 当窗口关闭后，接收方一直不发送 ack，更新滑动窗口，将出现死锁现象。 为了解决这个问题，TCP 为每个连接设有一个持续定时器，只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。如果持续计时器超时，就会发送窗口探测 ( Window probe ) 报文，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。 窗口探查探测的次数一般为 3 此次，每次次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 RST 报文来中断连接。 糊涂窗口综合症 如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。 当发送程序缓慢地生产数据，接收程序缓慢地消耗数据，或者两者同时存在时，滑动窗口运作会出现严重问题。 处理每个数据包都存在一定量的开销，数据包数增加会增加网络通信的开销，可能使数据处理量进一步减少。最终的结果就是抖动。 要解决糊涂窗口综合症 让接收方不通告小窗口给发送方； 让发送方避免发送小数据； 怎么让接收方不通告小窗口呢？ 当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 0，也就阻止了发送方再发数据过来。 怎么让发送方避免发送小数据呢？ 使用 Nagle 算法，该算法的思路是延时处理，它满足以下两个条件中的一条才可以发送数据： 要等到窗口大小 \u003e= MSS 或是 数据大小 \u003e= MSS； 收到之前发送数据的 ack 回包 只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。 另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。 可以在 Socket 设置 TCP_NODELAY 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭） ","date":"2022-05-17","objectID":"/2022/05/net-process/:20:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"TCP socket 编程 服务端和客户端初始化 socket，得到文件描述符； 服务端调用 bind，将 socket 绑定在指定的 IP 地址和端口; 服务端调用 listen，进行监听； 服务端调用 accept，等待客户端连接； 客户端调用 connect，向服务端的地址和端口发起连接请求； 服务端 accept 返回用于传输的 socket 的文件描述符； 客户端调用 write 写入数据；服务端调用 read 读取数据； 客户端断开连接时，会调用 close，那么服务端 read 读取数据的时候，就会读取到了 EOF，待处理完数据后，服务端调用 close，表示连接关闭。 这里需要注意的是，服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。 所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作监听 socket，一个叫作已完成连接 socket。 成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。 listen 时候参数 backlog 的意义？ Linux内核中会维护两个队列： 半连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态； 全连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 ESTABLISHED 状态； accept 发生在三次握手的哪一步？ 客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。 客户端调用 close 了，连接是断开的流程是什么？ 客户端调用 close，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1 状态； 服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，应用程序可以通过 read 调用来感知这个 FIN 包。这个 EOF 会被放在已排队等候的其他已接收的数据之后，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态； 接着，当处理完数据后，自然就会读到 EOF，于是也调用 close 关闭它的套接字，这会使得服务端发出一个 FIN 包，之后处于 LAST_ACK 状态； 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态； 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态； 客户端经过 2MSL 时间之后，也进入 CLOSE 状态； ","date":"2022-05-17","objectID":"/2022/05/net-process/:21:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Network"],"content":"Google BBR 这一节的内容是来自于 chatGPT 和 new bing 的问答； BBR算法的核心原理是根据网络的带宽、RTT（Round Trip Time，往返延迟时间）等特性，不断地调整发送数据包的速率和数量，以达到最佳的网络性能。具体来说，BBR算法的实现包括以下几个关键步骤： 测量网络带宽：BBR算法通过发送一系列数据包，并测量其发送时间和到达时间，计算出当前网络的带宽情况。 测量网络延迟：BBR算法通过测量数据包往返的时间，计算出当前网络的RTT。 确定发送速率：根据当前的带宽和延迟情况，BBR算法会自动调整数据包的发送速率和数量，以达到最佳的网络性能。 动态调整拥塞窗口：BBR算法通过动态调整拥塞窗口大小，以确保网络的带宽和延迟在最佳状态下。 Google BBR（Bottleneck Bandwidth and Round-trip propagation time）是一种新型的拥塞控制算法，与传统的拥塞控制和流量控制有以下改进的点： 更精确的拥塞控制：传统的拥塞控制算法主要依赖于丢包来判断网络拥塞情况，而BBR则通过估算网络带宽和RTT来动态调整发送窗口大小，从而更准确地控制网络拥塞。 更高的网络利用率：传统的拥塞控制算法通常会导致网络利用率不足，而BBR则通过更准确的拥塞控制，能够更有效地利用网络带宽，从而提高网络吞吐量和响应速度。 更好的抗拥塞能力：BBR通过对网络拥塞的精确控制，能够在网络拥塞时自适应地减小发送速率，从而避免网络拥塞恶化。 更低的延迟和抖动：BBR通过准确地测量RTT和带宽，能够更精确地控制数据包的发送时间，从而减少网络延迟和抖动。 总之，BBR相较于传统的拥塞控制和流量控制，能够更准确地控制网络拥塞，更高效地利用网络带宽，具有更好的抗拥塞能力和更低的网络延迟和抖动。 缺点 对于某些网络环境不适用：BBR算法主要适用于高速长距离网络，对于较短距离、低速网络，BBR算法可能不如其他算法表现优秀。 对于UDP流量不友好：BBR算法主要针对TCP流量进行优化，对于UDP流量，BBR算法可能会表现不如其他算法。 可能引起其他TCP流量拥塞：在某些情况下，BBR算法可能会过于占用网络带宽，导致其他TCP流量拥塞，从而影响整个网络的性能。 需要更高的CPU计算能力：BBR算法的实现需要更高的CPU计算能力，因此在某些设备上可能会导致性能下降或延迟增加。 适用场景 Google BBR算法主要适用于高速、长距离网络环境，例如数据中心、云计算、视频直播等网络场景。在这些场景中，网络拥塞控制是一个非常关键的问题，因为网络拥塞会导致丢包、延迟增加、吞吐量下降等问题，从而影响网络的性能和用户体验。 BBR算法具有以下几个适用场景： 高速数据中心网络：BBR算法可以有效地处理高速数据中心网络中的流量拥塞，提高网络的吞吐量和用户体验。 云计算环境：BBR算法可以应用于云计算环境中的虚拟机、容器等网络通信中，提高网络性能和稳定性。 视频直播场景：BBR算法可以应用于视频直播场景中，通过提高视频传输的速率和降低延迟，提高观看体验。 远程办公场景：在远程办公场景中，BBR算法可以优化视频会议、文件传输等网络通信，提高网络性能和稳定性，从而提高工作效率。 总体来说，Google BBR算法适用于高速、长距离网络环境，特别是在对网络性能和用户体验有较高要求的场景中，可以发挥出其优秀的拥塞控制和带宽利用效果。 子网掩码 子网掩码是一个32位的2进制数， 其对应网络地址的所有位都置为1，对应于主机地址的所有位置都为0。子网掩码告知路由器，地址的哪一部分是网络地址，哪一部分是主机地址，使路由器正确判断任意IP地址是否是本网段的，从而正确地进行路由。子网掩码由1和0组成，且1和0分别连续。 将子网掩码和 IP 地址按位计算 AND，就可得到网络号。如果网络地址相同，表明接受方在本网络上，那么可以把数据包直接发送到目标主机。路由器寻址工作中，也就是通过这样的方式来找到对应的网络号的，进而把数据包转发给对应的网络内。 划分子网，数量是 2 的子网位数 减去 2，这 2 指的是，全 1 的广播地址和全 0 的网络地址； 广播地址 广播是一种同时向网络上的所有设备发送消息的方法。 广播地址是一个特殊地址，用于向给定网段上的所有设备发送消息。 适用的场景 发现：当新设备加入网络时，它可以发送广播消息来宣布它的存在。 然后网络上的所有其他设备都可以收到此消息并采取适当的措施。 配置：在某些情况下，可能需要使用特定设置或参数配置网络上的所有设备。 通过发送广播消息，可以快速轻松地将此配置分发到网络上的所有设备。 故障排除：当网络出现问题时，向所有设备发送广播消息以确定问题的根本原因可能很有用。 给定 ip 和 子网掩码，如何确定广播地址 确认几类地址，比如 C 类地址，前24 位是网路号，后 8 位是主机号； 然后将 ip 地址与子网掩码进行与操作，可以获知主机号中挪用几位作为子网号； 子网号进行组合，每个组合中主机号全部位 1 的就是广播地址； IPV6 IPv4 的地址是 32 位的，大约可以提供 42 亿个地址，但是早在 2011 年 IPv4 地址就已经被分配完了。 但是 IPv6 的地址是 128 位的，这可分配的地址数量是大的惊人，说个段子 IPv6 可以保证地球上的每粒沙子都能被分配到一个 IP 地址。 但 IPv6 除了有更多的地址之外，还有更好的安全性和扩展性，说简单点就是 IPv6 相比于 IPv4 能带来更好的网络体验。 但是因为 IPv4 和 IPv6 不能相互兼容，所以不但要我们电脑、手机之类的设备支持，还需要网络运营商对现有的设备进行升级，所以这可能是 IPv6 普及率比较慢的一个原因。 Pv6 相比 IPv4 的首部改进： 取消了首部校验和字段。 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。 取消了分片/重新组装相关字段。 分片与重组是耗时的过程，IPv6 不允许在中间路由器进行分片与重组，这种操作只能在源与目标主机，这将大大提高了路由器转发的速度。 取消选项字段。 选项字段不再是标准 IP 首部的一部分了，但它并没有消失，而是可能出现在 IPv6 首部中的「下一个首部」指出的位置上。删除该选项字段使的 IPv6 的首部成为固定长度的 40 字节。 ICMP ICMP 全称是 Internet Control Message Protocol，也就是互联网控制报文协议。 ICMP 主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。 在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址，那么这个具体的原因将由 ICMP 负责通知。 BGP BGP BGP协议的核心就是通过BGP对等关系不断地交换路由信息,选择和传播最佳路径,从而实现网络之间的互联互通。这是Internet能够稳定运行的基石。 BGP 的过程 BGP 路由器之间建立BGP对等关系(BGP Peering),用于交换路由信息。 每个BGP路由器都有一个独立的自治系统号(AS Number),用于标识自己所在的网络。 BGP路由器会定期向对等路由器发送自己的路由表信息,这些信息包含了该路由器可以到达的网络和子网。 BGP路由器在接收到对等路由器发送的路由信息后,会根据路由选择算法选择一条最佳路径,并把这条路径信息记录到自己的路由表中。 BGP会定期检查路由表,如果最佳路径发生变化,就会立即传播更新信息给所有的对等路由器。 BGP可以支持不同AS之间进行路由传播,所以BGP可以实现Internet这样庞大复杂网络的互联互通。 BGP还支持各种路由策略,如设置本地优先级、过滤某个对等方的路由等,这使得网络管理员可以很灵活地控制路由选择和路由传播。 跨域问题 summary 浏览器为了保护数据安全而采用的一种称为“同源策略”的机制，当跨域进行网络请时，浏览器将会进行拦截； 解决方法，分为客户端和服务端两种，一种server全部放行；二是客户端请求，服务端根据 header 中设置的 domain 进行个性化处理； 定义，什么是跨域问题 跨域问题产生的原因是浏览器的同源策略。所谓\"同源\"指的是\"协议+域名+端口\"三者相同。 同源策略的目的是为了保证用户信息的安全,防止恶意的网站获取该信息。同源策略规定,A 网站中的 JavaScript 脚本,只能获得同域名的 Cookie、DOM 和 AJAX 信息。 当从一个源加载的文档或脚本试图与另一个源交互时,就会产生跨域问题。例如,当从源 A 的网页试图使用 XMLHttpRequest 向源 B 的服务器发送请求,该请求会被 browsers 拒绝。 解决方案 CORS(跨域资源共享)。这是最简单的方式,只需要在服务端设置 Access-Control-Allow-Origin 就可以了。 Header set Access-Control-Allow-Origin \"*\" JSONP。通过\u003cscript\u003e\\ 标签 src 属性请求一个 JSONP 接口,此接口会返回一个函数调用,并传入数据作为参数。 \u003cscript src=\"http://example.com/api?callback=func\"\u003e\u003c/script\u003e func({ name: \"John\" }); 代理。在同源服务器上设置一个代理,转发跨域请求。 var proxy = require('http-proxy-middleware'); app.use('/api","date":"2022-05-17","objectID":"/2022/05/net-process/:22:0","tags":["TCP","Http","Net"],"title":"一张思维导图看网络【持续迭代】","uri":"/2022/05/net-process/"},{"categories":["Android"],"content":"概述 总结自己的 Android 知识，按照编码 -\u003e 运行，画了一张图，xmind 导出的图比较大，后续持续更新，迭代这部分的内容。 下面是一些常见的知识,将会慢慢补充进思维导图内 Handler 与 Binder handler 处理的是 App 进程内的通信； binder 处理的是，App 进程间、application 和 framework 之间的通信； 任务启动管理 - 启动框架 抽象任务 task； 优先级 ； countdownlatch 数值为依赖 task 的数量； 运行的 executor ； 被依赖的 task 列表； toWait 方法； notify 方法，countdownlatch 减一； 构造 task 的有向无环图； TaskManager： 管理所有的 task，及其拓扑关系； 管理需要执行的 task； countdownlatch 值为 Activity 跳转的生命周期 ActivityA跳转到ActivityB： Activity A：onPause Activity B：onCreate Activity B：onStart Activity B：onResume Activity A：onStop ActivityB返回ActivityA： Activity B：onPause Activity A：onRestart Activity A：onStart Activity A：onResume Activity B：onStop Activity B：onDestroy ","date":"2022-04-03","objectID":"/2022/04/android_summary/:0:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"旋转屏幕 不改配置，默认配置 onPause--\u003e onStop--\u003e onDestroy--\u003e onCreate--\u003e onStart--\u003e onRestoreInstanceState--\u003e onResume--\u003e 修改配置 onConfigChanged--\u003e Activity 的启动模式 参考链接1 仅仅适用于Activity启动Activity，并且采用的都是默认Intent，没有额外添加任何Flag standard：标准启动模式（默认启动模式），每次都会启动一个新的activity实例。 singleTop：单独使用使用这种模式时，如果Activity实例位于当前任务栈顶，就重用栈顶实例，而不新建，并回调该实例onNewIntent()方法，否则走新建流程。 singleTask：这种模式启动的Activity只会存在相应的Activity的taskAffinit任务栈中，同一时刻系统中只会存在一个实例，已存在的实例被再次启动时，会重新唤起该实例，并清理当前Task任务栈该实例之上的所有Activity，同时回调onNewIntent()方法。 singleInstance：这种模式启动的Activity独自占用一个Task任务栈，同一时刻系统中只会存在一个实例，已存在的实例被再次启动时，只会唤起原实例，并回调onNewIntent()方法。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:1:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"Intent.FLAG_ACTIVITY_NEW_TASK分析 当我们用ApplicationContext去启动standard模式的Activity会报错，这是因为standard模式的Activity默认会进入启动它的Activity所属的任务栈中，但是由于非Activity类型的Context(如ApplicationContext)并没有所谓的任务栈，这就是问题所在。解决这个问题的方法是为待启动Activity指定FLAG_ACTIVITY_NEW_TASK标记位，这样启动的时候就会为它创建一个新的任务栈，如果设置待启动的Activity的taskAffinity时，这个时候待启动Activity实际上是以singleTask模式启动的。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:2:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"FLAG_ACTIVITY_SINGLE_TOP 为Activity指定singleTop启动模式，效果和在xml中指定该模式相同。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:3:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"FLAG_ACTIVITY_CLEAR_TOP 具有此标记的Activity，当它启动时，在同一个任务栈中所有位于它上面的Activity都要出栈。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:4:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"FLAG_ACTIVITY_CLEAR_TASK FLAG_ACTIVITY_CLEAR_TASK只能和FLAG_ACTIVITY_NEW_TASK配合使用哦 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:5:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"FLAG_ACTIVITY_EXCLUDE_FROM_RECENTS 具有这个标记的Activity不会出现在历史Activity的列表中，在某些情况下我们不希望用户通过历史列表回到我们的Activity的时候这个标记比较有用。它等同于在xml中指定Activity的属性android``:excludeFromRecents=\"true\" Activity 的启动流程 参考链接1 点击应用图标后会去启动应用的Launcher Activity，如果Launcer Activity所在的进程没有创建，还会创建新进程，整体的流程就是一个Activity的启动流程。 Instrumentation: 监控应用与系统相关的交互行为。 AMS：组件管理调度中心，什么都不干，但是什么都管。 ActivityStarter：Activity启动的控制器，处理Intent与Flag对Activity启动的影响，具体说来有： 1 寻找符合启动条件的Activity，如果有多个，让用户选择； 2 校验启动参数的合法性； 3 返回int参数，代表Activity是否启动成功。 ActivityStackSupervisior：这个类的作用你从它的名字就可以看出来，它用来管理任务栈。 ActivityStack：用来管理任务栈里的Activity。 ActivityThread：最终干活的人，Activity、Service、BroadcastReceiver的启动、切换、调度等各种操作都在这个类里完成。 注：这里单独提一下ActivityStackSupervisior，这是高版本才有的类，它用来管理多个ActivityStack，早期的版本只有一个ActivityStack对应着手机屏幕，后来高版本支持多屏以后，就有了多个ActivityStack，于是就引入了ActivityStackSupervisior用来管理多个ActivityStack。 有了以上的理解，整个流程可以概括如下： 1、点击桌面应用图标，Launcher 进程将启动 Activity（MainActivity）的请求以 Binder 的方式发送给了 AMS。 2、AMS 接收到启动请求后，交付 ActivityStarter 处理 Intent 和 Flag 等信息，然后再交给 ActivityStackSupervisior/ActivityStack 处理 Activity 进栈相关流程。同时以 Socket 方式请求 Zygote 进程 fork 新进程。 3、Zygote 接收到新进程创建请求后 fork 出新进程。 4、在新进程里创建 ActivityThread 对象，新创建的进程就是应用的主线程，在主线程里开启 Looper 消息循环，开始处理创建 Activity。 5、ActivityThread 利用 ClassLoader 去加载 Activity、创建 Activity 实例，并回调 Activity 的 onCreate() 方法，这样便完成了Activity 的启动。 从开发层面来看，启动另一个 activity 通常会使用 context.startActivity()，最终去到Instrumentation 的 execStartActivitiesAsUser 方法中。 int result = ActivityManagerNative.getDefault() .startActivities(whoThread, who.getBasePackageName(), intents, resolvedTypes,token, options, userId); ActivityManagerNative 获取 AMS 进程代理，进而告知 AMS 将要启动另一个 activity。 static public IActivityManager getDefault() { return gDefault.get(); } private static final Singleton\u003cIActivityManager\u003e gDefault = new Singleton\u003cIActivityManager\u003e() { protected IActivityManager create() { IBinder b = ServiceManager.getService(\"activity\"); if (false) { Log.v(\"ActivityManager\", \"default service binder = \" + b); } IActivityManager am = asInterface(b); if (false) { Log.v(\"ActivityManager\", \"default service = \" + am); } return am; } }; 启动如此，Activity 的生命周期又是如何被 AMS 进程管理的呢？在 ActivityThread 的 attach 方法中 final IActivityManager mgr = ActivityManagerNative.getDefault(); try { mgr.attachApplication(mAppThread); } catch (RemoteException ex) { throw ex.rethrowFromSystemServer(); } ActivityManagerNative 把 ApplicationThread 的代理写给了AMS进程 public void attachApplication(IApplicationThread app) throws RemoteException { Parcel data = Parcel.obtain(); Parcel reply = Parcel.obtain(); data.writeInterfaceToken(IActivityManager.descriptor); data.writeStrongBinder(app.asBinder()); mRemote.transact(ATTACH_APPLICATION_TRANSACTION, data, reply, 0); reply.readException(); data.recycle(); reply.recycle(); } 进而会有一系列scheduleXXXActivity回调。 public final void schedulePauseActivity(IBinder token, boolean finished, boolean userLeaving, int configChanges, boolean dontReport) { int seq = getLifecycleSeq(); if (DEBUG_ORDER) Slog.d(TAG, \"pauseActivity \" + ActivityThread.this + \" operation received seq: \" + seq); sendMessage( finished ? H.PAUSE_ACTIVITY_FINISHING : H.PAUSE_ACTIVITY, token, (userLeaving ? USER_LEAVING : 0) | (dontReport ? DONT_REPORT : 0), configChanges, seq); } ","date":"2022-04-03","objectID":"/2022/04/android_summary/:6:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"总结 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:7:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"第一部分 - 上半场 当启动Activity的过程中且在AMS处理之前的操作，称之为\"上半场\"。 Activity -\u003e Instrumentation ","date":"2022-04-03","objectID":"/2022/04/android_summary/:7:1","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"第二部分 - 下半场 AMS处理完成，并开始回调App 进程的过程到Activity启动大的操作，称之为\"下半场\"。 ActivityStarter -\u003e ActivityStackSupervisor -\u003e ActivityThread -\u003e ActivityThread.java#H -\u003e handleLaunchActivity -\u003e performLaunchActivity Context 的区别 Context 的关联类采用了装饰模式，主要有以下的优点： 使用者（比如 Service ）能够方便的使用 Context。 如果 ContextImpl 发生变化，它的装饰类 ContextWrapper 不需要做任何修改。 ContextImpl 的实现不会暴露给使用者，使用者也不必关心 ContextImpl 的实现。 通过组合而非继承的方式，拓展 ContextImpl 的功能，在运行时选择不同的装饰类，实现不同的功能。 Context的数量等于Activity的个数 + Service的个数 +1，这个1为Application。 这还涉及 application 启动 activity 的时候，需要加 Intent.FLAG_ACTIVITY_NEW_TASK flag； application 的 context 是在启动进程的时候创建的。 Android 的内存管理/回收策略 对Android系统有较好理解，知道AMS与Kennel层LMK相结合的方式(Adj)去管理和查杀或回收进程； 以及LMK的内存统计策略，当系统内存不足时，AMS会遍历App进程并通知进程进行内存释放(onTrimMemoryLevel)，以及触发各个进程进行GC等。 需要有一些纵向层次的理解，涉及LMK，AMS，APP多层的协同机制，其中每个层面又都有一套自己的策略。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:7:2","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"AMS AMS 在进程管理这块儿做两件事 进程LRU列表动态更新：动态调整进程在mLruProcesses列表的位置 进程优先级动态调整：实际是调整进程oom_adj的值。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:8:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"LMK机制 在Android中，即使当用户退出应用程序后，应用进程也还会存在内存中，方便下次可以快速进入应用而不需要重新创建进程。 这样带来的直接影响就是由于进程数量越来越多，系统内存会越来越少，这个时候就需要杀死一部分进程来缓解内存压力。 至于哪些进程会被杀死，这个时候就需要用到Low Memory Killer机制来进行判定。 Android的Low Memory Killer基于Linux的OOM机制， 在Linux中，内存是以页面为单位分配的，当申请页面分配时如果内存不足会通过以下流程选择 bad 进程来杀掉从而释放内存 LMK驱动层在用户空间指定了一组内存临界值及与之一一对应的一组 oom_adj 值， 当系统剩余内存位于内存临界值中的一个范围内时，如果一个进程的 oom_adj 值大于或等于这个临界值对应的oom_adj值就会被杀掉。 Binder 可参考链接 从IPC角度来说：Binder是Android中的一种跨进程通信方式，该通信方式在linux中没有，是Android独有； 从 Android Driver 层：Binder 还可以理解为一种虚拟的物理设备，它的设备驱动是 /dev/binder； 从 Android Native 层：Binder 是创建 ServiceManager 以及 BpBinder/BBinder 模型，搭建与binder 驱动的桥梁； 从 Android Framework 层：Binder 是各种 Manager（ActivityManager、WindowManager等）和相应 xxxManagerService 的桥梁； 从 Android APP 层：Binder 是客户端和服务端进行通信的媒介，当 bindService 的时候，服务端会返回一个包含了服务端业务调用的 Binder对象，通过这个Binder对象，客户端就可以获取服务端提供的服务或者数据，这里的服务包括普通服务和基于AIDL的服务。 Binder 是基于 C/S 架构设计的。由 Client、Server、ServiceManager 和 Binder 驱动组成。Client、Server负责自各的业务、ServiceManager 运行在用户空间负责代理业务，Binder 驱动运行在内核空间真正对接业务细节。其中 ServiceManager 和 Binder 驱动由系统提供，而 Client、Server 由应用程序来实现。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:9:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"一次通信的过程 Server 进程向 Binder 驱动发送 Binder 实体请求注册服务， Binder 驱动将请求转发到 ServiceManager 注册后把名字和 Binder 实体等信息填入查找表中。 Client 进程在 Binder 驱动的帮助下通过名字从 ServiceManager 中获取到 Server Binder 实体的引用，至此，Client 与 Server 总算是勾搭上了。 与此同时，Binder 驱动开始创建数据缓冲区并通过 ServiceManager 提供的 Server 进程信息地址使用 mmap 函数将 Server 进程用户空间地址映射到创建好的缓冲区上，为跨进程通信做好了准备。 Client 进程调用 copy_from_user 函数将数据拷贝到数据缓冲区后 Binder 驱动再通知 Server 进程进行解包。 Server 进程收到通知后进行解包和方法调用，并将结果写到自己的有映射的内存中。 由于内核缓冲区与 Server进程用户空间地址存在映射关系的，这就相当于目标方法的结果直接传递到了内核数据缓冲区，Binder 驱动通知 Client 进程调用 copy_to_user 函数将缓冲区的目标结果拷贝到自己的用户空间中。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:10:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"为什么要使用 Binder？ 性能：移动设备中如果广泛的使用跨进程通信机制肯定会对通信机制提出严格的要求，而 Binder 相比较传统的进程通信方式更加的高效。 安全：由于传统进程通信方式没有对通信的双方和身方做出严格的验证，只有上层协议才会去架构，如 socket 连接的 IP 地址可以人为的伪造。而 Binder 身份校验也是 android 权限模式的基础。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:11:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"Binder 的线程管理 每个 Binder 的 Server 进程会创建很多线程来处理 Binder 请求，可以简单的理解为创建了一个 Binder 的线程池吧（虽然实际上并不完全是这样简单的线程管理方式），而真正管理这些线程并不是由这个 Server 端来管理的，而是由 Binder 驱动进行管理的。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:12:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"Binder 有什么优势？ 性能方面 共享内存 0 次数据拷贝 Binder 1 次数据拷贝 Socket/管道/消息队列 2 次数据拷贝 稳定性方面 Binder：基于 C/S 架构，客户端（Client）有什么需求就丢给服务端（Server）去完成，架构清晰、职责明确又相互独立，自然稳定性更好 共享内存：虽然无需拷贝，但是控制复杂，难以使用 从稳定性的角度讲，Binder 机制是优于内存共享的。 安全性方面 传统的 IPC 没有任何安全措施，安全依赖上层协议来确保。 传统的 IPC 方法无法获得对方可靠的进程用户 ID/进程 UI（UID/PID），从而无法鉴别对方身份。 binder 的 uid 是由 driver 保证； 传统的 IPC 只能由用户在数据包中填入 UID/PID，容易被恶意程序利用。 传统的 IPC 访问接入点是开放的，无法阻止恶意程序通过猜测接收方地址获得连接。 Binder 既支持实名 Binder，又支持匿名 Binder，安全性高。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:13:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"Binder 是如何做到一次拷贝的？ 主要是因为 Linux 是使用的虚拟内存寻址方式，它有如下特性： 用户空间的虚拟内存地址是映射到物理内存中的； 对虚拟内存的读写实际上是对物理内存的读写，这个过程就是内存映射； 这个内存映射过程是通过系统调用 mmap() 来实现的； Binder 借助了内存映射的方法，在内核空间和接收方用户空间的数据缓存区之间做了一层内存映射，就相当于直接拷贝到了接收方用户空间的数据缓存区，从而减少了一次数据拷贝 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:14:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"Binder 机制是如何跨进程的？ Binder 驱动 在内核空间创建一块接收缓存区； 实现地址映射：将内核缓存区、接收进程用户空间映射到同一接收缓存区 发送进程通过系统调用（copy_from_user）将数据发送到内核缓存区。 由于内核缓存区和接收进程用户空间存在映射关系，故相当于也发送了接收进程的用户空间，实现了跨进程通信。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:15:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"为什么 Intent 不能传递大数据？ Intent 携带信息的大小其实是受 Binder 限制。数据以 Parcel 对象的形式存放在 Binder 传递缓存中。如果数据或返回值比传递 buffer 大，则此次传递调用失败并抛出 TransactionTooLargeException 异常。 Binder 传递缓存有一个限定大小，通常是 1Mb。但同一个进程中所有的传输共享缓存空间。多个地方在进行传输时，即时它们各自传输的数据不超出大小限制，TransactionTooLargeException 异常也可能会被抛出。在使用 Intent 传递数据时，1Mb 并不是安全上限。因为 Binder 中可能正在处理其它的传输工作。不同的机型和系统版本，这个上限值也可能会不同。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:16:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"Binder IPC 实现原理 Binder IPC 正是基于内存映射（mmap）来实现的，但是 mmap() 通常是用在有物理介质的文件系统上的。 比如进程中的用户区域是不能直接和物理设备打交道的，如果想要把磁盘上的数据读取到进程的用户区域，需要两次拷贝（磁盘–\u003e内核空间–\u003e用户空间）；通常在这种场景下 mmap() 就能发挥作用，通过在物理介质和用户空间之间建立映射，减少数据的拷贝次数，用内存读写取代 I/O 读写，提高文件读取效率。 而 Binder 并不存在物理介质，因此 Binder 驱动使用 mmap() 并不是为了在物理介质和用户空间之间建立映射，而是用来在内核空间创建数据接收的缓存空间。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:17:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"一次完整的 Binder IPC 通信过程通常是这样： 首先 Binder 驱动在内核空间创建一个数据接收缓存区； 接着在内核空间开辟一块内核缓存区，建立内核缓存区和内核中数据接收缓存区之间的映射关系，以及内核中数据接收缓存区和接收进程用户空间地址的映射关系； 发送方进程通过系统调用 copyfromuser() 将数据 copy 到内核中的内核缓存区，由于内核缓存区和接收进程的用户空间存在内存映射，因此也就相当于把数据发送到了接收进程的用户空间，这样便完成了一次进程间的通信。 Oneway 关键词 非阻塞式调用。 Oneway 表示客户端不关服务端的返回值，甚至也不关系执行是否正常或者异常。只管通知一下。 代码层面也可以看出来，我们仔细看 initASVE 和 initASVEOneway 这两个方法在aidl内的实现。 oneway 关键词是用在 AIDL 中的，目的是实现异步调用， IPC 调用的时候，不用等待 server 的 reply 就返回。 Client端，判断如果是 ONEWAY，在会在transaction发送到binder驱动后（收到BR_TRANSACTION_COMPLETE），马上退出等待。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:17:1","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"坑点 oneway 默认处理异常不返回。发现为oneway直接吃掉了异常，仅仅打印一行日志。 也没有任何机制可以给上层通知。 Handler机制 主要涉及的角色如下所示： Message：消息。 MessageQueue：消息队列，负责消息的存储与管理，负责管理由 Handler 发送过来的 Message。读取会自动删除消息，单链表维护，插入和删除上有优势。在其next()方法中会无限循环，不断判断是否有消息，有就返回这条消息并移除。 Looper：消息循环器，负责关联线程以及消息的分发，在该线程下从 MessageQueue获取 Message，分发给Handler，Looper创建的时候会创建一个 MessageQueue，调用loop()方法的时候消息循环开始，其中会不断调用messageQueue的next()方法，当有消息就处理，否则阻塞在messageQueue的next()方法中。当Looper的quit()被调用的时候会调用messageQueue的quit()，此时next()会返回null，然后loop()方法也就跟着退出。 Handler：消息处理器，负责发送并处理消息，面向开发者，提供 API，并隐藏背后实现的细节。 整个消息的循环流程还是比较清晰的，具体说来： 1、Handler通过sendMessage()发送消息Message到消息队列MessageQueue。 2、Looper通过loop()不断提取触发条件的Message，并将Message交给对应的target handler来处理。 3、target handler调用自身的handleMessage()方法来处理Message。 事实上，在整个消息循环的流程中，并不只有Java层参与，很多重要的工作都是在C++层来完成的。我们来看下这些类的调用关系。 注：虚线表示关联关系，实线表示调用关系。 在这些类中MessageQueue是Java层与C++层维系的桥梁，MessageQueue与Looper相关功能都通过MessageQueue的Native方法来完成，而其他虚线连接的类只有关联关系，并没有直接调用的关系，它们发生关联的桥梁是MessageQueue。 总结 Handler 发送的消息由 MessageQueue 存储管理，并由 Looper 负责回调消息到 handleMessage()。 线程的转换由 Looper 完成，handleMessage() 所在线程由 Looper.loop() 调用者所在线程决定。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:18:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"Handler 引起的内存泄露原因以及最佳解决方案 Handler 允许我们发送延时消息，如果在延时期间用户关闭了 Activity，那么该 Activity 会泄露。 这个泄露是因为 Message 会持有 Handler，而又因为 Java 的特性，内部类会持有外部类，使得 Activity 会被 Handler 持有，这样最终就导致 Activity 泄露。 解决：将 Handler 定义成静态的内部类，在内部持有 Activity 的弱引用，并在Acitivity的onDestroy()中调用handler.removeCallbacksAndMessages(null)及时移除所有消息。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:19:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"为什么我们能在主线程直接使用 Handler，而不需要创建 Looper ？ 通常我们认为 ActivityThread 就是主线程。事实上它并不是一个线程，而是主线程操作的管理者。在 ActivityThread.main() 方法中调用了 Looper.prepareMainLooper() 方法创建了 主线程的 Looper ,并且调用了 loop() 方法，所以我们就可以直接使用 Handler 了。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:20:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"Handler 里藏着的 Callback 能干什么？ Handler.Callback 有优先处理消息的权利 ，当一条消息被 Callback 处理并拦截（返回 true），那么 Handler 的 handleMessage(msg) 方法就不会被调用了；如果 Callback 处理了消息，但是并没有拦截，那么就意味着一个消息可以同时被 Callback 以及 Handler 处理。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:21:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"创建 Message 实例的最佳方式 为了节省开销，Android 给 Message 设计了回收机制，所以我们在使用的时候尽量复用 Message ，减少内存消耗： 通过 Message 的静态方法 Message.obtain()； 通过 Handler 的公有方法 handler.obtainMessage()。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:22:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"主线程的死循环一直运行是不是特别消耗CPU资源呢？ 并不是，这里就涉及到Linux pipe/epoll机制，简单说就是在主线程的MessageQueue没有消息时，便阻塞在loop的queue.next()中的nativePollOnce()方法里，此时主线程会释放CPU资源进入休眠状态，直到下个消息到达或者有事务发生，通过往pipe管道写端写入数据来唤醒主线程工作。这里采用的epoll机制，是一种IO多路复用机制，可以同时监控多个描述符，当某个描述符就绪(读或写就绪)，则立刻通知相应程序进行读或写操作，本质是同步I/O，即读写是阻塞的。所以说，主线程大多数时候都是处于休眠状态，并不会消耗大量CPU资源。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:23:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"handler postDelay这个延迟是怎么实现的？ handler.postDela y并不是先等待一定的时间再放入到 MessageQueu e中，而是直接进入MessageQueue，以 MessageQueue 的时间顺序排列和唤醒的方式结合实现的。 next 方法中，有计算下次唤醒的时间间隔； ","date":"2022-04-03","objectID":"/2022/04/android_summary/:24:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"如何保证在msg.postDelay情况下保证消息次序？ 入队的时候，会按照时间顺序进行排序。 AMS 参考链接1 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:25:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"关键的类 ActivityManagerServices，简称AMS，服务端对象，负责系统中所有Activity的生命周期。 ActivityThread，App 的真正入口。当开启 App 之后，调用 main() 开始运行，开启消息循环队列，这就是传说的 UI 线程或者叫主线程。与 ActivityManagerService 一起完成Activity的管理工作。 ApplicationThread，用来实现 ActivityManagerServie 与 ActivityThread 之间的交互。在ActivityManagerSevice 需要管理相关 Application 中的 Activity 的生命周期时，通过 ApplicationThread 的代理对象与 ActivityThread 通信。 ApplicationThreadProxy，是 ApplicationThread 在服务器端的代理，负责和客户端的 ApplicationThread 通信。AMS 就是通过该代理与 ActivityThread 进行通信的。 Instrumentation，每一个应用程序只有一个 Instrumetation 对象，每个 Activity 内都有一个对该对象的引用，Instrumentation 可以理解为应用进程的管家，ActivityThread 要创建或暂停某个 Activity 时，都需要通过 Instrumentation 来进行具体的操作。 ActivityStack，Activity 在 AMS 的栈管理，用来记录经启动的 Activity 的先后关系，状态信息等。通过 ActivtyStack 决定是否需要启动新的进程。 ActivityRecord，ActivityStack 的管理对象，每个 Acivity 在 AMS 对应一个 ActivityRecord，来记录 Activity 状态以及其他的管理信息。其实就是服务器端的 Activity 对象的映像。 TaskRecord，AMS 抽象出来的一个“任务”的概念，是记录 ActivityRecord 的栈，一个“Task”包含若干个ActivityRecord。AMS 用 TaskRecord 确保 Activity 启动和退出的顺序。如果你清楚 Activity 的4种launchMode，那么对这概念应该不陌生。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:26:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"简述ActivityManagerService的作用，什么时候初始化？ ActivityManagerService 主要负责系统中四大组件的启动、切换、调度及应用进程的管理和调度等工作，其职责与操作系统中的进程管理和调度模块类似。 ActivityManagerService进行初始化的时机很明确，就是在SystemServer进程开启的时候，就会初始化ActivityManagerService， 可以在SystemServer类中找到相关的启动代码。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:27:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"简述ActivityThread和ApplicationThread，以及关系和区别 ActivityThread ActivityThread在Android中代表Android的主线程，但是并不是一个Thread类。ActivityThread类是Android 进程的初始类，它的main函数是这个App进程的入口。当创建完新进程之后，main函数被加载，然后执行一个loop的循环使当前线程进入消息循环。 ApplicationThread ApplicationThread是ActivityThread的内部类， 是一个Binder对象。在此处它是作为IApplicationThread对象的server端等待client端的请求然后进行处理，最大的client就是AMS。 首先，我们看一下Activity的启动逻辑过程：Applicationthread的ScheduleActivity通过一个叫H的Handler发送了一个启动Activity信息。handleLaunchActivity接收了这个消息，然后做处理，处理的逻辑是让PreformLaunchActivity处理，并最终执行Activity的启动。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:28:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"Instrumentation是什么，和ActivityThread是什么关系 Instrumentation 是Android系统中一系列控制方法的集合(hook),这些方法可以在正常的生命周期之外控制Android控件的运行，也可以控制Andoroid如何加载应用程序。 事实上，AMS与ActivityThread之间诸如Activity的创建、暂停等的交互工作都是由Instrumentation操作的。并且每个Activity都持有一个Instrumentation对象的一个引用， 整个进程中是只有一个Instrumentation。当startActivityForResult()调用之后，实际上还是调用了mInstrumentation.execStartActivity()。 它们之间的关系如下： AMS是大BOSS资本，负责指挥和调度的，ActivityThread是企业老板，虽然说企业的事自己说了算，但是需要听从AMS的指挥，而Instrumentation则是CTO，负责项目的大事小事，但是一般不抛头露面，听老板ActivityThread的安排。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:29:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"ActivityManagerService和zygote进程通信是如何实现的 应用启动时，Launcher进程请求 AMS，AMS 发送创建应用进程请求，Zygote进程接受请求并fork应用进程。而AMS发送创建应用进程请求调用的是 ZygoteState.connect() 方法，ZygoteState 是 ZygoteProcess 的内部类。 Zygote 处理客户端请求：Zygote 服务端接收到参数之后调用 ZygoteConnection.processOneCommand() 处理参数，并 fork 进程。 最后通过 findStaticMain() 找到 ActivityThread 类的 main() 方法并执行，子进程就这样启动了。 怎么用 Context.getSystemService()方法获取AMS的实例，然后调用其提供的API。 WMS ","date":"2022-04-03","objectID":"/2022/04/android_summary/:30:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"WMS 的作用 Android中的window机制的出现就是为了统一管理屏幕上的显示View，让程序有条不紊的执行。 WMS 管理的是窗口，负责窗口的添加、删除、顺序的调整； WMS 不负责洁面的合成和绘制，合成和绘制是由 SurfaceFlinger 完成； View 必须被添加到窗口中，才可以被绘制； View 有自己的 onDraw 回调，在这个回调里进行视图的绘制操作； View 每个视图都是一个图层，就是一个 surface，这块的内存是由 SurfaceFlinger 申请的； 这块内存是通过内存共享的方式在 SurfaceFlinger 和 App 进程之间进行共享的； 具体的感知方式：SurfaceFlinger 申请了 surface 的内存后，通过 binder 的方式将内存相关信息传递给 App 进程，App 向内存中写入绘制内容，绘制完毕，通知 SurfaceFlinger 进行图层的混排，再将数据渲染到屏幕上； 为什么使用共享内存的方式，而不是 binder 呢？因为图像的数据太大了，binder 和 socket 效率都太低了； ","date":"2022-04-03","objectID":"/2022/04/android_summary/:31:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"关键的类 PhoneWindow：Window我们应该很熟悉，它是一个抽象类，具体的实现类为PhoneWindow，它对View进行管理。 WindowManagerImpl ：WindowManager是一个接口类，继承自接口ViewManager, 它是用来管理Window的，它的实现类为WindowManagerImpl。 ViewManager中定义了三个方法：ViewManager中定义了三个方法，分别用来添加、更新和删除View DecorView：窗口内的真实视图；最高层的视图； ViewRootImpl：View 的最高层级，实现 view 和 WindowManager 之间的一些协议；可以触发视图的绘制；可以理解成一个桥梁；内部持有 DecorView 实例的引用； WindowSession： windowstate：WindowState是系统进程层面管理的window对象，windowState通过InputChannel与IMS获取联系。 W，IWindow.Stub 的 binder 服务对象，主要的作用是接收 WMS 的 IPC 调用； 想要对Window进行添加和删除就可以使用WindowManager，具体的工作都是由WMS来处理的，WindowManager和WMS通过Binder来进行跨进程通信，WMS作为系统服务有很多API是不会暴露给WindowManager的，这一点与ActivityManager和AMS的关系有些类似。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:32:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"创建图层的流程 首先APP端新建一个Surface图层的容器壳子， APP通过Binder通信将这个Surface的壳子传递给WMS， WMS为了填充Surface去向SurfaceFlinger申请真正的图层， SurfaceFlinger收到WMS请求为APP端的Surface分配真正图层 将图层相关的关键信息Handle及Producer传递给WMS WMS利用Handle和Producer创建一个SurfaceControl对象，之后再利用其创建Surface 至此，WMS端的Surface创建并填充完毕，然后返回给APP端，APP端就获得了直接和SurfaceFlinger通信的能力 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:33:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"View 的绘制原理 参考链接1 参考链接2 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:34:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"屏幕的刷新机制： 在一个典型的显示系统中，一般包括 CPU、GPU、Display 三个部分， CPU负责计算帧数据，把计算好的数据交给GPU，GPU会对图形数据进行渲染，渲染好后放到buffer(图像缓冲区)里存起来，然后Display（屏幕或显示器）负责把buffer里的数据呈现到屏幕上。 画面撕裂：由于上述谈到的，缓冲生产出的视图数据和绘制数据的数据源，使用的是同一个 buffer，就可能出现在屏幕刷新的时候，数据不一致，进而导致不是一个完整的一帧画面的问题； 为了解决画面撕裂的问题 双缓冲：一个绘制数据的缓冲；一个显示数据的缓冲；二者互不干扰； VSync：发出该信号时，就是两个缓冲区交换内存地址的时机； ","date":"2022-04-03","objectID":"/2022/04/android_summary/:34:1","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"两个概念 刷新频率，refresh rate：屏幕在一秒内，可以刷新的次数；比如 60Hz； 帧率，frame rate：GPU 每秒可以画的帧数；比如 帧率比刷新频率快的时候，就会出现画面撕裂； 屏幕的显示，是由上至下扫描展示的；当屏幕扫描完，到最后一行的时候，放松 vsync 信号，通知缓冲期交换地址指针； ","date":"2022-04-03","objectID":"/2022/04/android_summary/:34:2","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"API 16 后新增的优化机制 VSync 的引入，还残留一个问题没解决：刷新依赖于 VSync 信号，没有 VSync 不能刷新，如果 VSync 来时，缓冲区的数据没有准备好，就会显示上一帧的内容，就会出现卡顿。 解决方案：新增一个缓冲期，变成 三缓冲区。能保证帧是连续的。 本质原因，是帧的生成时间太长导致的。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:34:3","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"重绘 调用 requestLayout 会导致该 view 已经其递归上去的父 view都会重新走一遍measure、layout、draw三大流程。 调用invalidate只会导致draw流程的重走。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:34:4","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"SurfaceView 与 TextureView ","date":"2022-04-03","objectID":"/2022/04/android_summary/:35:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"SurfaceView 我们知道每个窗口在SurfaceFlinger服务中都对应有一个layer，用来描述它的绘制表面surface。对于那些具有SurfaceView的窗口来说，每个SurfaceFlinger服务中还对应一个独立的Layer或者LayerBuffer，用来单独描述它的绘制表面，以区别它的宿主窗口的绘制表面。 surfaceView在其宿主Activity窗口上挖了一个“洞”，这个“洞”实际上只不过是在其宿主Activity窗口上设置了一块透明区域 优缺点 **优点：**由于在系统中（WMS和SF）中，它与宿主窗口是分离的。因此：Surface的渲染可以放到单独线程去做，渲染时可以有自己的GL context。这对于一些游戏、视频等性能相关的应用非常有益，因为它不会影响主线程对事件的响应。 缺点: 因为这个Surface不在View hierachy中，它的显示也不受View的属性控制，所以不能进行平移，缩放等变换，也不能放在其它ViewGroup中，一些View中的特性也无法使用 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:35:1","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"TextureView 在4.0(API level 14)中引入，与SurfaceView一样继承View，它可以将内容流直接投影到View中，它可以将内容流直接投影到View中，可以用于实现Live preview等功能。 它不会在WMS中单独创建窗口，而是作为View hierachy中的一个普通View，因此可以和其它普通View一样进行移动，旋转，缩放，动画等变化。 值得注意的是TextureView必须在硬件加速的窗口中。它显示的内容流数据可以来自App进程或是远端进程。 各种 token ","date":"2022-04-03","objectID":"/2022/04/android_summary/:35:2","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"ActivityRecord 中的 token 是啥时候创建的？作用是什么？ 可参考的链接1 ，这个文章写得很好。 时机：在创建 ActivityRecord 对象的时候，就会创建 token。 作用：启动一个Activity的时候会为这个 Activity 生成一个 ActivityRecord 对象，该对象用于 AMS 管理跟踪，而 Token 就在这里诞生了。Token 类实现了 IApplicationToken.Stub，也就是作为 Binder 的服务端，那么它自然的接收客户端的请求，那它主要提供什么样的服务呢? android/view/IApplicationToken.aidl interface IApplicationToken { void windowsDrawn(); void windowsVisible(); void windowsGone(); boolean keyDispatchingTimedOut(String reason); long getKeyDispatchingTimeout(); } 可以看出，大部分是用于接收 WindowManagerService 通知 ActivityManagerService 的关于 Window 的消息，也有 key 的相关消息。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:36:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"WMS 中的 token 是什么时候创建的？作用是什么？ 是什么：WMS专为Activity实现了一个 WindowToken 的子类：AppWindowToken 时机：具体位置为 ActivityStack.startActivityLocked()，也就是启动 Activity 的时候，通过 WMS 根据 ActivityRecord 中的 token，一起创建了 AppWindowToken。 作用：WindowManagerService 中 AppWindowToken 保存着 ActivityManagerService Binder 对象，用来向AMS 传递 Window 和按键的一些信息. wms 中有与 ams 中一一对应的 stack 和 task； ","date":"2022-04-03","objectID":"/2022/04/android_summary/:37:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"App 中的 token ActivityClientRecord 是 activity 在 App 应用进程中的代表。其中保存了 AMS 这个 server 的 token 引用。 时机：scheduleLaunchActivity 方法中，进行了 ActivityClientRecord 的构建。这里 scheduleLaunchActivity 方法是通过 binder 进行 IPC 方法调用的。 作用：这个 ActivityClientRecord 类是 Activity 在 ActivityThread 中一一对应的，一个APP有多个Activity, 也就是说有多个ActivityClientRecord， 那么当 AMS 要启动一个 Activity 的时候，怎么样找到 APP 中正确的那个Activity呢？答案就是通过Token,先通过token找到ActivityClientRecord,然后再通过ActivityClientRecord中的activity就找到了正确的Activity了。Activity中Token主要用于在请求AMS服务时用于定位到具体到AMS中正确的 ActivityRecord。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:38:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"WindowManager.LayoutParams里的token 时机：setView 的时候，构建 WindowManager.LayoutParams 的 token 时，用 Window 中的 mAppToken 也就是AMS中ActivityRecord中的Token。 作用：WindowManager.LayoutParams中的 token传递给WMS,另外它的大部分作用是一致性判断。 badToken 问题案例 那为什么窗口显示的时候会出现BadTokenException？ 很明显是WindowManagerService 的mWindowMap 已经找不到对应的token，那为什么会出现这种情况呢？从表面上看那肯定是addview的时候，activity或者toast生成的token，已经被清除了。 我们来分析上述的问题，BadTokenException能够产生的情形蛮多的，就当前的调用栈看，是在handleResumeActivity的时候出现问题。 情况一 ActivityManagerService 里面成员变量 mHandler 的 Looper，不会被Client-Side（即APP进程的操作所影响）。它在调用 destroyActivityLocked 的时候会先给Handler发一个延迟的DESTROY_TIMEOUT_MSG，如果client端顺利执行完了destroy，则会通知ActivityStack移除这个MSG，否则它就会被执行。 系统在调用 Activity 的 destroy 操作的时候，出现超时导致系统 mHandler 执行 DESTROY_TIMEOUT_MSG，测试log： 那什么情况下，在没有调用这些生命周期的情况就直接调用了destory。 1）还未完成resume的情况下，主动调用clean task; 2）在manifest中注明了activity是noHistory=true，则会在切换activity的时候，当前activity stop 的时候会执行requestFinishActivityLocked： 3）Intent 启动参数，设置FLAG_ACTIVITY_CLEAR_TOP，跳转到之前到activity； 解决方案 主线程里面不能有大量耗时操作，这个DESTROY_TIMEOUT为10s 1.避免在Application与Activity的onCreate及onActivityResult阶段做耗时操作。 2.尽量把noHistory去掉，stop不强制触发finish，不发送DESTROY_TIMEOUT，AMS不再删除WindowToken。 3.根据业务逻辑判断较早的基于FLAG_ACTIVITY_CLEAR_TOP启动Activity后当前Activity是否具有耗时操作，进一步优化。 情况二 延迟addView 目前最常见的堆栈，也是日常编码极其容易触发的BadTokenException就是多线程操作 Dialog，在执行窗口显示的时候Activity已经被销毁了，可以看下边的调用栈： 能够很清晰的看到Dialog.show的时候找不到token，这类问题一般有两种情形导致： 1.多线程操作，未准确判断生命周期直接进行窗口展示，当\u0008Activity已经destroy后，线程回调继续使用该context进行页面展示。 2.通过hanlder发送Runnable，而该runnable中有ui操作的流程, 在onPause之后没有及时清理掉这些未处理的消息导致destory后又触发了ui操作。 解决方案 线程回调中执行需要判断context，currentActivity.isFinishing()，能够部分拦截； 在show的时候catch (WindowManager.BadTokenException e)； 热修复 https://mp.weixin.qq.com/s?__biz=MzAwNDY1ODY2OQ==\u0026mid=2649286384\u0026idx=1\u0026sn=f1aff31d6a567674759be476bcd12549\u0026scene=4#wechat_redirect ","date":"2022-04-03","objectID":"/2022/04/android_summary/:39:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"类加载 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:40:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"Android中ClassLoader的种类\u0026特点 BootClassLoader（Java的BootStrap ClassLoader）： 用于加载Android Framework层class文件。 PathClassLoader（Java的App ClassLoader）： 用于加载已经安装到系统中的apk中的class文件。 DexClassLoader（Java的Custom ClassLoader）： 用于加载指定目录中的class文件。 BaseDexClassLoader： 是PathClassLoader和DexClassLoader的父类。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:40:1","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"热修复的原理 在app重启时，通过classloader抢先加载补丁的类，由于app在运行时需要修复的类已经被加载，运行时无法对类卸载，因此必须需要重启才能生效。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:41:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"Dalvik下的类校验问题 当dex加载到内存时，如果不存在odex文件会做dexopt将其转换成odex，在dexopt的过程中会做dvmClassVerify，如果某个类及其直接引用的类都在同一个dex的情况下，该类会被打上CLASS_ISPREVERIFIED标志，在dvmResolveClass的时候会做校验，也就是以下的代码，当补丁类加载的时候，如果满足这三个条件，就会校验失败抛出异常 fromUnverifiedConstant=false，非const-class/instance-of指令引用补丁类 IS_CLASS_FLAG_SET(referrer, CLASS_ISPREVERIFIED)，补丁类被打上CLASS_ISPREVERIFIED referrer-\u003epDvmDex != resClassCheck-\u003epDvmDex，补丁类和引用类不在同一个dex ","date":"2022-04-03","objectID":"/2022/04/android_summary/:41:1","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"方案分类 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:42:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"【native修复】Andfix 原理 通过env-\u003eFromReflectMethod可以得到Method对象的ArtMethod起始地址，然后将其强转为ArtMethod指针，从而对方法结构进行修改。 问题 不能对原有类进行方法和字段的增减，都会导致索引发生变化，从而破坏原有类的结构，访问时就无法索引到正确的方法和字段 依赖Android底层源码，如果厂商修改了虚拟机方法，替换机制就可能出问题。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:42:1","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"【native 修复】Sophix https://developer.aliyun.com/article/103527 原理 Sophix在Andfix基础上提出了一种新的思路，通过计算地址偏移对ArtMethod整体做替换，从而解决了底层结构兼容性问题。从方法创建的源码上看，类的方法数组是通过开辟连续的空间，然后逐个new出来。也就是说ArtMethod的内存地址排列是连续的，因此可以通过两个方法的地址的差计算出。ArtMethod的大小，然后通过memcpy直接拷贝即可完成方法的替换。 问题 依赖ArtMethod的内存排列结构； 不能对原有类进行方法和字段的增减； 非静态修复类不能被反射调用，由于反射的对象是运行时的，而修复方法的类新加载的，不一致导致校验失败； ","date":"2022-04-03","objectID":"/2022/04/android_summary/:42:2","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"【Instant Run方案】Robust 原理 通过gradle的transform在编译期插桩，对每个类中插入一个变量changeQuickRedirect，并且在所有方法预置一段逻辑，如果changeQuickRedirect不为空，则重定向到补丁方法执行，否则执行原来的方法。 补丁下发后通过DexClassLoader加载patch.dex，反射拿到 PatchesInfoImpl 类，里面保存了混淆前后的名字，比如说上面的 com.meituan.sample.State 被混淆成 com.meituan.sample.d 通过反射拿到com.meituan.sample.d，将changeQuickRedirect字段赋值用patch.dex中加载出来的StatePatch对象。 问题 包体积问题，插桩会导致包体积变大 dex中method id不能超过65536限制，主要原因是小函数插桩函数变大，容易导致无法内联，解决方式通过配置黑名单过滤小函数 super调用问题，补丁类无法直接通过super调用父类方法 解决方法：修改原始类的调用指令，改成invoke-super，由于invoke-super在调用时会校验当前类，补丁类需要继承原始类的父类，举个例子解释一下 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:42:3","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"【类加载】QQ 空间 原理 QZone的思路是绕过第二个条件，预先在apk里面增加一个辅助类并单独打成一个dex，通过插桩的方式给所有类增加对辅助类的引用，从而让所有类不被打上CLASS_ISPREVERIFIED标志 问题 Dalvik下绕过dexopt导致在类加载的时候才做校验，影响加载性能 art下dex2oat时同dex的类存在内联优化可能，如果补丁原来的类被内联了，且补丁类新增方法，内联类调用补丁类时方法、字段索引都是原来的，从而导致内存地址错乱，解决办法是将补丁类的父类和调用类都打到补丁包，但这样会导致补丁包变得很大。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:42:4","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"【类加载】QFIX 原理 QFix的思路是绕过第一个条件，在加载补丁类的时候，手动在jni层调用dvmResolveClass，设置fromUnverifiedConstant=true，提前调用后会有缓存，下次执行就直接从缓存获取从而绕过校验。 问题 不支持多态，由于时机在dexopt之后，optimize阶段会将invoke-virtual指令替换成invoke-virtual-quick，也就是将方法直接替换成vtable里面的索引，当新增virtual方法后会导致vtable索引错乱，从而导致方法调用异常 多态是怎么实现的 每个类在解析之后对所有的虚方法会生成会有一个vtable表，子类的vtable表会与父类的vtable表合并，通过比对方法签名，优先删去父类的保留子类的，否则添加到末尾，而invoke-virtual指令是通过遍历类的vtable表找到方法索引，然后通过索引在对象的vtable找到实际方法调用 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:42:5","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"【类加载】Tinker 原理 Tinker的思路是绕过第三个条件，自研了一套DexDiff算法，通过差量的方式打出补丁包下发，然后将patch.dex和应用变更的classN.dex合并成完整的dex，然后对完整的dex进行替换。 合并dex app启动后开启独立进程，自研了一套算法进行合并 Dalvik：对每个需要修复的dex合成新dex，然后做dexopt Art：多个dex打包成zip包，由于动态加载的dex2oat默认是speed模式全量编译，为了避免耗时过长导致anr，通过命令先做quiken/interpret-only模式的dex2oat，通过解释模式先运行，然后后台再做全量编译 问题 dex合并在vm heap上进行，容易oom，可以优化成在native进行，native内存不受vm限制 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:42:6","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"【类加载】JVMTI JVMTI：JVM Tool Interface，Java虚拟机定义的开发和监控JVM使用的接口，通过该接口可以探查JVM内部的运行状态，以及控制JVM应用程序的执行。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:42:7","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"So修复 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:43:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"原理 替换加载方式 android提供了两个方法加载so System.load(String filename);//可以加载自定义路径下的so System.loadLibaray(String filename);//用来加载已经安装APK中的so 最简单的方式就是包装一下这两个方法，如果有补丁so则通过System.load加载，否则通过System.loadLibaray加载，不过该方式对代码有侵入性，无法修复三方库的so 反射替换加载路径 类似类加载的方式，so加载的时候实际也是从classloader中查找路径，可以把补丁so库的路径插入到nativeLibraryDirectories数组的最前面，优先加载补丁库达到修复的目的。 插件化 参考链接1 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:43:1","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"目的 插件一般也是以一个apk的文件形式存在，然后被宿主apk动态加载并运行。这么做的好处是： 减小包大小。例如用户不常用的功能可以单独打包成一个插件apk，这样可以减小宿主apk的大小。 插件apk可以独立更新。 宿主和插件分开编译，提升开发效率。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:44:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"classloader 相关的内容 类加载原理和\"父委托\"查找机制，大致分为三步，简单作如下说明： 第一步：当前ClassLoader.findLoadedClass()，尝试从已经加载过的缓存中读取。有则直接返回，无则进入下一步； 第二步：如果存在parent，则委托parentClassLoader.loadClass()，自低向上依次委托，一致到BootClassLoader； 第三步：自顶向下依次findClass()。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:45:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"SO 文件的安装处理 APK安装流程详解4——安装中关于so库的那些事 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:46:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"ClassLoader与SO的关系 加载：System.load(path)/System.loadLibrary(name)，能否成功，取决于目标so文件能否找到，或由当前ClassLoader.nativeElements[]内部找到，或由外部传入。 打开：能否成功，一个so只能被同一个ClassLoader打开，打开次数不限制。否则报错：already opened by ClassLoader xxx, can’t open in ClassLoader xxx native方法调用：如果是JNI调用，能否成功，取决于当前JNI接口类的classLoader是否是打开它的classLoader，否则报错：No implementation found for xxx。 dlopen/dlsym/dlclose：如果是dlopen形式的打开、方法调用、关闭，取决与加载依赖它的so的ClassLoader的能否找到被依赖的so，如果找不到，主动调用System.load()，然后在dlopen也行。但是这个so库只能被同一个ClassLoader load一次。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:46:1","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"插件的整体的流程 时机 主动：业务方主动调用加载方法； 被动：业务方调用了插件中的类； 核心操作：hook Instrumentation，创建自己的 Instrumentation，代理原有ActivityThread.mInstrumentation； 流程详解 创建 applicationinfo； 创建 loadapk； 创建 plugin 的 classloader； 替换资源； 注册广播； 安装 ContentProvider； 创建 application； 替换 packageManager； 回调 application 的 oncreate； ","date":"2022-04-03","objectID":"/2022/04/android_summary/:47:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"Activity 组件化的处理方式 对于Activity的插件化来说主要是两步： 如何让未在AndroidMainfest.xml注册的Activity通过AMS的校验 如何让未注册的Activity正常启动 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:48:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"业内方案 Qigsaw Qigsaw对于第一步来说它的处理是将插件和宿主编译的时候，将插件内AndroidMainfest.xml的Activity信息复制到宿主的AndroidMainfest.xml内，从而第一步通过校验。 对于第二步来说，Qigsaw插件化框架修改了Classloader的实现，添加了插件相关的Path，从而导致即使是插件内的类也可以加载,从而实现Activity插件化。 优点： 稳定且兼容性强 未使用Hidden Api Hook 少 改动少 缺点： 宿主和插件要在同仓下编译 无法动态新增Activity（宿主的AndroidMainfest.xml是编译时修改，无法通过更新插件升级） Replugin Replugin对于第一步来说，它是编译期间将生成Activity的基类，然后强制插件内的Activity继承此Activity,然后重写了其startActivity的方法，改为使用Replugin内的实现。这样可以按照一般插件化的方案来处理第一步，优点是没有Hook系统类。 对于第二步来说，Replugin Hook 了Classloader ,所以其可以在Activity创建的时候，将第一步中存储的插件的Activity的类名和占桩的Activity的类名读取出来，然后返回真正的插件的Activity的类即可。 优点： 稳定且兼容性强 未使用Hidden Api Hook 少 改动少 缺点： 需要生成代码和修改原代码 Mira 对于Mira来说，其第一步Hook了Instrumentation，当你执行了Activity#startActivity的时候，内部执行了Instrumentation#execStartActivity方法，所以目前Hook了这个方法，用于存储插件Activity 和 占桩Activity的关系，并将插件Activity替换成占桩Activity，完成第一步。 对于第二步来说，Hook 了ActivityThread的内部类H,它是个Handle.Callback， 这个地方需要注意，在Android 7 以上会触发ActivityThread.H.EXECUTE_TRANSACTION 消息，以下则会触发ActivityThread.H.LAUNCH_ACTIVITY 消息，版本不同消息类型不同，然后针对这俩消息中Intent存储的占桩Activity信息还原成插件Activity的信息。且此时也需要修改Classloader,用于加载插件Activity。 优点： 稳定性强 缺点： 兼容性一般（需要针对Android7.0前后版本做适配） 使用了Hidden Api Hook稍多 改动稍多 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:48:1","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"Resource 资源的插件化 资源插件化的过程可总结为三步： 第一步，Application启动时hook替换Application及LoadedApk的resouces到我们自定义的 WrapperResources 上来； 反射调用AssetManager.addAssetPath(String path)方法，我们把插件APK的路径传递进去，就可实现访问插件的资源。App中有多少插件就调用多少次，把所有插件的资源都add进去，构造出一个\"超级Resources\"为全局共用，查找引用，把宿主与插件中需要使用资源的地方都替换为这个\"超级Resources\"即是。这是资源插件化的第一步。 第二步，插件启动时把插件的资源add到全局资源中，分配不同的段位与resId； 第三步，Activity在启动时hook替换resouces到MiraWrapperResources实例上。 在以下几个时机需要注意替换 resource 引用、AssetManager 引用 application 启动 activity configuration 变化 新建 activity 的时候； ","date":"2022-04-03","objectID":"/2022/04/android_summary/:49:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"ID 冲突的解决方案 每个资源都有一个对应的 ID 值 0xPPTTEEEE，由于宿主和插件都是各自打包，开发插件 App 和开宿主App的流程基本是一样的。所以在合并插件资源到宿主时，某个资源 ID 值有可能与宿主资源的 ID 是相同的，即资源 ID 冲突，Mira 的解决方案是通过修改 AAPT 打包工具为插件资源 ID 分配新段位，和固定宿主 App 中需要共享给插件的资源 ID。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:49:1","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"service 的插件化 整体的流程和 activity 的插件化很像，分为上半场和下半场。 上半场一样； 区别在于下半场； 因为 start 就是简单的启动一个 Service 组件，所以可以简单理解为只有一次交互消息，而bindService 执行时会有两次消息传递，第一次是 AMS 通知 ActivityThread 创建Service的消息，第二次是 AMS 传递 ServiceConnection 对象到 ActivityThread 的消息。 因为 stop 是简单的停止一个 Service 组件，只有一次交互消息，且消息体中包含了Intent 信息；而 unbind 有两次交互消息，且 stopService 消息体中没有 Intent 信息，只有 IBinder token 信息。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:50:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"具体步骤 上半场我们选择hook AMN，即创建IActivityManagerProxy作为AMN的代理对象。我们只要\"欺骗AMS\"要start/stop、bind/unBinder的Service已在AndroidManifest中存在就好。在经过AMN发送Intent信息到AMS之前，把该Intent上的targetService替换为一个在AndroidManifest中声明的StubService，把原来的targetService信息存放在Bundle的扩展字段位上即可。 下半场我们选择hook ActivityThread.H.mCallback，拦截AMS通知App启动或绑定StubService的消息。在即将启动或绑定StubService之前，把StubService换回原先保存在Bundle扩展位上的targetService。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:50:1","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"Receiver的插件化 静态广播需要在AndroidManifest中声明，应用安装和Android系统重启时，PMS都会解析App的Manifest，所以静态广播的注册信息位于PMS中。动态广播是在代码中调用Context.registerReceiver() –\u003e AMN.getDefault().registerReceiver()手动注册的，所以注册信息存在于AMS中。二者区别仅在于注册方式不同，之后就都一样了。 我们就可以把静态广播都改为动态广播，避免在AndroidManifest中声明，也就避免了AMS检查。这就是Receiver的插件化思路。 动态广播不需要和AMS打交道，所以它就是一个普通类。我们只要确保宿主App能加载插件中的这个动态广播类即是。在ClassLoader相关章节中介绍过全局的类加载器，有它作保证，我们可以加载任一插件中的任何一个类。这样，插件中的动态广播就可以被宿主App正常调用了。 时机：Mira 在使用一个插件前，都必须要preload()预加载。其中包括很重要的一步是将插件中的静态广播转为动态广播注册在宿主中。即插件初始化调用之前，我们取得插件中的静态广播列表，调用相应插件的PluginClassLoader创建实例，以动态广播的形式注册进宿主中。 这种方案使得丧失了静态广播的特性，体现在不需要启动App就可以启动一个静态广播。当然这里我们不能浅显的认为，App的启动一定是打开某个Activity，通常情况下启动首页的MainActivity只是启动App的一种。Receiver作为四大组件之一，也支持外部调起，进而创建进程，启动应用，接收到广播。尤其推送Push场景下，当App进程已死后，其它伙伴应用可通过发送静态广播来唤醒App。当采用了这种静态转动态的方案后，插件中的所有静态广播特性丧失，即不在支持在App没启动和插件没就绪的情况下，接收到广播。后续我们会对此方案持续改进。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:51:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"ContentProvider的插件化 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:52:0","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"主进程插件化 比较简单。类似Receiver的插件化解决方案，把插件中声明在Manifest的静态广播转动态广播\"注册\"在宿主中。其实Provider也可以这么实现，这时不叫\"注册\"，叫\"安装\"。该方法位于 ActivityThread.installContentProvider 方法中，我们可以反射调用该方法，把插件中的Providers作为第二个参数填充进去即可。 时机：越早越好。因为Provider更多场景是给第三方App用得，插件中的Provider必须要安装在宿主中才能生效，越早安装，第三方App等待的时间就越短。App安装自身Provider时机是ActivityThread.installContentProvider()方法执行，会在App进程启动时立刻执行，比Application.onCreate()早，略晚于Application.attchBaseContext()。Mira在使用一个插件前，都必须要preload()预加载。其中包括很重要的一步是将插件中的Provider安装在宿主中。即插件初始化调用之前，我们取得插件中的Provider列表，修改providerInfo.applicationInfo.packageName包名为宿主包名，反射调用ActivityThread.installContentProvider()方法安装即可。所以如果可能，尽可能早得preload()插件。 参照PMS通过PackageParser解析Apk，Mira中PluginPackangeManager用于管理插件安装包相关内容，包括解析插件Apk，解析Manifest，创建Package，提取四大组件等。在此调用getProviders()获取插件中的Provider列表。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:52:1","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Android"],"content":"子进程插件化 有跨进程IPC操作，工作在本进程，主要为其它进程App提供数据的Provider，这类Provider的插件化方案比较复杂。直接让外界App或其它进程直接调用本进程插件里定义的Provider，并不是一个理想的解决方案，我们定义了一个StubContentProvider作为中转，让外界App先访问到中转Provider，进而分发到插件里的Provider上，这种设计得益于Provider独有的URI authority作为唯一定位符机制，URI是资源统一定位符，按照既定协议唯一标识一个确定的资源，但它本身就是一个字符串，所以非常适合用于这种转发机制。 ","date":"2022-04-03","objectID":"/2022/04/android_summary/:52:2","tags":["Android"],"title":"一张思维导图看 Android【持续迭代】","uri":"/2022/04/android_summary/"},{"categories":["Other"],"content":"背景 文档是日常开发过程中非常重要的记录和交流的工具,也是学习新技术必然要阅读的材料.学习技术的时候,都会建议直接看官方文档,不同的技术网站,会看到 Guide,Tutorial,Wiki,Reference 等分类(也可能只包含其中一个或者几个). 我之前就一直对这几个英文单词有疑问,尤其是我在看 Android 开发者官网的时候,不明白每个分类的依据,间接导致,自己也没有学会如何写文档.后来发现了这篇文章,读完觉得很有道理. The documentation system ,窃以为非常好,值得我进行模仿学习. 以下的内容会进行自我理解的翻译,有意无意的删除一些冗余的修辞,如有幸被网上邻居搜到,建议看原文,非常简单. Summary 为了编写良好的软件文档,需要说一个秘密: 没有一个名为文档的东西,文档应该是四样东西的集合. 这四样分别是是：tutorials(教程),how-to guides(如何做的引导),technical reference (技术参考),explanation(解释). 它们代表四种不同的目的或职能,并且这四种的写作方式都有差异.了解了这些差异,通常能巨大的提高文档的质量. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:0:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"关于即将描述的文档系统 这里的文档系统是非常简单的,近乎于全面适用行业内的方案.行文有个承诺: 如果将这些原则在实践中进行应用,将极大的提高写作文档的质量. 有很多公司/组织/开源项目采用了本文所述的方案,详细见链接采用本方案的项目 Introduction ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:1:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"问题和解决方案 ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:2:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"需要解决的问题 如果文档不够好,产品再好,人们也不会使用它.即使人们必须使用它,那也是因为他们别无选择,没有良好的文档,人们无法如你期望的那样使用你开发的产品. 当然了,每个人都知道文档的重要性,每个人也都尝试去写好文档,最终也都失败了. 这也不是写作的人不够努力,通常是他们没有按照正确的方式去做而已. 本文介绍的文档系统,不是为了让你更加努力的工作,而是让你写作的文档更好,使用正确的方式进行写作,让文档更加易懂,更加容易维护: The right way is the easier way. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:2:1","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"文档系统的秘密 有一个不应该是秘密的秘密: 文档应该围绕四种不能的功能目的进行构造: tutorials(教程),how-to guides(如何做的引导),technical reference (技术参考),explanation(解释).每一种都需要有独立的写作模式. 软件的使用者在不同的情况下,需要不同的文档,故而,大部分的软件,对于这四种文档,都需要包含. 文档将围绕这四种进行构建,并且四种文档需要独立的创建. Tutorials(教程) How-to guides(如何做的引导) Reference(技术参考) Explanation(解释) oriented to(面向的/目的/导向) 学习 有一个固定的目标 传达信息 为了更深的理解 must (必须做到) 让一个初学者上手 演示如何解决一个特定的问题 描述技术的内部参数等 深层次的解释 its form(形式) 一节课 一些列的步骤 纯粹的描述 用文字进行阐述说明 analogy(类比) 教一个孩子如何进行烹饪 烹饪中的食谱 百科全书里的文章 关于烹饪的历史书 如上这种划分,可以让作者清楚写什么内容,写在哪儿,如何写; 读者清楚去哪找想要的内容.这种划分,可以让作者从原先的一股脑的将一堆信息进行拼凑的状态中解脱,因为这种划分,按照职责划分,不同类型的文章只需要完成一样职责,写作时目的很明确,不再出现拼凑信息的情况. 坦白讲,那些不符合该方案的文档还是非常难以维护的.因为我们列出的 4 种类型针对的是 4 种不同的需求,一旦将这些需求对应的内容糅合在一个文档里的时候,文档的内容为了兼顾,肯定有相互之间的牵扯,读者就会被牵扯. 一旦理解了上述的方案,就会极大地提高文档的结构性,我们也就能知晓接下来采取什么方式提高我们的文档质量. 接下里的章节中,将会针对这四种类型的文档,分别进行详细的描述. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:2:2","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"让文档自己工作 对于作者而言 对于文档的作者而言,最大的难题是不知道他们该做这些什么. 作者为了让自己想表达的内容以合适的方式排列在一起,不停的写再重写,不停的反复. 通过这种文档系统结构,将会使得写作更加容易,因为该方案将文档进行明确的职责区分,将文档进行明确的隔离,这样使得写作和维护都很容易,也很容易使用和查找. 虽然说文档不能自己完成,但是现在编写文档的时候,可以做到不用操心哪些内容应该包含,哪些内容不应该包含.在职责明确的背景下,我们很容易知道在什么地方,写什么,怎么写. 对于读者而言 对于读者言,可以更好的与软件进行交互了,在试用的不同阶段,可以很快的找到自己需要的资料. 按照上述四个象限进行编写文档,有助于软件吸引和留住用户,他们可以快速接入,更加高效的使用软件. Tutorials Tutorials(教程) 是由课程组合而成,内容都是些课程,目的是带领读者通过一系列步骤来完成某种项目.项目的作者需要这些 Tutorials(教程 ),一次向初学者展示他们可以用作者的软件可以获取到的东西. Tutorials(教程) 是以学习为导向的,具体来说,Tutorials(教程) 是教会学习者如何使用,成为一个使用者,而不是学习项目本身. 你作为作者就是个老师,读者就是个学生.你需要对你教授给学生的东西负责.学生在你的指导下,将会通过一系列的操作在最终获到你想传授的技能. 最终的结局和步骤,都取决于你.但是读者应该是什么样的人,却是无法预测的.结局对于初学者来说,必须有意义,而且必须有所收获. 有一个重要的事情需要说明,当学习者阅读完Tutorial时,他应该对剩下的文档内容心里有数了,对于这个软件本身也做到了心里有数. 大多数软件的Tutorial很差,甚至干脆没有.Tutorial是一个让学习者成为软件用户的契机.如果Tutorial很差,或者没有,获取新用户的难度会大很多. 在介绍四种文档的章节中,这部分是最难写的,因为Tutorial是最难理解,也最难做好的内容. 传授知识的最佳方式是现实中存在一个可以互动的老师.这基本是不可能的,所以我们写的Tutorial就是最好的替代品.这也能说明,我们需要格外的注意Tutorial的部分. Tutorial 必须对初学者有用,简单有意义,而且紧跟软件的发版节奏,及时保持最新状态. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:2:3","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"和烹饪类比 可以类比教一个孩子如何烹饪. 你教孩子做什么菜不重要.重要的是,孩子通过你的传授,发现了烹饪的乐趣,获得了自信并且想再次尝试. 孩子通过学习过程中所做的事情,将会学习到烹饪中最重要的事情.他将学会为了做一道鸡丝面,应该放些什么材料,而且知道如何处理这些材料. 这是因为,使用软件,和烹饪一样,是个手艺活.尽管说,他是需要知识,但是这些知识是实用性的,需要实际使用,而不是理论性的. 当我们学一门新的手艺和技巧的时候,总是从使用这个手艺或技巧开始. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:3:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"如何写好Tutorial (How to write good tutorials) ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:4:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"让学习者在使用中学(Allow the user to learn by doing) 在事情的初期阶段,我们通过实际使用来学.这也是我们学习说话和走路使用的方法. 在软件的Tutorial中,都是软件的初学者需要做的事情.学习者在阅读Tutorial后可以知晓,从一个简单入门的项目向一个更复杂的项目需要使用的工具和步骤. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:4:1","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"让学习者开始动起来 (Get the user started) 对于初学者进行手把手式的讲解,是让人更容易接受的.而不是将初学者当作一个经验丰富的用户.有时候,传授的内容可能不是所谓的“正确”方式,因为刚开始的时候,不要传授所谓的最佳实践. Tutorial 的最核心的点是,让学习者开始行动起来,让他踏上使用的旅程,而不是要一次性将他们带到旅途的终点. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:4:2","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"确保Tutorial是可用的 (Make sure that your tutorial works) 作为指导者,还有一个很重要的任务,就是让学习者充满自信,自信于在你的指导下,通过软件,以自己的能力,可以完成Tutorial中要求的内容. 有很多的内容可以帮我们达到这个目的.一份措辞温和友好的帮助文档,连续且逻辑清晰的语言,都对此大有裨益.但是其中最重要的一点是,你让阅读者进行的操作案例必须是可用的.阅读学习者必须根据你的步骤能看到跟你说的一样的效果. 如果学习者在学习过程中,进行的操作不顺利,产生错误或者意想不到的结果,即使这个不是你的原因,你的Tutorial就算是失败了.学习者如果跟你面对面交流,那么你可以直接线下指导,但是绝大部分情况,都是直接阅读Tutorial的,那就很难直接指导.所以,在写作Tutorial的时候,就需要想方设法的我避免这个样的事情发生. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:4:3","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"确保阅读者的操作能获得及时反馈(Ensure the user sees results immediately) 学习者在过程中执行的所有操作应该是完成一些学习者阅读时已经可理解的操作,无论这个操作有多小,都必须让阅读者明白目的.试想一下,你的一个学生,在看到一个效果之前,需要阅读两页的文档,且执行一些自身都觉得奇怪的操作,这个过程也太长了.学习者进行的每一步操作,应该做到尽快明显且可见.,执行的动作和效果之间的联系也需要清晰明了. Tutorial整体或者其中的任一章节结束的时候,他的结尾,都必须是个有意义的总结,让学习者一顿操作下来是有意义的. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:4:4","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"让你的Tutorial是重复的,可反复操作的(Make your tutorial repeatable) 你的Tutorial必须是非常可靠,可复现的.这点并不容易,原因在于,学习者使用的操作系统可能不一样,经验和使用工具的水平并不一样,更重要的是,学习者使用的软件和资料也与此同时发生了变化. Tutorial必须适应这么多情况,在这些情况下都能正常工作. 所以 Tutorial 需要定期进行详细的测试,以保证它持续的有效. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:4:5","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"聚焦在具体的步骤中,而不是抽象的概念里(Focus on concrete steps, not abstract concepts) Tutorial 必须是具体的,围绕着规格说明进行开展的,有明确的步骤和步骤对应的结果. 进行抽象概念的介绍的诱惑力太大,毕竟,计算机的强大也是来自于此,然而,大多数的学习都是由具体到抽象,反过来是个比较糟糕的学习方式. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:4:6","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"必要的解释要尽量的少(Provide the minimum necessary explanation) 在完成 Tutorial 中不需要了解的知识,不要进行解释.额外的扩展和讨论是可以的,但是不应该出现在 Tutorial 中.在 Tutorial 中,只会令学习者分心,还会干扰学习目的.只有必要的解释才可以放在这部分,其他的可以提供链接导航. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:4:7","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"关注于哪些用户需要执行的步骤 (Focus only on the steps the user needs to take) Tutorial 需要关注的是手头的任务.也许你的命令还有很多的其他的可选项,也许你的API还有很多其他的使用方式,但是对于学习者当前的任务而言,并不需要. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:4:8","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"Divio 中的一个 Tutorial 例子(Example from Divio’s documentation) 可以看下这个 Tutorial 可以着重看下关于 Django 的 Tutorial,如图所示,其实就是在承诺,如果学者具备了基本的前提能力,并且按照文档所述的步骤一步一步的执行,当阅读完之后,将会完成一个用 Django 实现的web应用,其中数据库中用的是 Postgress, S3实现的媒体存储等等.为了达成这样的目标,Tutorial 就需要一步一步填充这些内容. 注意,Tutorial 目录都没有指明学习什么,而聚焦在应该做些什么,做什么的顺序. 如何做的指南(How-to guides) “How-to-guides”是通过指引读者进行一系列的步骤以解决现实中特定的问题。 Guide 是食谱，是为了解决一个特定问题的指导方案。举个例子，如何创建一个web表单；如何启用LDAP权限验证。 guide始终是目标为导向的。 Guide 和 Tutorial完全不同，二者的编写目的和面向的目标都不一样，对此必须有清晰的认识。具体来说，有几下几个差异 Tutorial 是你作为一个作者，想让读者作为一个初学者，需要知道的内容。是作者认为初学者应该知道的。 Guide 是面向有经验的用户，为的是解决他们的一个实际问题。 在编写 Guide 的时候，作者可以假设读者已经具备了常规的知识和理解。可以假设读者已经具备了操作使用作者的软件所需要的基础能力和基本的工具。 和 Tutorial 不同的是, Guide 是比较容易写好的，这部分内容是比较轻松，比较容易写的。 ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:5:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"和烹饪类比 可以想象成某样食物的食谱。 食谱必须清晰明了，有明确的定义。他们描述了一个明确的问题。食谱在向一个有基本烹饪经验的人，如何完成食物的烹饪过程。 从来没有任何烹饪经验的人，只靠食谱，是很难完成一道菜的烹饪的，所以说，食谱本来不是烹饪课的一部份。与此同时，如果有经验的厨师，发现食谱在描述一些他们早就掌握的基础能力，基础的技巧，他们就会很愤怒。 ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:6:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"如果编写一份好的guide(How to write good how-to guides) ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:7:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"提供一系列的步骤(Provide a series of steps) Guide 必须包含一些读者必须操作的步骤（这个在 Tutorial 也有类似的需求）。作者并不需要从头开始描述步骤，以一个相对合理的点进行开始描述即可。Guide 必须是可靠的，但是，Guide 并不需要保证像 Tutorial 一样的可重复性。 ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:7:1","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"聚焦于结果(Focus on results) Guide 必须聚焦于某个特定的目标。与目标无关的任何其他事情都是分心的。和 Tutorial 一样，详细的解释并不适合放这儿。 ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:7:2","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"解决某个特定的问题(Solve a particular problem) Guide 必须的标题命名也必须是有明确指向一个问题的，比如： 如何。。。 Guide 和 Tutorial 的另一个不同点是，阅读 Guide 的人知道自己阅读 Guide 需要什么，最终的目的是什么，他们已经知道阅读完 Guide 自己将获得什么，他们只是不知道该怎么做而已。而对于 Tutorial 而言，读者其实并不知道自己将获得什么，读者阅读完获得的内容，完全是由作者说了算。 ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:7:3","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"不要解释概念(Don’t explain concepts) guide中不需要解释任何东西，guide只适合放些解决问题的步骤，如果有解释的需求，可以进行超链接。 ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:7:4","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"也许允许存在一些弹性变通(Allow for some flexibility) 一份 Guide 针对同一件事应该是允许存在一些不同的处理方式的。Guide中能让读者采取变通的地方应该做到显而易见。不要让guide太过特殊，一点通用型和灵活性都没有。 ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:7:5","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"Leave things out(将事情抛诸脑后) 实用性比完整性更有价值.Tutorial (教程)需要是完整的,有头有尾的指导. Guide 并不需要这样.Guide 可以从作者认为合适的地方开始和结束。Guide 也不需要提及那些仅仅因为它与主题相关,但是并不是关键内容的部分.臃肿的 Guide 并不能帮助用户快速找到解决方案. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:7:6","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"名字很重要(Name guides well) Guide 的标题很重要,标题必须能准确告诉读者,文章的内容具体是干什么的. “How to create a class-based view (如何创建一个基于类的视图)” 就是个很好的标题. 然而像 “(Creating a class-based)创建基于类的视图” 和 “Class-based views (基于类的视图)“就更差劲了. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:7:7","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"Divio 中的 Guide 例子(Example from Divio’s documentation) 看一下这个文档our how-to guides . 这里的每个标题都是在说明内容是一个问题的答案. “how do I…? (如何解决…如何做到…)”. 这些标题里都是在阐述类似的概念\"how to “. 每一个都是一道菜的食谱,都会引导读者完成对应的菜. 虽然我在 Tutorial 和 Guide 都是服务用户的需求.但是,Tutorial 的内容是作者在告诉读者,作者认为读者应该知道的内容. 然而,Guide,是作者在回答读者问的问题. 参考(Reference guides) Reference是机械的技术说明，说明如何进行操作。 Reference只有一个职责，就是进行描述。Reference是面向代码的。从根本上说，描述了关键的class，函数，API，以及罗列一些字段属性，还有方法，同时呢，说明如何使用它们。 Reference是信息导向的。 无论如何，尽管Reference可以包含一些example来演示使用方式，然而呢，依旧不应该试图解释一些基本概念和如何完成常规的需求。 Reference应该是简单直切主题的。 请注意，Reference的描述应该是包含一些机理的基本描述。如：如何初始化一个类，如何调用一个方法，例子，以及调用方法时，参数的限制等等。 对于一些开发者而言，Reference是他们唯一能想到的文档了。他们已经对软件非常熟悉了，也知晓了如何使用了。他们认为学习者就需要这些文档。 Reference比较容易写好，甚至在某种程度上来说，都可以自动生成。但是这还远远不够。 ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:8:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"和烹饪进行类比(Analogy from cooking) 想象一下百科全书上有一篇关于生姜作为原材料的文章。 当你在Reference中查询生姜时，你想要获取的信息都是些像起源，表现，化学机理，以及如何进行烹饪。 你希望你检索的任何食材都以类似的方式展示信息。而且你希望获取一些基本扩展信息，比如生姜家族还有姜粉，还有豆蔻等等。 还有一些潜在问题风险也是我们想获取的。比如。生姜可能会导致胃灼热，与一些抗凝血的药一起食用会有副作用。 ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:9:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"如何写一篇好的 Reference(How to write good reference guides) ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:10:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"Reference是围绕代码进行结构的组织(Structure the documentation around the code) 将reference的结构和代码的结构保持一致，这样使用者看代码的同时，可以同时看到reference。这种方式也有利于开发维护文档，及时知晓哪块缺少文档，哪块需要更新。 ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:10:1","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"保持连贯性(Be consistent) 在书写Reference的过程中，结构，语气和格式都需要保持一致。就像一本百科全书和字典那样。 ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:10:2","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"只做内容描述(Do nothing but describe) 技术Reference只需要尽可能的描述完整，描述清楚就行。其他的像解释，讨论，指导，命令，猜测，观点等等，不仅会让读者分心，也会让Reference难以使用，维护困难。可以在适当的时候，在Reference中提供简单的example进行演示。 不要在Reference中忍不住指引读者，使用超出基本操作之外的操作来完成某项完整的需求.更不要在 reference 中试图对一些概念进行解释或者进行一些主题讨论.相反,如果有类似的需求,可以放一个链接,导航到 Guide,Explanation 和 Tutorial 部分. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:10:3","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"一定要精确 (Be accurate) Reference 这部分的内容必须时刻保持最新,紧跟软件的更新和发展,但凡 reference 和软件有一丝的不一致,就可能将读者或者用户带入沟里. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:10:4","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"以Divio的文档作为例子(Example from Divio’s documentation) 可以看下这个链接里的例子 这是个典型的 Reference 文档,这里是展示的命令行工具的解释. 这里的描述就是如本文上述的内容一样,完整而精确地展示了这个工具的的功能,命令以及命令的参数. 这部分的内容的易读性可能没那么好,但是这部分的目的是为了尽快无干扰的找到相关功能的信息. Explanation Explanation(解释) 或者 discussion(讨论)是要阐明一个特定的主题. 这其实扩大了文档对主题的覆盖范围. Explanation(解释) 是面向理解的. Explanation(解释) 本质上也可以等价于 discussions(讨论) ,他们其实都比较散漫.Explanation(解释) 是在跳出了软件本身,从更高的视野和不同的角度在解释和阐明软件.你可以想象,你的用户在闲暇时间,希望阅读的是文档,而不是源码. 很少有人明确的创建Explanation(解释) 这一章节.而是本该属于这章节的内容分散在了其他的章节里.有时,文档里有对应Explanation(解释) 应有内容的章节,但是这些章节都命名成了\"背景”,或者其他主题形式的记录,这就导致这些命名不能很好的表征内容. Discussions (讨论)并没有看上去的那么容易,想象一下,你手里有张白纸,这时候,有人问了一个问题,该如何进行回答和讨论? 一个topic (主题)不是像 Guide(指南) 一样,解决一个特定的问题,传授一些特有的步骤; 也不是像tutorial(教程)一样,在向读者传授你认为读者他们应该掌握的内容.也不是由机器来决定的 reference . 这部分的内容完全是有作者自己来界定讨论的内容,以及覆盖的范围.所以这部分的内容看上是比较随意的. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:11:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"类比烹饪(Analogy from cooking) 考虑下,在进行历史,科技和科学的上下文和背景下,进行烹饪的讨论. 讨论的内容会是烹饪和厨房. 这部分讨论的内容并不是传授如何烹饪,也不是食谱的集合. 这部分内容只是在进行描述. 相反的,这部分内容是在从多个角度进行阐述分析问题. 可能是在解释为什么我们今天会如此处理事情,或者事情的处理如何糟糕,甚至会描述替代的方案. 这部分内容会加深我们对知识的理解,即使这部分内容并不是立马可应用于实际的业务场景中,但是这部分内容的价值并不是靠在实际的生产应用中体现. 当我们需要闲暇事件,离开厨房的时候,从更高的层次上,来加深对烹饪的理解时,了解更多关厨房的主题时,我们就会选择阅读这部分内容. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:12:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"如何写好一份 explanation(How to write a good explanation) ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:13:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"提供上下文环境(Provide context) Explanations 可以用来提供上下文和背景. 例如,在 Django或者 CMS 中如何处理 Web 表单. 在这部分,可以解释为什么是如此处理,相关的设计决策,历史原因,技术限制等等. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:13:1","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"讨论替代方案和建议意见(Discuss alternatives and opinions) Explanation 可以考虑进行替代方案,或者同一问题的多种不同解决方案.举个例子,在一篇关于 Django 部署的文章中,可以讨论和评估不同的服务器部署. Discussions 也可以用来讨论两种相反的意见和选择. 举个例子,是否需要将测试模块放入源码工程的包下面. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:13:2","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"不要进行指导,也不要提供技术支持(Don’t instruct, or provide technical reference) Explanation 应该做一些其他部分的文档没有做的事情. Explanation 不适合对读者进行指导如何进行操作,也不适合提供技术解决方案.这些内容都是其他文档的职责. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:13:3","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"Example from Divio’s documentation Divio 文档中的一个例子 看一眼这个文档, our explanation section (名称是“Background” -名字并不重要,阐释的主题和内容更加重要). 这些文章没有教任何东西. 他们不会告诉读者该做什么.它们不是 reference . 他们只是讨论特定的话题.举个例子, 读者不需要知道 缓存 或 CDN 亦或是如何管理环境变量来使用平台或完成任何特定任务,但是阅读完这些内容之后,读者的经验和平台的使用能力都会更加清晰,理解也会更加深刻. 这些文章的内容提供了一个更加广阔的图景,更加清晰地上下文. 读者作为一个用户,作为一个使用方,也许他们并不需要知道处理一个问题的方式为何如此.但是当他们知道这些背景和缘由之后,他们会对产品更加满足,自身也会更加的快乐. 关于文档的结构(About the structure) ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:14:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"为什么这个不明显(Why isn’t this obvious?) 这个结构是非常清晰的,而且是能其效果的. 但是为什么让人觉得这个结构没那么明显呢?原因是,这四个类型的文档,处在四个象限,每个象限的和其相邻的象限在特征上是有重叠. 从上图中可以看到,每个象限都和邻居有重叠. Tutorials 和 Guides 都有描述操作步骤; Guides 和 Reference 都有关于我们在工作时应该做的内容. Reference 和 Explanation 都有理论知识的内容. Tutorials 和 Explanation 相较于实际的工作内容,对学习有莫大的帮助. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:15:0","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Other"],"content":"坍塌的趋势(The tendency to collapse) 考虑到这些文档之间的重叠部分,不同类型的文档相互之间变得混淆并相互混合也就不足为奇了.事实上,这些不同类型的文档彼此之间存在一种难以抗拒的力量,让他们之间纠缠不清.它的作用是坍塌式的结构,这就是为什么这么多文档看起来像这样. 省略的内容 后面有一些使用本结构的文档链接和介绍,就不再翻译了. 总结 文章中最后也有说明,不是所有的文档都需要具备齐全这四种类型,最重要的是,知道有这四种类型,注意阅读者的分级分层,内容的重点和意图. ","date":"2021-10-03","objectID":"/2021/10/the-documentation-system_how_to_write_good_document/:15:1","tags":["Documentation"],"title":"文档系统_程序员如何写好文档 (The documentation system)","uri":"/2021/10/the-documentation-system_how_to_write_good_document/"},{"categories":["Android"],"content":"概述 记录我平时使用的一些软件,提效的,娱乐的. 快速打开 Raycast Alfred Contexts ","date":"2021-07-06","objectID":"/2021/07/mysoftware/:0:0","tags":["Android","Java"],"title":"mySoftware","uri":"/2021/07/mysoftware/"},{"categories":["Android"],"content":"目的: 用于快速打开应用软件和文件夹 其中比较知名的就是 Alfread了,我目前把它和Context进行配合使用. Raycast 和 Alfred 差不多,Raycast 我装了,但是用的频率不高,目前没发现他有什么特别的亮点,用来作为 Alfred 的备选,毕竟免费. Context有一个feature就是可以切换window,比如,AndroidStudio里打开了多个Project,形成了多个window,这说话,直接Alfred打开Androidstudio的话,只是打开了软件,至于哪个Window,有时候不清楚,这种情况下,Context 是个很好的补充. Context 的缺陷就是,他只是用来打开,已有的窗口的. 输入法 搜狗输入法 目前国内也就搜狗输入法还行了,当然百度也有Mac版本,但是体验上,还是搜狗好点. 终端 iterm2 oh-my-zsh Mac 下很好的终端工具了.目前没发现其他替代品; Git fork Native开发,相比对sourceTree,颜值和性能都更高,无他,颜值即正义. Android开发 AndroidStudio 开发Android必备,只是有一点至今让我诟病的地方,就是ActivityStack的打印被删除了… C/Cpp开发 Clion VSC配置cpp开发环境也试过,繁琐.Mac 下的Xcode也用过,感觉一般, 不得不说,jetbrains做的IDE,真香. Java开发 IntellijIdea Eclipse NetBeans 目前在用的就是 IntellijIdea 了,其他的基本不用了.只有一个 NetBeans 在某些场景下是有优势的,那就是JavaSE GUI开发的时候. 清除广告 AdBlock Pro 清除Safari广告用; 看动漫太多的广告了,Chrome 上清除广告很容易,Safari就只能依赖这个plugin了. database DataGrip 一个客户端,支持查看所有的数据库,jetbrains太香了. 分屏 Grid windows 系统有个自动管理窗口的功能,这个软件就是在Mac上实现类似的功能; 扩展屏幕 Deskreen 只要有个浏览器就可以实现屏幕的扩展,有时候可以将自己的iPad用上. statusbar 隐藏图标 Dozer Bartender Dozer是开源的,Bartender 是收费的. 画图 draw.io OmniGraffle draw.io 比较简单; OmniGraffle 是收费的,而且入门的门槛很高.但是自定义很方便; 屏幕用时记录 Eye Monitor RescueTime 第一个是用来当前屏幕用了多久,提醒使用者可以休息了; RescueTime 可以将所有使用的时间进行归类,每星期一封邮件,也可以在控制台上查看; 笔记类 Focalboard Notion 我来 OneNote 语雀 OneNote 传统的笔记本,最好的点在于,他就像一个实体的笔记本概念. Notion 现在很火爆的笔记本,可以实现很多的功能,报表,看板,自定义数据库等等; Focalboard 作为Notion的开源替代版本;最重要是有看板; 我来是国产的notion,目前还有待完善; 语雀是蚂蚁金服出品,传统的笔记当中做的比较完善的,加上在线的Markdown渲染的很好,有免费的cdn,速度很快; 破解反编译 Hopper Disassembler IDA Pro 7.0 浏览器 Microsoft Edge chrome Firefox TorBrowser TODO Microsoft To Do 音乐 NeteaseMusic API Postman 截图 Snipaste 截图软件很多,偏爱他的原因是截图完之后,可以将截出来的图片pin在屏幕上,常有需要对比图片的时候,这样可以pin多个,放在一起对比. 快捷打开 Shortcat 快速触达系统的功能的快捷方式. 聊天 Telegram Lite Finder TotalFinder 增加Mac自带的Finder; 翻墙 ShadowsocksX-NG 将网页转成App Unite 可以将一个网页转换成Mac App,其实他还是一个内嵌的网页;方便点,我用来将微信读书生成一个App; 解压缩 The Unarchiver 免费好用,支持很多的压缩方式; 阅读源码 Understand Windows下有一个叫SourceInsight的神奇软件,Understand是Mac的SourceInsight; 代码 Visual Studio Code 调试网络 Wireshark 思维导图 XMind ZEN 显示状态栏 eul ","date":"2021-07-06","objectID":"/2021/07/mysoftware/:1:0","tags":["Android","Java"],"title":"mySoftware","uri":"/2021/07/mysoftware/"},{"categories":["java"],"content":"概述 总结自己的 java 知识，按照编码 -\u003e 运行，画了一张图，xmind 导出的图比较大，后续持续更新，迭代这部分的内容。 下面是一些常见的知识,将会慢慢补充进思维导图内 HashMap 原理 可参考的文章 HashMap原理，循环链表是如何产生的 HashMap? ConcurrentHashMap? 相信看完这篇没人能难住你！ 转换红黑树的阈值为何设置为8 官方comment ","date":"2021-07-03","objectID":"/2021/07/java_summary/:0:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"结构 Java 8 之前：数组 + 链表 Java 8 之后：数组 + 链表； ","date":"2021-07-03","objectID":"/2021/07/java_summary/:1:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"存储的对象 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:1:1","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Java7 Entry\u003cK,V\u003e[] table，Entry 是 HashMap 中的一个静态内部类，它有key、value、next、hash（key的hashcode）成员变量。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:1:2","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Java8 TREEIFY_THRESHOLD 用于判断是否需要将链表转换为红黑树的阈值。 HashEntry 修改为 Node。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:1:3","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"负载因子： 给定的默认容量为 16，负载因子为 0.75。Map 在使用过程中不断的往里面存放数据，当数量达到了 16 * 0.75 = 12 就需要将当前 16 的容量进行扩容，而扩容这个过程涉及到 rehash、复制数据等操作，所以非常消耗性能。 因此通常建议能提前预估 HashMap 的大小最好，尽量的减少扩容带来的性能损耗。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:2:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"put 操作 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:3:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Java7 判断当前数组是否需要初始化。 如果 key 为空，则 put 一个空值进去。 根据 key 计算出 hashcode。 根据计算出的 hashcode 定位出所在桶。 如果桶是一个链表则需要遍历判断里面的 hashcode、key 是否和传入 key 相等，如果相等则进行覆盖，并返回原来的值。 如果桶是空的，说明当前位置没有数据存入，新增一个 Entry 对象写入当前位置。 当调用 addEntry 写入 Entry 时需要判断是否需要扩容。如果需要就进行两倍扩充，并将当前的 key 重新 hash 并定位。而在 createEntry 中会将当前位置的桶传入到新建的桶中，如果当前桶有值就会在位置形成链表。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:3:1","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Java8 当 Hash 冲突严重时，在桶上形成的链表会变的越来越长，这样在查询时的效率就会越来越低；时间复杂度为 O(N)，因此 1.8 中重点优化了这个查询效率。 判断当前桶是否为空，空的就需要初始化（在resize方法 中会判断是否进行初始化）。 根据当前 key 的 hashcode 定位到具体的桶中并判断是否为空，为空表明没有 Hash 冲突就直接在当前位置创建一个新桶即可。 如果当前桶有值（ Hash 冲突），那么就要比较当前桶中的 key、key 的 hashcode 与写入的 key 是否相等，相等就赋值给 e,在第 8 步的时候会统一进行赋值及返回。 如果当前桶为红黑树，那就要按照红黑树的方式写入数据。 如果是个链表，就需要将当前的 key、value 封装成一个新节点写入到当前桶的后面（形成链表）。 接着判断当前链表的大小是否大于预设的阈值，大于时就要转换为红黑树。 如果在遍历过程中找到 key 相同时直接退出遍历。 如果 e != null 就相当于存在相同的 key,那就需要将值覆盖。 最后判断是否需要进行扩容。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:3:2","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"get 操作 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:4:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Java7 首先也是根据 key 计算出 hashcode，然后定位到具体的桶中。 判断该位置是否为链表。 不是链表就根据 key、key 的 hashcode 是否相等来返回值。 为链表则需要遍历直到 key 及 hashcode 相等时候就返回值。 啥都没取到就直接返回 null 。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:4:1","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Java8 首先将 key hash 之后取得所定位的桶。 如果桶为空则直接返回 null 。 否则判断桶的第一个位置(有可能是链表、红黑树)的 key 是否为查询的 key，是就直接返回 value。 如果第一个不匹配，则判断它的下一个是红黑树还是链表。 红黑树就按照树的查找方式返回值。 不然就按照链表的方式遍历匹配返回值。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:4:2","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"HashMap 自身的缺陷 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:5:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"循环链表 修改为红黑树之后查询效率直接提高到了 O(logn)。但是 HashMap 原有的问题也都存在，比如在并发场景下使用时容易出现死循环： 在 HashMap 扩容的时候会调用 resize() 方法，就是这里的并发操作容易在一个桶上形成环形链表；这样当获取一个不存在的 key 时，计算出的 index 正好是环形链表的下标就会出现死循环：在 1.7 中 hash 冲突采用的头插法形成的链表，在并发条件下会形成循环链表，一旦有查询落到了这个链表上，当获取不到值时就会死循环。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:5:1","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"死循环 形成循环链表后，一旦有查询落到了这个链表上，当获取不到值时就会死循环。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:5:2","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"非线程安全 就如上所说的两个问题，都是并发导致的问题。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:5:3","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"扩容相关 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:6:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"何时扩容 当向容器添加元素的时候，会判断当前容器的元素个数，如果大于等于阈值—即大于当前数组的长度乘以加载因子的值的时候，就要自动扩容。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:6:1","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"扩容的算法是什么 扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:6:2","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Hashmap如何解决散列碰撞？ Java中HashMap是利用“拉链法”处理HashCode的碰撞问题。在调用HashMap的put方法或get方法时，都会首先调用hashcode方法，去查找相关的key，当有冲突时，再调用equals方法。hashMap基于hasing原理，我们通过put和get方法存取对象。当我们将键值对传递给put方法时，他调用键对象的hashCode()方法来计算hashCode，然后找到bucket（哈希桶）位置来存储对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当碰撞发生了，对象将会存储在链表的下一个节点中。hashMap在每个链表节点存储键值对对象。当两个不同的键却有相同的hashCode时，他们会存储在同一个bucket位置的链表中。键对象的equals()来找到键值对。 额外补充，其他解决办法是， 开放地址法，但是这个方法浪费存储空间，空间利用率很低。适用于规模很小的场景； 再hash法，进行二次、三次hash； ","date":"2021-07-03","objectID":"/2021/07/java_summary/:7:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"数组大小为何是 2 的倍数 与运算比或运算效率高，提高速度； 减少hash冲突； 整体为了提高散列的均匀性。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:8:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"红黑树 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:9:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"为何需要转换成红黑树 每次遍历一个链表，平均查找的时间复杂度是 O(n)，n 是链表的长度。红黑树有和链表不一样的查找性能，由于红黑树有自平衡的特点，可以防止不平衡情况的发生，所以可以始终将查找的时间复杂度控制在 O(log(n))。最初链表还不是很长，所以可能 O(n) 和 O(log(n)) 的区别不大，但是如果链表越来越长，那么这种区别便会有所体现。所以为了提升查找性能，需要把链表转化为红黑树的形式。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:9:1","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"那为什么不一开始就用红黑树，反而要经历一个转换的过程呢？ 因为树节点(TreeNodes)所占的空间是普通节点Node的两倍，所以我们只有在桶中包含足够的节点时才使用树节点(请参阅TREEIFY_THRESHOLD)(只有在同一个哈希桶中的节点数量大于等于TREEIFY_THRESHOLD时，才会将该桶中原来的链式存储的节点转化为红黑树的树节点)。并且当桶中的节点数过少时 (由于移除或调整)，树节点又会被转换回普通节点(当桶中的节点数量过少时，原来的红黑树树节点又会转化为链式存储的普通节点)，以便节省空间。　","date":"2021-07-03","objectID":"/2021/07/java_summary/:9:2","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"阈值的选取 体现了时间和空间平衡的思想 如果 hashCode 分布良好，也就是 hash 计算的结果离散好的话，那么红黑树这种形式是很少会被用到的，因为各个值都均匀分布，很少出现链表很长的情况。在理想情况下，桶(bins)中的节点数概率(链表长度)符合泊松分布，当桶中节点数(链表长度)为 8 的时候，概率仅为 0.00000006。这是一个小于千万分之一的概率，通常我们的 Map 里面是不会存储这么多的数据的，所以通常情况下，并不会发生从链表向红黑树的转换。 阈值为何是 8 和 6，这个是一个概率问题，是用泊松分布计算出来。 ConcurrentHashMap 可以参考的文章 HashTable是一个线程安全的类，它使用synchronized来锁住整张Hash表来实现线程安全，即每次锁住整张表让线程独占，相当于所有线程进行读写时都去竞争一把锁，导致效率非常低下。ConcurrentHashMap可以做到读取数据不加锁，并且其内部的结构可以让其在进行写操作的时候能够将锁的粒度保持地尽量地小，允许多个修改操作并发进行，其关键在于使用了锁分段技术。它使用了多个锁来控制对hash表的不同部分进行的修改。对于JDK1.7版本的实现, ConcurrentHashMap内部使用段(Segment)来表示这些不同的部分，每个段其实就是一个小的Hashtable，它们有自己的锁。只要多个修改操作发生在不同的段上，它们就可以并发进行。JDK1.8的实现降低锁的粒度，JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（首节点）。 JAVA7之前ConcurrentHashMap主要采用锁机制，在对某个Segment进行操作时，将该Segment锁定，不允许对其进行非查询操作，而在JAVA8之后采用CAS无锁算法，这种乐观操作在完成前进行判断，如果符合预期结果才给予执行，对并发操作提供良好的优化. ","date":"2021-07-03","objectID":"/2021/07/java_summary/:9:3","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Put ","date":"2021-07-03","objectID":"/2021/07/java_summary/:10:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Java 7 首先是通过 key 定位到 Segment，之后在对应的 Segment 中进行具体的 put。 虽然 HashEntry 中的 value 是用 volatile 关键词修饰的，但是并不能保证并发的原子性，所以 put 操作时仍然需要加锁处理。 首先第一步的时候会尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则利用 scanAndLockForPut() 自旋获取锁: 尝试自旋获取锁。 如果重试的次数达到了 MAX_SCAN_RETRIES 则改为阻塞锁获取，保证能获取成功。 将当前 Segment 中的 table 通过 key 的 hashcode 定位到 HashEntry。 遍历该 HashEntry，如果不为空则判断传入的 key 和当前遍历的 key 是否相等，相等则覆盖旧的 value。 为空则需要新建一个 HashEntry 并加入到 Segment 中，同时会先判断是否需要扩容。 最后会使用unlock()解除当前 Segment 的锁。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:10:1","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Java 8 根据 key 计算出 hashcode 。 判断是否需要进行初始化。 如果当前 key 定位出的 Node 为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。 如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。 如果都不满足，则利用 synchronized 锁写入数据。 最后，如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:10:2","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Get ","date":"2021-07-03","objectID":"/2021/07/java_summary/:11:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"1.7 只需要将 Key 通过 Hash 之后定位到具体的 Segment ，再通过一次 Hash 定位到具体的元素上。 由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值。 ConcurrentHashMap 的 get 方法是非常高效的，因为整个过程都不需要加锁。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:11:1","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"1.8 根据计算出来的 hashcode 寻址，如果就在桶上那么直接返回值。 如果是红黑树那就按照树的方式获取值。 就不满足那就按照链表的方式遍历获取值。 Java 中的 map 与 Android 的 SparseArray 的比较 SparseArray 比HashMap更省内存，在某些条件下性能更好，主要是因为它避免了对key的自动装箱（int转为Integer类型），它内部则是通过两个数组来进行数据存储的，一个存储 key，另外一个存储 value，为了优化性能，它内部对数据还采取了压缩的方式来表示稀疏数组的数据，从而节约内存空间，我们从源码中可以看到key和value分别是用数组表示： private int[] mKeys; private Object[] mValues; key 的下标 index 和 values 的下标 index 是一一对应的，在查询的时候，可以根据 key 进行二分查找，查找到 index 就是 values 的下标，效率较高。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:11:2","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"ArrayMap 还有一个类是 ArrayMap，结构也是两个数组，一个存储 hash，一个存储 value； 查询的时候，也是二分查找，查找数组里存储的hash值和 key 的 hash 值一致的 下标； ","date":"2021-07-03","objectID":"/2021/07/java_summary/:12:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"对比 0-1,000时，SparseArray 具备更好的性能： 1、如果key的类型已经确定为int类型，那么使用SparseArray，因为它避免了自动装箱的过程，如果key为long类型，它还提供了一个LongSparseArray来确保key为long类型时的使用 2、如果key类型为其它的类型，则使用ArrayMap。 1,000 - 10,000 hashmap 具备更好的插入优势；SparseArray 具备更好的查询优势； 10,000 以上 hashmap 优势降低。 设计模式 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:13:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"创建型（5） ","date":"2021-07-03","objectID":"/2021/07/java_summary/:14:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"单例模式 参考的文章 双重检查锁的意义 外层的判空，是为了提升性能； 内层的加锁是为了原子话； 变量 volatile 是为了防止指令重排； 通过静态内部类实现单例模式有哪些优点？ 不用 synchronized ，节省时间。 调用 getInstance() 的时候才会创建对象，不调用不创建，节省空间，这有点像传说中的懒汉式。 builder 模式，工厂模式， 抽象工厂模式 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:14:1","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"结构型（7） 适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:15:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"行为型（11） 策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:16:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"六大原则 开闭原则是基础 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:17:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"开放封闭原则（Open Close Principle） 对扩展开放，对修改封闭 原则思想：尽量通过扩展软件实体来解决需求变化，而不是通过修改已有的代码来完成变化 描述：一个软件产品在生命周期内，都会发生变化，既然变化是一个既定的事实，我们就应该在设计的时候尽量适应这些变化，以提高项目的稳定性和灵活性。 优点：单一原则告诉我们，每个类都有自己负责的职责，里氏替换原则不能破坏继承关系的体系。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:17:1","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"里氏代换原则（Liskov Substitution Principle） 高度抽象的继承体系，即使增加子类，不需要修改父类 原则思想：使用的基类可以在任何地方使用继承的子类，完美的替换基类。 大概意思是：子类可以扩展父类的功能，但不能改变父类原有的功能。子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法，子类中可以增加自己特有的方法。 优点：增加程序的健壮性，即使增加了子类，原有的子类还可以继续运行，互不影响。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:17:2","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"依赖倒转原则（Dependence Inversion Principle） 面向接口编程，接口需要高度的抽象 依赖倒置原则的核心思想是面向接口编程. 依赖倒转原则要求我们在程序代码中传递参数时或在关联关系中，尽量引用层次高的抽象层类， 这个是开放封闭原则的基础，具体内容是：对接口编程，依赖于抽象而不依赖于具体。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:17:3","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"接口隔离原则（Interface Segregation Principle）‘ 接口的信息要合适，不需要含有复杂冗余的方法 这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。还是一个降低类之间的耦合度的意思，从这儿我们看出，其实设计模式就是一个软件的设计思想，从大型软件架构出发，为了升级和维护方便。所以上文中多次出现：降低依赖，降低耦合。 例如：支付类的接口和订单类的接口，需要把这俩个类别的接口变成俩个隔离的接口 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:17:4","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"迪米特法则（最少知道原则）（Demeter Principle） 知道的越少越好 原则思想：一个对象应当对其他对象有尽可能少地了解，简称类间解耦 大概意思就是一个类尽量减少自己对其他对象的依赖，原则是低耦合，高内聚，只有使各个模块之间的耦合尽量的低，才能提高代码的复用率。 优点：低耦合，高内聚。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:17:5","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"单一职责原则（Principle of single responsibility） 聚焦 原则思想：一个方法只负责一件事情。 描述：单一职责原则很简单，一个方法 一个类只负责一个职责，各个职责的程序改动，不影响其它程序。 这是常识，几乎所有程序员都会遵循这个原则。 优点：降低类和类的耦合，提高可读性，增加可维护性和可拓展性，降低可变性的风险。 动态代理原理及实现 静态代理通常只代理一个类，动态代理是代理一个接口下的多个实现类。 静态代理事先知道要代理的是什么，而动态代理不知道要代理什么东西，只有在运行时才知道。 动态代理是实现 JDK 里的 InvocationHandler 接口的 invoke 方法，但注意的是代理的是接口，也就是你的业务类必须要实现接口，通过 Proxy 里的 newProxyInstance 得到代理对象。还有一种动态代理 CGLIB，代理的是类，不需要业务类继承接口，通过派生的子类来实现代理。通过在运行时，动态修改字节码达到修改类的目的。AOP 编程就是基于动态代理实现的，比如著名的 Spring 框架、Hibernate 框架等等都是动态代理的使用例子。 final List\u003cString\u003e list = new ArrayList\u003cString\u003e(); List\u003cString\u003e proxyInstance = (List\u003cString\u003e) Proxy.newProxyInstance(list.getClass().getClassLoader(), list.getClass().getInterfaces(), new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { return method.invoke(list, args); } }); proxyInstance.add(\"你好\"); System.out.println(list); 问题1：为什么 JDK 动态代理要基于接口实现？而不是基于继承来实现？ 解答：因为 JDK 动态代理生成的对象默认是继承 Proxy ，Java 不支持多继承，所以 JDK 动态代理要基于接口来实现。 问题2：JDK 动态代理中，目标对象调用自己的另一个方法，会经过代理对象么？ 解答：内部调用方法使用的对象是目标对象本身，被调用的方法不会经过代理对象。 应用 Retrofit 应用：Retrofit 通过动态代理，为我们定义的请求接口都生成一个动态代理对象，实现请求 静态嵌套类和内部类的区别 静态嵌套类：Static Nested Class是被声明为静态（static）的内部类，它可以不依赖于外部类实例被实例化。 内部类：需要在外部类实例化后才能实例化，其语法看起来挺诡异的。 反射 反射的核心是 JVM 在运行时才动态加载类或调用方法/访问属性，它不需要事先（写代码的时候或编译期）知道运行对象是谁。 Java 反射主要提供以下功能： 在运行时判断任意一个对象所属的类； 在运行时构造任意一个类的对象； 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）； 在运行时调用任意一个对象的方法 重点：是运行时而不是编译时。 要想解剖一个类,必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法.所以先要获取到每一个字节码文件对应的Class类型的对象. 注解 三种类型的注解 SOURCE：存在于源码级别，编译期可以读取，但是不会保存到 class 文件中； CLASS：编译级别，存在于 class 文件中，但是运行时会被丢弃； RUNTIME：存储在 class 文件中，并且 vm 运行时也会保留，可以通过反射获取； [@Retention(RetentionPolicy.RUNTIME) public @interface Description { String value(); }](\u003c@Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) public @interface CustomAnnotation{ }\u003e) @SupportedAnnotationTypes(\"com.example.CustomAnnotation\") public class CompileTimeAnnotationProcessor extends AbstractProcessor { @Override public boolean process(Set\u003c? extends TypeElement\u003e annotations, RoundEnvironment roundEnv) { Set\u003c? extends Element\u003e elements = roundEnv.getElementsAnnotatedWith(CustomAnnotation.class); for(Element e : elements){ if(!e.getClass().equals(ParticularType.class)){ processingEnv.getMessager().printMessage(Kind.ERROR, \"@CustomAnnotation annotated fields must be of type ParticularType\"); } } return true; } } 泛型 参数化类型，操作的类型以参数的形式传递。可以用于类、接口、方法中。 目的是为了安全。 型是Java SE1.5的新特性，泛型的本质是参数化类型，也就是说所操的数据类型被指定为一个参数。这种参数类型可以用在类、接口和方法的创建中，分别称为泛型类、泛型接口、泛型方法。 Java语言引入泛型的好处是安全简单。 在Java SE 1.5之前，没有泛型的情况的下，通过对类型Object的引用来实现参数的“任意化”，“任意化”带来的缺点是要做显式的强制类型转换，而这种转换是要求开发者实际参数类型可以预知的情况下进行的。对于强制类型换错误的情况，编译器可能不提示错误，在运行的时候出现异常，这是一个安全隐患。 泛型的好处是在编译的时候检查类型安全，并且所有的转换都是自动和隐式的，提高代码的重用率。 1、泛型的类型参数只能是类类型（包括自定义类），不是简单类型。 2、同一种泛型可以对应多个版本（因为参数类型是不确的），不同版本的泛型类实例是不兼容的。 3、泛型的类型参数可以有多个。 4、泛型的参数类型可以使用 extends 语句，例如。习惯上称为“有界类型”。 5、泛型的参数类型还可以是通配符类型。例如 Class\u003c?\u003e classType = Class.forName(\"java.lang.String\"); ","date":"2021-07-03","objectID":"/2021/07/java_summary/:17:6","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"泛型擦除以及相关的概念 泛型的信息只存在编译期间，等到进入 jvm 时候，已经被擦除； 擦除的时候，如果有指定上限，则使用上限，没指定，则使用 object； 泛型信息只存在代码编译阶段，在进入JVM之前，与泛型关的信息都会被擦除掉。 在类型擦除的时候，如果泛型类里的类型参数没有指定上限，则会被转成Object类型，如果指定了上限，则会被传转换成对应的类型上限。 Java中的泛型基本上都是在编译器这个层次来实现的。生成的Java字节码中是不包含泛型中的类型信息的。使用泛型的时候加上的类型参数，会在编译器在编译的时候擦除掉。这个过程就称为类型擦除。 类型擦除引起的问题及解决方法： 1、先检查，在编译，以及检查编译的对象和引用传递的题 2、自动类型转换 3、类型擦除与多态的冲突和解决方法 4、泛型类型变量不能是基本数据类型 5、运行时类型查询 6、异常中使用泛型的问题 7、数组（这个不属于类型擦除引起的问题） 9、类型擦除后的冲突 10、泛型在静态方法和静态类中的问题 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:18:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"协变和逆变；大名鼎鼎的 PECS （producer extend，consumer super），往两头扩散； 将 collection 视为 product 还是 consumer 四种引用 强引用： 使用最普遍的引用。只要引用链没有断开，强引用就不会断开。当内存空间不足，抛出OutOfMemoryError终止程序也不会回收具有强引用的对象。通过将对象设置为null来弱化引用,使其被回收 软引用 对象处在有用但非必须的状态。只有当内存空间不足时, GC会回收该引用的对象的内存。可以用来实现高速缓存（作用）–比如网页缓存、图片缓存。 弱引用 弱引用就是只要JVM垃圾回收器发现了它，就会将之回收。非必须的对象,比软引用更弱一些。GC时会被回被回收的概率也不大,因为GC线程优先级比较低。适用于引用偶尔被使用且不影响垃圾收集的对象。 虚引用 不会决定对象的生命周期。任何时候都可能被垃圾收集器回收。跟踪对象被垃圾收集器回收的活动,起哨兵作用。 必须和引用队列ReferenceQueue联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会把这个虚引用加入到与之 关联的引用队列中。 程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。用来跟踪对象的 gc 活动。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:19:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"LeakCanary 的应用 可以参考的文章 通过一个 Java 演示原理 ； LeakCanary 的检测原理是： 弱引用对象在其包装对象被回收后（弱引用对象创建时，传入了引用队列），该弱引用对象会被加到引用队列中（ReferenceQueue）。 通过在 ReferenceQueue 中检测是否有目标对象的弱引用对象存在，即可判断目标对象是否被回收。如果在队列中，则说明是回收了，不存在内存泄漏，反之则存在内存泄漏； 为什么要放入空闲消息里面去执行？ 因为gc就是发生在系统空闲的时候的，所以当空闲消息被执行的时候，大概率已经执行过一次gc了。 为什么在空闲消息可以直接检测activity是否被回收？ 跟问题1一样，空闲消息被执行的时候，大概率已经发生过gc，所以可以检测下gc后activity是否被回收。 如果没有被回收，应该是已经泄漏了啊，为什么再次执行了一次gc，然后再去检测？ 根据问题2，空闲消息被执行的时候，大概率已经发生过gc，但是也可能还没发生gc，那么此时activity没有被回收是正常的，所以我们手动再gc一下，确保发生了gc，再去检测activity是否被回收，从而100%的确定是否发生了内存泄漏。 ThreadLocal 可以参考的文章 ThreadLocal原理及魔数0x61c88647 ThreadLocal是一种线程封闭技术。ThreadLocal提供了get和set等访问接口或方法，这些方法为每个使用该变量的线程都存有一份独立的副本，因此get总是返回由当前执行线程在调用set时设置的最新值。 从ThreadLocal的set和get方法可以看出，它们所操作的对象都是当前线程的localValues对象的table数组，因此在不同线程中访问同一个ThreadLocal的set和get方法，它们对ThreadLocal所做的读写操作仅限于各自线程的内部，这就是为什么ThreadLocal可以在多个线程中互不干扰地存储和修改数据。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:20:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"example private static final ThreadLocal\u003cInteger\u003e threadIds = new ThreadLocal\u003c\u003e(); Integer id = threadIds.get(); if (id == null) { id = nextThreadId.getAndIncrement(); threadIds.set(id); } 一个 threadlocal 只能维护一个变量；等价于每一个线程私有变量都需要 new 一个 threadlocal 实例。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:21:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"内存泄漏问题 threadLocalMap 使用 ThreadLocal 的弱引用作为 key，如果一个 ThreadLocal 不存在外部强引用时，Key(ThreadLocal) 势必会被 GC 回收，这样就会导致 ThreadLocalMap 中 key 为 null， 而 value 还存在着强引用，只有 thead 线程退出以后,value 的强引用链条才会断掉。 但如果当前线程再迟迟不结束的话，这些 key 为 null 的 Entry 的 value 就会一直存在一条强引用链： Thread Ref -\u003e Thread -\u003e ThreaLocalMap -\u003e Entry -\u003e value 永远无法回收，造成内存泄漏。 就比如线程池里面的线程，线程都是复用的，那么之前的线程实例处理完之后，出于复用的目的线程依然存活，所以，ThreadLocal设定的value值被持有，导致内存泄露。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:22:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"ThreadLocal 正确的使用方法 每次使用完 ThreadLocal 都调用它的 remove() 方法清除数据。 将 ThreadLocal 变量定义成 private static，这样就一直存在 ThreadLocal 的强引用，也就能保证任何时候都能通过 ThreadLocal 的弱引用访问到Entry的value值，进而清除掉 。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:23:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"使用场景 线程间的数据隔离 在Android中，Looper类就是利用了ThreadLocal的特性，保证每个线程只存在一个Looper对象。 当某些数据是以线程为作用域并且不同线程具有不同的数据副本的时候，就可以考虑采用ThreadLocal。 为什么Java里的匿名内部类只能访问final修饰的外部变量？ public class TryUsingAnonymousClass { public void useMyInterface() { final Integer number = 123; System.out.println(number); MyInterface myInterface = new MyInterface() { @Override public void doSomething() { System.out.println(number); } }; myInterface.doSomething(); System.out.println(number); } } // 编译后的结果 class TryUsingAnonymousClass$1 implements MyInterface { private final TryUsingAnonymousClass this$0; private final Integer paramInteger; TryUsingAnonymousClass$1(TryUsingAnonymousClass this$0, Integer paramInteger) { this.this$0 = this$0; this.paramInteger = paramInteger; } public void doSomething() { System.out.println(this.paramInteger); } } 因为匿名内部类最终会编译成一个单独的类，而被该类使用的变量会以构造函数参数的形式传递给该类，例如：Integer paramInteger，这个时候修改传入的参数并不能改动到外部类的变量。这变量相当于脱离了之前类的生命周期。 如果变量不定义成 final 的，paramInteger在匿名内部类被可以被修改，进而造成和外部的paramInteger不一致的问题，为了避免这种不一致的情况，因次Java规定匿名内部类只能访问final修饰的外部变量。 ConcurrentModificationException ","date":"2021-07-03","objectID":"/2021/07/java_summary/:24:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"出现的原因： 在 ArrayList 中，在迭代遍历 list 的过程中，修改了 list 的大小时，就会抛出这个并发修改的异常。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:25:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"解决方案 Collections.synchronizedList(new ArrayList\u003c\u003e())，将对 list 的操作修改为线程安全的，带来的损失是性能损耗； 改成 CopyOnWriteArrayList （推荐这种）； ","date":"2021-07-03","objectID":"/2021/07/java_summary/:26:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"CopyOnWriteArrayList /** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return {@code true} (as specified by {@link Collection#add}) */public boolean add(E e) { synchronized (lock) { Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; } } 针对修改 list 内容的变更，不在原有的数据上修改，而是进行 copy，修改完成之后，调用setArray(newElements); 重新指向新数据即可。 java.util.concurrent 包的学习 参考资料一 locks部分：显式锁(互斥锁和速写锁)相关； atomic部分：原子变量类相关，是构建非阻塞算法的基础； executor部分：线程池相关； collections部分：并发容器相关； tools部分：同步工具相关，如信号量、闭锁、栅栏等功能； ","date":"2021-07-03","objectID":"/2021/07/java_summary/:27:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"一些常见的类 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"BlockingQueue 此接口是一个线程安全的 存取实例的队列。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:1","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"ArrayBlockingQueue ArrayBlockingQueue 是一个有界的阻塞队列。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:2","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"DelayQueue DelayQueue 对元素进行持有直到一个特定的延迟到期，才能得到运行。注入其中的元素必须实现 java.util.concurrent.Delayed 接口。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:3","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"LinkedBlockingQueue 内部以一个链式结构(链接节点)对其元素进行存储 。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:4","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"PriorityBlockingQueue 一个无界的并发队列，它使用了和类 java.util.PriorityQueue 一样的排序规则。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:5","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"SynchronousQueue 一个特殊的队列，它的内部同时只能够容纳单个元素。 如果该队列已有一元素的话，试图向队列中插入一个新元素的线程将会阻塞，直到另一个线程将该元素从队列中抽走。 如果该队列为空，试图向队列中抽取一个元素的线程将会阻塞，直到另一个线程向队列中插入了一条新的元素。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:6","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"BlockingDeque 此接口表示一个线程安全放入和提取实例的双端队列。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:7","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"LinkedBlockingDeque LinkedBlockingDeque 是一个双端队列，可以从任意一端插入或者抽取元素的队列。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:8","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"ConcurrentMap 一个能够对别人的访问(插入和提取)进行并发处理的 java.util.Map接口。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:9","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"ConcurrentNavigableMap 一个支持并发访问的 java.util.NavigableMap，它还能让它的子 map 具备并发访问的能力。 其中有 headMap tailMap 等方法，可以指定范围的子集。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:10","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"CountDownLatch CountDownLatch 是一个并发构造，它允许一个或多个线程等待一系列指定操作的完成。 CountDownLatch 以一个给定的数量初始化。countDown() 每被调用一次，这一数量就减一。 通过调用 await() 方法之一，线程可以阻塞等待这一数量到达零。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:11","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"CyclicBarrier CyclicBarrier 类是一种同步机制，它能够对处理一些算法的线程实现同步。 循环的障碍物，可以反复使用。 适用于，执行一组固定大小，且偶尔需要彼此相互等待的线程。 等待的线程是需要阻塞的，与 CountDownLatch 的区别是，CountDownLatch 只是进行了计数而已，不会被阻塞，CyclicBarrier 的线程是会被阻塞的。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:12","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Exchanger 参考资料 Exchanger 是 JDK 1.5 开始提供的一个用于两个工作线程之间交换数据的封装工具类，简单说就是一个线程在完成一定的事务后想与另一个线程交换数据，则第一个先拿出数据的线程会一直等待第二个线程，直到第二个线程拿着数据到来时才能彼此交换对应数据。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:13","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Semaphore 控制许可集，控制多个共享资源的计数器。 保护一个重要(代码)部分防止一次超过 N 个线程进入。 在两个线程之间发送信号。 用于保护重要的数据 如果你将信号量用于保护一个重要部分，试图进入这一部分的代码通常会首先尝试获得一个许可，然后才能进入重要部分(代码块)，执行完之后，再把许可释放掉。 用于通信，在线程之间发送信号 如果你将一个信号量用于在两个线程之间传送信号，通常你应该用一个线程调用 acquire() 方法，而另一个线调用 release() 方法。 如果没有可用的许可，acquire() 调用将会阻塞，直到一个许可被另一个线程释放出来。 如果无法往信号量释放更多许可时，一个 release() 调用也会阻塞。 使用场景 限制同时访问资源的线程总数； 流量控制； ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:14","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"ReentrantLock 可参考的文章1 可参考的文章2 可参考的文章3 可参考的文章4 ReentrantLock可以尝试获取锁与设置获取锁的时限，需要手动释放锁 synchronized不能扩展锁之外的方法或者块边界，尝试获取锁时不能中途取消，获取不到锁会阻塞，synchronized正常或异常退出会自动释放锁。 可重入锁，可以对同一把锁，多次上锁； 公平锁，FIFO，有队列，先进先出；默认是非公平的；每次 acquire 的时候，都检查等待最长时间的线程； Synchronized 获取锁的行为是不公平的，并非是按照申请对象锁的先后时间分配锁的，每次对象锁被释放时，每个线程都有机会获得对象锁，这样有利于提高执行性能，但是也会造成线程饥饿现象。 ReentrantLock 常用的方法有哪些？ ReentrantLock 常见方法如下： lock()：用于获取锁 unlock()：用于释放锁 tryLock()：尝试获取锁 getHoldCount()：查询当前线程执行 lock() 方法的次数 getQueueLength()：返回正在排队等待获取此锁的线程数 isFair()：该锁是否为公平锁 ReentrantLock 有哪些优势 灵活性，自主可控； 具备等待超时机制； 具备构造公平锁的能力； 可以感知等待锁的线程数量； 可以被中断； ReentrantLock 有哪些缺点 需要使用 import 引入相关的 Class 不能忘记在 finally 模块释放锁,这个看起来比 synchronized 丑陋 synchronized 可以放在方法的定义里面, 而 reentrantlock 只能放在块里面. 比较起来, synchronized 可以减少嵌套 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:15","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"ExecutorService 是一个接口，约定了一些方法，用以管理多个异步任务的执行，可以获取执行任务的 future，用以跟踪任务的执行。 可以执行任务，关闭任务等。 基于此，有一个线程池实现类 - ThreadPoolExecutor。 为什么需要线程池 线程是很重的资源，JVM 的线程和系统的线程是一一对应的，创建和销毁都是系统调用，是很消耗资源的； 线程不少越多越好，线程是 CPU 调度的最小单位,但 CPU 的核心数有限，同时能运行的线程数有限，所以需要根据调度算法切换执行的线程，而线程的切换需要开销，比如替换寄存器的内容、高速缓存的失效等等。如果线程数太多，切换的频率就变高，可能使得多线程带来的好处抵不过线程切换带来的开销，得不偿失。 小结一下： Java中线程与操作系统线程是一比一的关系。 线程的创建和销毁是一个“较重”的操作。 多线程的主要是为了提高 CPU 的利用率。 线程的切换有开销，线程数的多少需要结合 CPU核心数与 I/O 等待占比。IO 占比高的，可以适当提高线程数，以充分利用 CPU 资源； 所以 控制线程的数量； 缓存一批线程，避免重复的创建和销毁； 线程池 可以参考的资源1 线程池就是事先将多个线程对象放到一个容器中，使用的时候就不用new线程而是直接去池中拿线程即可，节省了开辟子线程的时间，提高了代码执行效率。 熟悉对象池、连接池的朋友肯定对池化技术不陌生，一般池化技术的使用方式是从池子里拿出资源，然后使用，用完了之后归还。但是线程池的实现不太一样，不是说我们从线程池里面拿一个线程来执行任务，等任务执行完了之后再归还线程，你可以想一下这样做是否合理。线程池的常见实现更像是一个黑盒存在，我们设置好线程池的大小之后，直接往线程池里面丢任务，然后就不管了。 线程池其实是一个典型的生产者-消费者模式。 自己设计一个线程池 一个队列，用以存放 task 任务； 一个线程集合，用以执行任务； 定义拒绝策略； 线程池讲白了就是存储线程的一个容器，池内保存之前建立过的线程来重复执行任务，减少创建和销毁线程的开销，提高任务的响应速度，并便于线程的管理。 我个人觉得如果要设计一个线程池的话得考虑池内工作线程的管理、任务编排执行、线程池超负荷处理方案、监控。 初始化线程数、核心线程数、最大线程池都暴露出来可配置，包括超过核心线程数的线程空闲消亡配置。 任务的存储结构可配置，可以是无界队列也可以是有界队列，也可以根据配置分多个队列来分配不同优先级的任务，也可以采用 stealing 的机制来提高线程的利用率。 ThreadPoolExecutor 是个线程池实现类。 简单来说线程池把任务的提交和任务的执行剥离开来，当一个任务被提交到线程池之后： 如果此时线程数小于核心线程数，那么就会新起一个线程来执行当前的任务。 如果此时线程数大于核心线程数，那么就会将任务塞入阻塞队列中，等待被执行。 如果阻塞队列满了，并且此时线程数小于最大线程数，那么会创建新线程来执行当前任务。 如果阻塞队列满了，并且此时线程数大于最大线程数，那么会采取拒绝策略。 任务是先入队，还是先执行？ 看两个条件 core 线程数； 任务队列是否已满； 线程数达到核心数的时候，如果任务队列未满 任务是先入队，而不是先创建最大线程数。 线程数达到核心数的时候，如果任务队列满了 如果任务队列也满了，新增最大线程数的线程时，任务是可以直接给予新建的线程执行的，而不是入队。 什么时候创建非核心线程 核心线程忙碌状态； 等待队列已满； 此时线程数小于核心线程数，并且线程都处于空闲状态，现提交一个任务，是新起一个线程还是给之前创建的线程？ When a new task is submitted in method `[execute(java.lang.Runnable)](https://developer.android.com/reference/java/util/concurrent/ThreadPoolExecutor#execute(java.lang.Runnable))`, if fewer than corePoolSize threads are running, a new thread is created to handle the request, even if other worker threads are idle. 参考链接 答案 ：新创建一个线程执行任务。 原生线程池的核心线程一定伴随着任务慢慢创建的吗？ 并不是，线程池提供了两个方法： prestartCoreThread：启动一个核心线程 prestartAllCoreThreads ：启动所有核心线程 不要小看这个预创建方法，预热很重要，不然刚重启的一些服务有时是顶不住瞬时请求的，就立马崩了，所以有预热线程、缓存等等操作。 你是如何理解核心线程的 ? 核心线程指的是线程池承载日常任务的中坚力量，也就是说本质上线程池是需要这么些数量的线程来处理任务的，所以在懒中又急着创建它。 而最大线程数其实是为了应付突发状况。 线程池的核心线程在空闲的时候一定不会被回收吗？ 有个 allowCoreThreadTimeOut 方法，把它设置为 true ，则所有线程都会超时，不会有核心数那条线的存在。 你是怎么理解 KeepAliveTime 的？ 这就是上面提到的，线程池其实想要的只是核心线程数个线程，但是又预留了一些数量来预防突发状况，当突发状况过去之后，线程池希望只维持核心线程数的线程，所以就弄了个 KeepAliveTime，当线程数大于核心数之后，如果线程空闲了一段时间（KeepAliveTime），就回收线程，直到数量与核心数持平。 线程池希望维持的线程数量就是 core 数量的线程，可能存在突发情况，导致线程的数量达到 max，但是突发事件过后，还是希望恢复到常态 core 的数量。 那 workQueue 有什么用？ 缓存任务供线程获取。所以工作队列起到一个缓冲作用，具体队列长度需要结合线程数，任务的执行时长，能承受的等待时间等。 你是如何理解拒绝策略的？ 线程数达到最大值； 队列中的任务数达到最大值； 满足上述两个条件后， 默认实现是 AbortPolicy 直接抛出异常。 直接丢弃任务； 让提交任务的线程自己运行； 淘汰老的未执行的任务而空出位置； 具体用哪个策略，根据场景选择。当然也可以自定义拒绝策略，实现 RejectedExecutionHandler 这个接口即可。 线程池里的 ctl 的作用？ 工作线程数和线程池状态结合在一起维护，低 29 位存放 workerCount，高 3 位存放 runState。 其实并发包中有很多实现都是一个字段存多个值的，比如读写锁的高 16 位存放读锁，低 16 位存放写锁，这种一个字段存放多个值可以更容易的维护多个值之间的一致性，也算是极简主义。 线程池有几种状态吗？ RUNNING：能接受新任务，并处理阻塞队列中的任务 SHUTDOWN：不接受新任务，但是可以处理阻塞队列中的任务 STOP：不接受新任务，并且不处理阻塞队列中的任务，并且还打断正在运行任务的线程，就是直接撂担子不干了！ TIDYING：所有任务都终止，并且工作线程也为0，处于关闭之前的状态 TERMINATED：已关闭。 为什么要先进队列，而不是直接新建线程执行 其实经过上面的分析可以得知，线程池本意只是让核心数量的线程工作着，不论是 core 的取名，还是 keepalive 的设定，所以你可以直接把 core 的数量设为你想要线程池工作的线程数，而任务队列起到一个缓冲的作用。最大线程数这个参数更像是无奈之举，在最坏的情况下做最后的努力，去新建线程去帮助消化任务。 所以我个人觉得没有为什么，就是这样设计的，并且这样的设定挺合理。 原生版线程池的实现可以认为是偏向 CPU 密集的，也就是当任务过多的时候不是先去创建更多的线程，而是先缓存任务，让核心线程去消化，从上面的分析我们可以知道，当处理 CPU 密集型任务的时，线程太多反而会由于线程频繁切换的开销而得不偿失，所以优先堆积任务而不是创建新的线程。 如何修改原生线程池，使得可以先拉满线程数再入任务队列排队？ 如果了解线程池的原理，很轻松的就知道关键点在哪，就是队列的 offer 方法。 execute 方法想必大家都不陌生，就是给线程池提交任务的方法。在这个方法中可以看到只要在 offer 方法内部判断此时线程数还小于最大线程数的时候返回 false，即可走下面 else if 中 addWorker (新增线程)的逻辑，如果数量已经达到最大线程数，直接入队即可。 自定义队列，让队列在线程数还未到达最大值时，不允许入队，就会进入创建新线程的逻辑。 如果线程池中的线程在执行任务的时候，抛异常了，会怎么样？ 把这个线程废了，然后新建一个线程替换之。 所以如果一个任务执行一半就抛出异常，并且你没有自行处理这个异常，那么这个任务就这样戛然而止了，后面也不会有线程继续执行剩下的逻辑，所以要自行捕获和处理业务异常。 shutdown：一个是安全的关闭线程池，会等待任务都执行完毕； shutdownNow：粗暴的直接咔嚓了所有线程，管你在不在运行； shutdownNow 了之后还在任务队列中的任务咋办？线程池还算负责，把未执行的任务拖拽到了一个列表中然后返回，至于怎么处理，就交给调用者了！ 线程池如何动态修改核心线程数和最大线程数？ CPU 密集型的话，核心线程数设置为 CPU核数+1 I/O 密集型的话，核心线程数设置为 2*CP","date":"2021-07-03","objectID":"/2021/07/java_summary/:28:16","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"为什么不推荐使用jdk自带的 executors 的方式来创建线程池? 避免资源耗尽的风险； 如果用这种方式设置，则 FixedThreadPool和SingleThreadPool允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM CachedThreadPool和ScheduledThreadPool允许创建的线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM ","date":"2021-07-03","objectID":"/2021/07/java_summary/:29:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"executors 的几种线程池 newCachedThreadPool 不固定线程数量，且支持最大为Integer.MAX_VALUE的线程数量: 1、线程数无限制。 2、有空闲线程则复用空闲线程，若无空闲线程则新建线程 3、一定程序减少频繁创建/销毁线程，减少系统开销。 newFixedThreadPool 一个固定线程数量的线程池: 1、可控制线程最大并发数（同时执行的线程数）。 2、超出的线程会在队列中等待。 newSingleThreadExecutor 可以理解为线程数量为1的FixedThreadPool: 单线程化的线程池： 1、有且仅有一个工作线程执行任务。 2、所有任务按照指定顺序执行，即遵循队列的入队出队规则。 newScheduledThreadPool 支持定时以指定周期循环执行任务: 注意：前三种线程池是ThreadPoolExecutor不同配置的实例，最后一种是ScheduledThreadPoolExecutor的实例。 AQS 提供更多的锁机制 实现阻塞锁和与之相关依赖于先进先出队列等待队列的同步器； 参考的文章1 参考的文章2 参考文章3 参考的原理讲解 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:30:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"基于许可的多线程控制 为了控制多个线程访问共享资源 ，我们需要为每个访问共享区间的线程派发一个许可。拿到一个许可的线程才能进入共享区间活动。当线程完成工作后，离开共享区间时，必须要归还许可，以确保后续的线程可以正常取得许可。如果许可用完了，那么线程进入共享区间时，就必须等待，这就是控制多线程并行的基本思想。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:31:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"管程 基于许可的控制，有点和管程很像。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:32:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"排他锁和共享锁 第二个重要的概念就是排他锁(exclusive)和共享锁(shared)。顾名思义，在排他模式上，只有一个线程可以访问共享变量，而共享模式则允许多个线程同时访问。简单地说，重入锁是排他的；信号量是共享的。 共享也是一定量的共享。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:33:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"LockSupport public static void park() : 如果没有可用许可，则挂起当前线程 public static void unpark(Thread thread)：给thread一个可用的许可，让它得以继续执行 LockSupport.unpark(Thread.currentThread()); LockSupport.park(); 大家可以猜一下，park()之后，当前线程是停止，还是 可以继续执行呢？ 答案是：可以继续执行。那是因为在park()之前，先执行了unpark()，进而释放了一个许可，也就是说当前线程有一个可用的许可。而park()在有可用许可的情况下，是不会阻塞线程的。 综上所述，park()和unpark()的执行效果和它调用的先后顺序没有关系。这一点相当重要，因为在一个多线程的环境中，我们往往很难保证函数调用的先后顺序(都在不同的线程中并发执行)，因此，这种基于许可的做法能够最大限度保证程序不出错。 与park()和unpark()相比， 一个典型的反面教材就是Thread.resume()和Thread.suspend()。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:34:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Thread.resume()和Thread.suspend() Thread.currentThread().resume(); Thread.currentThread().suspend(); 首先让线程继续执行，接着在挂起线程。这个写法和上面的park()的示例非常接近，但是运行结果却是截然不同的。在这里，当前线程就是卡死。 因此，使用park()和unpark()才是我们的首选。而在AbstractQueuedSynchronizer中，也正是使用了 LockSupport 的park()和unpark()操作来控制线程的运行状态的。 在AbstractQueuedSynchronizer内部， 有一个队列，我们把它叫做同步等待队列。它的作用是保存等待在这个锁上的线程(由于lock()操作引起的等待）。 为了维护等待在条件变量上的等待线程，AbstractQueuedSynchronizer又需要再维护一个条件变量等待队列，也就是那些由Condition.await()引起阻塞的线程。 Java 对象真实占用的内存大小 可以参考的资源1 对象头（Header） MarkWord：用于存储对象运行时的数据，好比 HashCode、锁状态标志、GC分代年龄等。这部分在 64 位操作系统下占 8 字节，32 位操作系统下占 4 字节。 指针：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪一个类的实例。这部分就涉及到指针压缩的概念，在开启指针压缩的状况下占 4 字节，未开启状况下占 8 字节。 数组长度：这部分只有是数组对象才有，若是是非数组对象就没这部分。这部分占 4 字节。 实例数据（Instance Data）用于存储对象中的各类类型的字段信息（包括从父类继承来的） 对齐填充（Padding），Java 对象的大小默认是按照 8 字节对齐 由于 CPU 进行内存访问时，一次寻址的指针大小是 8 字节，正好也是 L1 缓存行的大小。如果不进行内存对齐，则可能出现跨缓存行的情况，这叫做 缓存行污染。 JVM 为对象进行填充，使其大小变为 8 个字节的倍数。使用这些填充后，oops 中的最后三位始终为零。这是因为在二进制中 8 的倍数的数字总是以 000 结尾。由于 JVM 已经知道最后三位始终为零，因此在堆中存储那些零是没有意义的。相反假设它们存在并存储 3 个其他更重要的位，以此来模拟 35 位的内存地址。现在我们有一个带有 3 个右移零的 32 位地址，所以我们将 35 位指针压缩成 32 位指针。这意味着我们可以在不使用 64 位引用的情况下使用最多 32 GB ： (2(32+3)=235=32 GB) 的堆空间。 当 JVM 需要在内存中找到一个对象时，它将指针向左移动 3 位。另一方面当堆加载指针时，JVM 将指针向右移动 3 位以丢弃先前添加的零。虽然这个操作需要 JVM 执行更多的计算以节省一些空间，不过对于大多数CPU来说，位移是一个非常简单的操作。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:35:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"压缩的原理 CompressedOops 工作原理 32 位内最多可以表示 4GB，64 位地址为 堆的基地址 + 偏移量，当堆内存 \u003c 32GB 时候，在压缩过程中，把 偏移量 / 8 后保存到 32 位地址。在解压再把 32 位地址放大 8 倍，所以启用 CompressedOops 的条件是堆内存要在 4GB * 8=32GB 以内。 JVM 的实现方式是，不再保存所有引用，而是每隔 8 个字节保存一个引用。例如，原来保存每个引用 0、1、2…，现在只保存 0、8、16…。因此，指针压缩后，并不是所有引用都保存在堆中，而是以 8 个字节为间隔保存引用。 在实现上，堆中的引用其实还是按照 0x0、0x1、0x2… 进行存储。只不过当引用被存入 64 位的寄存器时，JVM 将其左移 3 位（相当于末尾添加 3 个0），例如 0x0、0x1、0x2… 分别被转换为 0x0、0x8、0x10。而当从寄存器读出时，JVM 又可以右移 3 位，丢弃末尾的 0。（oop 在堆中是 32 位，在寄存器中是 35 位，2的 35 次方 = 32G。也就是说使用 32 位，来达到 35 位 oop 所能引用的堆内存空间）。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:36:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"为什么可以压缩？ 。。。。。。。 // todo ","date":"2021-07-03","objectID":"/2021/07/java_summary/:36:1","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"数据类型占用的空间 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:37:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"基础数据类型占用的内存大小 数据类型对应的内存占用，参考：https://www.baeldung.com/java-primitives ","date":"2021-07-03","objectID":"/2021/07/java_summary/:37:1","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"引用类型占用的内存大小 引用类型在 32 位系统上每个引用对象占用 4 byte，在 64 位系统上每个引用对象占用 8 byte。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:37:2","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["java"],"content":"Java 对象到底占用多大内存 可供参考的资料1 JOL 首先记住公式，对象由 对象头 + 实例数据 + padding 填充字节组成，虚拟机规范要求对象所占内存必须是 8 的倍数，padding 就是干这个的。 对象头由 Markword + 类指针kclass（该指针指向该类型在方法区的元类型） 组成。 可以借助这个工具进行分析 org.openjdk.jol:jol-core:0.17 new String(“xxxx”); 这个对象是 24 bytes； 无论是什么对象，一般 header 是 12，剩下的是具体的属性对象的大小，外加对齐的内容。 ","date":"2021-07-03","objectID":"/2021/07/java_summary/:38:0","tags":["Java,JVM"],"title":"一张思维导图看 Java 【持续迭代】","uri":"/2021/07/java_summary/"},{"categories":["Network"],"content":"概述 记录编译Cronet for Android 的过程和步骤. 准备工具 install depot_tools # 下载 $ git clone https://chromium.googlesource.com/chromium/tools/depot_tools.git 添加进path,或者 .bashrc/.zshrc # 将 /path/to/depot_tools 天换成自己安装的目录即可 $ export PATH=\"$PATH:/path/to/depot_tools\" 如果安装的位置是home目录下,上述命令切勿使用 ~,使用绝对路径或者 HOME 替代. $ export PATH=\"$PATH:${HOME}/depot_tools\" 我的安装路径是 ~/ide/depot_tools 所以,我执行的命令是 $ export PATH=\"$PATH:${HOME}/ide/depot_tools\" 下载代码 找个目录,clone代码,我选择的是 ~/workspace/chromium 拉取代码,因为我不想要history,如果想要history,去掉 –no-history 即可. # 这个命令是第一次拉取代码使用 $ fetch --nohooks --no-history chromium 根据网速,快的话办小时,慢的话,数小时之后完成. 20G的东西，我的网速很慢，过了一夜吧，也没具体看多久，这个工具有个问题，没有进度条。。。 当命令结束之后,目录下就会出现隐藏文件.gclient 和 文件夹 src. ​ 假如中间中断过，或者直接拷贝了一份已有的源码，非第一次拉取代码,可能会提示如下内容。 ​ ","date":"2021-06-02","objectID":"/2021/06/cronet-build/:0:0","tags":["Cronet"],"title":"cronet_build","uri":"/2021/06/cronet-build/"},{"categories":["Network"],"content":"非初次同步,则执行同步代码的命令 $ gclient sync 进入漫长的等待… 同步完成,自动执行 gclient runhooks 命令. 切换到src目录下 $cd src 安装额外依赖 $ ./build/install-build-deps.sh 依赖比较多,安装需要点时间,约1G的空间大小. 我安装的时候,还遇到一个问题 试了很多办法,还是不行,就按照提示的,跳过这个字体库的安装. ​ $ ./build/install-build-deps.sh --no-chromeos-fonts Run the hooks $ gclient runhooks build ","date":"2021-06-02","objectID":"/2021/06/cronet-build/:1:0","tags":["Cronet"],"title":"cronet_build","uri":"/2021/06/cronet-build/"},{"categories":["Network"],"content":"需求一: Building Cronet for development and debugging ","date":"2021-06-02","objectID":"/2021/06/cronet-build/:2:0","tags":["Cronet"],"title":"cronet_build","uri":"/2021/06/cronet-build/"},{"categories":["Network"],"content":"第一步: 设置out_dir,生成ninja文件 $ ./components/cronet/tools/cr_cronet.py gn --out_dir=out/Cronet 在linux进行编译,则自动生成Android 库,在Mac上,则会生成iOS库. 这个命令执行完成之后,会影响之前编译在out/Cronet目录中的内容. 如果 –out_dir 参数省略的话,就输出目录就会默认变成 out/Debug 和 out/Release,分别存放debug和release的输出内容. ","date":"2021-06-02","objectID":"/2021/06/cronet-build/:2:1","tags":["Cronet"],"title":"cronet_build","uri":"/2021/06/cronet-build/"},{"categories":["Network"],"content":"第二步: Running the ninja files $ ninja -C out/Cronet cronet_package ","date":"2021-06-02","objectID":"/2021/06/cronet-build/:2:2","tags":["Cronet"],"title":"cronet_build","uri":"/2021/06/cronet-build/"},{"categories":["Network"],"content":"生成物解释 编译完,用作Android开发的库都在 chromium/src/out/Cronet/cronet 目录下. ​ Android的jar包: 该目录下的所有jar文件,就是需要的jar包; Android的动态库: libs目录下有对应的so文件; 符号表: 对应的符号信息在symbols目录下,用于线上crash或其他栈信息的mapping; 头文件: include目录下有对应的头文件. 反混淆文件: 也在该目录下. ","date":"2021-06-02","objectID":"/2021/06/cronet-build/:2:3","tags":["Cronet"],"title":"cronet_build","uri":"/2021/06/cronet-build/"},{"categories":["Network"],"content":"需求二: build mobile release $ ./components/cronet/tools/cr_cronet.py gn --release $ ninja -C out/Release cronet_package ","date":"2021-06-02","objectID":"/2021/06/cronet-build/:3:0","tags":["Cronet"],"title":"cronet_build","uri":"/2021/06/cronet-build/"},{"categories":["Network"],"content":"需求三: 其他abi 默认不指定参数的情况下,生成的是 ARMv7 32位的库,如果需要其他版本的库,可以通过添加如下参数,进行生成. ","date":"2021-06-02","objectID":"/2021/06/cronet-build/:4:0","tags":["Cronet"],"title":"cronet_build","uri":"/2021/06/cronet-build/"},{"categories":["Network"],"content":"方案一是,修改 cr_cronet.py 文件的 gn_args 变量,按照需求修改成如下的值. ​ For ARMv8 64-bit: target_cpu=“arm64” For x86 32-bit: target_cpu=“x86” For x86 64-bit: target_cpu=“x64” ","date":"2021-06-02","objectID":"/2021/06/cronet-build/:4:1","tags":["Cronet"],"title":"cronet_build","uri":"/2021/06/cronet-build/"},{"categories":["Network"],"content":"方案二: 交互式,不需要修改文件 # 交互修改参数 $ gn args out/Cronet 会弹出输入界面,可以输入需要的参数,比如(这些参数我是参考的默认debug包的参数,只是添加了开头有的target_cpu部分) ​ target_cpu=\"arm64\" target_cpu=\"arm\" target_cpu=\"x86\" target_os = \"android\" enable_websockets = false disable_file_support = true disable_ftp_support = true disable_brotli_filter = false is_component_build = false use_crash_key_stubs = true ignore_elf32_limitations = true use_partition_alloc = false include_transport_security_state_preload_list = false use_platform_icu_alternatives = true use_errorprone_java_compiler = true enable_reporting = true use_hashed_jni_names = true ​ Tip: 其实最终的参数存在 out/Cronet/args.gn 这个文件里,也可以直接修改这个文件. 执行编译操作 $ ninja -C out/Cronet cronet_package ​ 生成的so文件在 src/out/Cronet/cronet/libs 下,因为我之前编译过 x86的,所以有两个. 其他,iOS编译 曾经也编译过iOS版本,步骤差不多,按照文档来,但是当时有个问题,在此记录下. 按照iOS编译文档 操作执行,生成需要的文件夹; 如果当时fetch的时候,参数不是 iOS,则需要确认 .gclient ,最后一行有 target_os = [ “ios” ] ,然后再执行 gclient sync,下载iOS的依赖; 文档说明 Ref Cronet build instructions ","date":"2021-06-02","objectID":"/2021/06/cronet-build/:4:2","tags":["Cronet"],"title":"cronet_build","uri":"/2021/06/cronet-build/"},{"categories":["Network"],"content":"概述 回顾一下 OKHttp 这个优秀库,画了张思维导图. ","date":"2021-02-09","objectID":"/2021/02/okhttp-1/:0:0","tags":["Android","Http"],"title":"OkHttp学习之简介(1)","uri":"/2021/02/okhttp-1/"},{"categories":["Android"],"content":"override 最近给电脑换了块SSD，装了Ubuntu 18.04。之前的aosp也不想copy过来了，直接重新编译一份，顺带看下新的SSD带来的提效。 因为手机是 nexus 6p，aosp 最后支持到 8.1. 记录下编译需要的操作。 步骤 open jdk(https://openjdk.java.net/install/ ) sudo apt install openjdk-8-jdk repo(https://gerrit.googlesource.com/git-repo/ ) AUTO sudo apt-get install repo MANUALLY $ mkdir -p ~/.bin $ PATH=\"${HOME}/.bin:${PATH}\" $ curl https://storage.googleapis.com/git-repo-downloads/repo \u003e ~/.bin/repo $ chmod a+rx ~/.bin/repo AOSP mirror mkdir aosp git config --global user.email \"tinggengyan@gmail.com\" git config --global user.name \"Tinggeng Yan\" sudo apt install python cd aosp # 切换指定版本分支 repo init -u https://mirrors.tuna.tsinghua.edu.cn/git/AOSP/platform/manifest -b android-8.1.0_r52 --depth=1 --repo-url=https://mirrors.tuna.tsinghua.edu.cn/git/git-repo/ --repo-branch=stable repo sync --current-branch build sudo apt-get install libx11-dev:i386 libreadline6-dev:i386 libgl1-mesa-dev g++-multilib sudo apt-get install -y git flex bison gperf build-essential libncurses5-dev:i386 sudo apt-get install tofrodos python-markdown libxml2-utils xsltproc zlib1g-dev:i386 sudo apt-get install dpkg-dev libsdl1.2-dev libesd0-dev sudo apt-get install git-core gnupg flex bison gperf build-essential sudo apt-get install zip curl zlib1g-dev gcc-multilib g++-multilib sudo apt-get install libc6-dev-i386 sudo apt-get install lib32ncurses5-dev x11proto-core-dev libx11-dev sudo apt-get install libgl1-mesa-dev libxml2-utils xsltproc unzip m4 sudo apt-get install lib32z-dev ccache export LC_ALL=C source build/envsetup.sh \u0026\u0026 lunch make -j 4 flash into nexus 6p cd /data/aosp/out/target/product/angler adb reboot bootloader fastboot devices #下面这条命令可选 #fastboot flashall -w #-w 选项会清除设备上的 /data 分区； #该选项在您第一次刷写特定设备时非常有用，但在其他情况下则没必要使用。 fastboot flash vendor vendor.img fastboot flash boot boot.img fastboot flash recovery recovery.img fastboot flash system system.img fastboot flash userdata userdata.img fastboot flash cache cache.img fastboot reboot ","date":"2020-09-06","objectID":"/2020/09/aosp_build/:0:0","tags":["aosp"],"title":"AOSP编译","uri":"/2020/09/aosp_build/"},{"categories":["Android"],"content":"emulator 需要编译对应的模拟器的镜像。 source build/envsetup.sh lunch 2 #这里填序号aosp_arm64-eng为2 make -j 4 emulator 如果编译完成后关闭了终端窗口，则需要用以下方式启动模拟器 source build/envsetup.sh lunch 2 #这里填序号aosp_arm64-eng为2 emulator other 可能出现的错误 error: insufficient permissions for device: udev requires plugdev group membership add group sudo usermod -aG plugdev $LOGNAME ref ref sony developer version branch AOSP tags ","date":"2020-09-06","objectID":"/2020/09/aosp_build/:1:0","tags":["aosp"],"title":"AOSP编译","uri":"/2020/09/aosp_build/"},{"categories":["Android"],"content":"概述 花了点时间,debug了一下系统,跟踪了一下Activity的启动流程.画了一张图,作为综述. 分析的 compileSdkVersion 为 28. 用的是 draw.io 画的,源文件 . ","date":"2020-07-23","objectID":"/2020/07/activity-launch-process-1/:0:0","tags":["Activity"],"title":"Activity启动流程概述","uri":"/2020/07/activity-launch-process-1/"},{"categories":["Tool"],"content":"概述 debug 是学习流程最快的方式,也是验证想法最好的方法.记录 Androidstudio 如何debug Android framework的代码. ","date":"2020-06-23","objectID":"/2020/06/as-debug-framework/:0:0","tags":["Android","framework"],"title":"AndroidStudio调试framework源码","uri":"/2020/06/as-debug-framework/"},{"categories":["Tool"],"content":"使用无 AOSP 的代码(Java层) 这是最简单方便的方式了. 下载某个版本的 Android Source code 确认 Source code 正确下载了. 新建项目,所用的 compile SDK 版本为需要调试的代码版本 android { // 设置成需要需要分析的,且已下载源码的版本 compileSdkVersion 29 ...... } 新建并启动对应版本的模拟器. 打断点; 这里以系统的 ActivityManagerService 为例. 因为ActivityManagerService 并未导出到Android.jar,所以无法直接搜索定位到 .java文件,所以采用双击shift的方式,检索文件. attach 到对应的进程,运行,查看断点. ActivityManagerService 这个类是在系统 system_process 进程中的,所以,需要对system_process 进程进行 attach 操作. ","date":"2020-06-23","objectID":"/2020/06/as-debug-framework/:1:0","tags":["Android","framework"],"title":"AndroidStudio调试framework源码","uri":"/2020/06/as-debug-framework/"},{"categories":["Tool"],"content":"小结 至此,经过如上操作,就可以对某个类进行debug操作了.对于分析framework代码也是方便的很. ","date":"2020-06-23","objectID":"/2020/06/as-debug-framework/:2:0","tags":["Android","framework"],"title":"AndroidStudio调试framework源码","uri":"/2020/06/as-debug-framework/"},{"categories":["Tool"],"content":"可能遇到的问题 有时候还是会遇到代码行号不匹配,debug定位的代码行号不对,目前原因未知,应该是source code 和生成模拟器镜像的代码有出入. 没有好的解决办法,有个替代的方案. 断点后,有明确的thread stack信息; 找到最早一个可以定位准备行号的函数; 针对这个函数进行 findByUsage,在查出的结果中,查找stack信息指引的函数. 使用 AOSP 的源码进行调试 上述的方法基本能满足常见的debug需求了.但是有个前提是,debug的设备基本只能是模拟器或者装了官方release镜像的亲儿子. 对于有修改ROM需求的情况下,debug 则需要导入 aosp 中framework 的代码. 对应的运行设备得是运行了自定义ROM的设备. ","date":"2020-06-23","objectID":"/2020/06/as-debug-framework/:2:1","tags":["Android","framework"],"title":"AndroidStudio调试framework源码","uri":"/2020/06/as-debug-framework/"},{"categories":["Tool"],"content":"生成 android.ipr 文件 // 1. 编译 idegen模块 mmm development/tools/idegen/ // 2. 生成 ./development/tools/idegen.sh 这个文件就代表了AS里的一个project. ","date":"2020-06-23","objectID":"/2020/06/as-debug-framework/:3:0","tags":["Android","framework"],"title":"AndroidStudio调试framework源码","uri":"/2020/06/as-debug-framework/"},{"categories":["Tool"],"content":"修改 android.iml 文件 同时还会生成一个 iml文件,代表了project的配置情况,可以用于配置加载哪些配置. AOSP巨大,可以只加载需要关注的模块,如 framework 和 Package 部分. 所以需要修改 android.iml 文件,将不需要的文件进行exclude. ","date":"2020-06-23","objectID":"/2020/06/as-debug-framework/:4:0","tags":["Android","framework"],"title":"AndroidStudio调试framework源码","uri":"/2020/06/as-debug-framework/"},{"categories":["Tool"],"content":"AS 打开 ipr 文件 ","date":"2020-06-23","objectID":"/2020/06/as-debug-framework/:5:0","tags":["Android","framework"],"title":"AndroidStudio调试framework源码","uri":"/2020/06/as-debug-framework/"},{"categories":["Tool"],"content":"可能遇到问题 导入可能遇到问题 External file changes sync may be slow: The current inotify(7) watch limit is too low. sudo vim fs.inotify.max_user_watches = 524288 sudo sysctl -p --system 重启即可; ","date":"2020-06-23","objectID":"/2020/06/as-debug-framework/:5:1","tags":["Android","framework"],"title":"AndroidStudio调试framework源码","uri":"/2020/06/as-debug-framework/"},{"categories":["Tool"],"content":"代码索引跳转 为了跳转到aosp的Java文件,而不是android.jar的class文件,需要调整 project struct. 新建一个 jdk,此处为 jdk_none, 删除所有的path; 新建一个 android sdk,依赖 jdk_none; project 依赖的sdk切换成第2步新建的SDK即可; ","date":"2020-06-23","objectID":"/2020/06/as-debug-framework/:6:0","tags":["Android","framework"],"title":"AndroidStudio调试framework源码","uri":"/2020/06/as-debug-framework/"},{"categories":["Tool"],"content":"让模拟器使用自定义的ROM source ./build/envsetup.sh lunch ,选择对应的 模拟器需要的API emulator 自己编译编译出的ROM位置\" ……/aosp/out/target/product/generic_x86_64 ","date":"2020-06-23","objectID":"/2020/06/as-debug-framework/:7:0","tags":["Android","framework"],"title":"AndroidStudio调试framework源码","uri":"/2020/06/as-debug-framework/"},{"categories":["Tool"],"content":"附,我还没试过 $ emulator -avd Nexus5-API22 -verbose -no-boot-anim -system (the path of system.img) 方案对比 第一种自然是方便的,要求比较低,对机器的性能要求也不高.有个劣势: 对于AIDL编译生成的Java文件,无法进行索引和导航.但是,可以借助官方的代码搜索网站进行弥补,搜索网站可以索引soong编译期间生成的Java代码: https://cs.android.com/android/platform/superproject AOSP的方式是灵活性更大,中间代码索引也方便. 就是性能要求比较高. ","date":"2020-06-23","objectID":"/2020/06/as-debug-framework/:7:1","tags":["Android","framework"],"title":"AndroidStudio调试framework源码","uri":"/2020/06/as-debug-framework/"},{"categories":["Tool"],"content":"Ref 导入AOSP ","date":"2020-06-23","objectID":"/2020/06/as-debug-framework/:8:0","tags":["Android","framework"],"title":"AndroidStudio调试framework源码","uri":"/2020/06/as-debug-framework/"},{"categories":["Tool"],"content":"概述 之前一直寻找一款类似于windows上的sourceinsight的软件,后来无意发现 Understand,感觉挺好,熟悉一下,可以用来看代码.体验不错. ","date":"2020-06-19","objectID":"/2020/06/tool-understand/:0:0","tags":["Understand","Tool"],"title":"Mac下 Understand 的初步配置","uri":"/2020/06/tool-understand/"},{"categories":["Tool"],"content":"导入流程 和sourceinsight一样,都是新建一个project,在此基础上进行代码的阅读和修改; new project import project files ","date":"2020-06-19","objectID":"/2020/06/tool-understand/:1:0","tags":["Understand","Tool"],"title":"Mac下 Understand 的初步配置","uri":"/2020/06/tool-understand/"},{"categories":["Tool"],"content":"部分实用快捷键 command + F: 在侧边的文件栏可以按照文件名进行搜索; 在打开的文件内可以搜索匹配的关键词; command + G: 在搜索的基础上可以查找匹配的结果的下一项; command +shift + G: 在搜索的基础上可以查找匹配的结果的上一项,即反向查找; command + F3 搜索选中的内容 command + option + p/n 返回前一个/下一个修改的地方 ","date":"2020-06-19","objectID":"/2020/06/tool-understand/:2:0","tags":["Understand","Tool"],"title":"Mac下 Understand 的初步配置","uri":"/2020/06/tool-understand/"},{"categories":["Tool"],"content":"部分实用的操作 绘图能力 uml 类图 在类名上右击,Graphical Views -\u003e UML Class Diagram 查看选中类调用其他类的关系图(单向的调用) 在类名上右击,Graphical Views -\u003e Cluster call 查看选中类和其他之间关系图(单向和双向的调用都会列出) 在类名上右击,Graphical Views -\u003e Cluster callby Butterfly 查看选中类内部的调用关系 在类名上右击,Graphical Views -\u003e Cluster callby Internal 查看选中类被哪些其他的类调用(单向的被调用) 在类名上右击,Graphical Views -\u003e Cluster callby 预览能力,非常好用的功能 在类名上,右击 View Information -\u003e Reference by Flat List: 查看类被引用的列表. 注: 如果选中的是方法名的话,这里展示的就是方法被引用的列表了. 文件搜索能力 除了直接使用搜索以外,可以在 Entity Filter 里进行过滤文件. 收藏夹 用以将需要分析的文件分组 查看调用链 通过选中方法右击 explore -\u003e explore called by/Calls,可以看不到方法被谁调用,自身又调用了谁,非常非常实用. ","date":"2020-06-19","objectID":"/2020/06/tool-understand/:3:0","tags":["Understand","Tool"],"title":"Mac下 Understand 的初步配置","uri":"/2020/06/tool-understand/"},{"categories":["Tool"],"content":"缺陷 文件的检索,快捷键 目前试用,有几个点比较不舒适,文件的检索能力,没有找到对应的快捷键,能迅速的搜索文件. 退而求其次,采用为Entity Filter 自定义快捷键的方式,来达到此目的. 当前我采用的是 control + e,目前看能满足需求. 在 information 里搜索关键词超级慢; 没有不可编辑的选项 阅读代码的时候,有时不小心误触什么键,可能导致代码变更,需要设置全部文件均不可修改. 不过这点可以通过权限控制,或者干脆不设置,小问题. 没办法快捷键检索类的属性和方法 目前可以查看属性只能通过Information. 方法可以通过菜单栏处的scope list 查看.没有快捷键进行关键词搜索,只能鼠标,这点太大的缺陷.关于这点,还是IDE或者VSC 比较方便.目前这个只能通过选中文件,在光标处于选中文件编辑区的情况下, commnand + f 进行检索,检索的顺序还不能模糊匹配. ","date":"2020-06-19","objectID":"/2020/06/tool-understand/:4:0","tags":["Understand","Tool"],"title":"Mac下 Understand 的初步配置","uri":"/2020/06/tool-understand/"},{"categories":["Android"],"content":"概述 记录一个意外发现的一个类 com.sun.net.httpserver.HttpsServer. 一个 Http 的 Server 端. 用处 适用于泛前端类开发者,在无后端服务的情况下,可以用来mock数据或者mock后端行为,非常灵活. 适用于网络库的开发者,测试库的行为; 缺点 目前不支持HTTP2协议. 分类 ","date":"2020-04-20","objectID":"/2020/04/jdk-httpserver/:0:0","tags":["Android","Java"],"title":"jdk携带的一个HttpServer实现","uri":"/2020/04/jdk-httpserver/"},{"categories":["Android"],"content":"HTTP 协议 ","date":"2020-04-20","objectID":"/2020/04/jdk-httpserver/:1:0","tags":["Android","Java"],"title":"jdk携带的一个HttpServer实现","uri":"/2020/04/jdk-httpserver/"},{"categories":["Android"],"content":"自定义一个 HTTP 服务; HttpsServer server = HttpsServer.create(new InetSocketAddress(8500), 0); HttpsConfigurator httpsConfigurator = new HttpsConfigurator(SSLContext.getDefault()); server.setHttpsConfigurator(httpsConfigurator); HttpContext context = server.createContext(\"/example\"); context.setHandler(new CustomHttpHandler()); server.start(); 该 Http 服务,是在本机的 8500 端口启动的; 根目录为 example. 所以,直接通过 http://127.0.0.1:8500/example 即可访问. ","date":"2020-04-20","objectID":"/2020/04/jdk-httpserver/:1:1","tags":["Android","Java"],"title":"jdk携带的一个HttpServer实现","uri":"/2020/04/jdk-httpserver/"},{"categories":["Android"],"content":"Server 的行为定义 public class CustomHttpHandler implements HttpHandler { @Override public void handle(HttpExchange exchange) throws IOException { URI requestURI = exchange.getRequestURI(); printRequestInfo(exchange); String response = \"This is the response at \" + requestURI; exchange.sendResponseHeaders(200, 0); OutputStream os = exchange.getResponseBody(); os.write(response.getBytes()); os.close(); } private void printRequestInfo(HttpExchange exchange) { System.out.println(\"-- headers --\"); Headers requestHeaders = exchange.getRequestHeaders(); requestHeaders.entrySet().forEach(System.out::println); System.out.println(\"-- principle --\"); HttpPrincipal principal = exchange.getPrincipal(); System.out.println(principal); System.out.println(\"-- HTTP method --\"); String requestMethod = exchange.getRequestMethod(); System.out.println(requestMethod); System.out.println(\"-- query --\"); URI requestURI = exchange.getRequestURI(); String query = requestURI.getQuery(); System.out.println(query); InputStream requestBody = exchange.getRequestBody(); if (requestBody == null) { return; } int available = 0; try { available = requestBody.available(); } catch (IOException e) { e.printStackTrace(); } System.out.println(\"request body available:\" + available); printMessage(requestBody); } private static void printMessage(InputStream requestBody) { byte[] buffer = new byte[1024]; try { while (true) { int read = requestBody.read(buffer); if (!(read \u003e 0)) break; System.out.println(\"body:::::\" + new String(buffer)); } } catch (IOException e) { e.printStackTrace(); } } } ","date":"2020-04-20","objectID":"/2020/04/jdk-httpserver/:1:2","tags":["Android","Java"],"title":"jdk携带的一个HttpServer实现","uri":"/2020/04/jdk-httpserver/"},{"categories":["Android"],"content":"Https 生成自签的证书的命令如下: keytool -genkey -alias alias -keyalg RSA -keystore keystore.jks -keysize 2048 ","date":"2020-04-20","objectID":"/2020/04/jdk-httpserver/:2:0","tags":["Android","Java"],"title":"jdk携带的一个HttpServer实现","uri":"/2020/04/jdk-httpserver/"},{"categories":["Android"],"content":"自定义一个 Https 服务; try { // setup the socket address InetSocketAddress address = new InetSocketAddress(8500); // initialise the HTTPS server HttpsServer httpsServer = HttpsServer.create(address, 0); SSLContext sslContext = SSLContext.getInstance(\"TLS\"); // initialise the keystore // 记得替换密码 char[] password = \"123456\".toCharArray(); KeyStore ks = KeyStore.getInstance(\"JKS\"); FileInputStream fis = new FileInputStream(\"keystore.jks\"); ks.load(fis, password); // setup the key manager factory KeyManagerFactory kmf = KeyManagerFactory.getInstance(\"SunX509\"); kmf.init(ks, password); // setup the trust manager factory TrustManagerFactory tmf = TrustManagerFactory.getInstance(\"SunX509\"); tmf.init(ks); // setup the HTTPS context and parameters sslContext.init(kmf.getKeyManagers(), tmf.getTrustManagers(), null); httpsServer.setHttpsConfigurator(new HttpsConfigurator(sslContext) { public void configure(HttpsParameters params) { try { // initialise the SSL context SSLContext context = getSSLContext(); SSLEngine engine = context.createSSLEngine(); params.setNeedClientAuth(false); params.setCipherSuites(engine.getEnabledCipherSuites()); params.setProtocols(engine.getEnabledProtocols()); // Set the SSL parameters SSLParameters sslParameters = context.getSupportedSSLParameters(); params.setSSLParameters(sslParameters); } catch (Exception ex) { System.out.println(\"Failed to create HTTPS port\"); } } }); httpsServer.createContext(\"/example\", new SimpleHttpsServer.SimpleHandler()); httpsServer.start(); } catch (Exception exception) { System.out.println(\"Failed to create HTTPS server on port \" + 8500 + \" of localhost\"); exception.printStackTrace(); } ","date":"2020-04-20","objectID":"/2020/04/jdk-httpserver/:2:1","tags":["Android","Java"],"title":"jdk携带的一个HttpServer实现","uri":"/2020/04/jdk-httpserver/"},{"categories":["Android"],"content":"自定义Https服务处理 public class SimpleHttpsServer { public static class SimpleHandler implements HttpHandler { @Override public void handle(HttpExchange t) throws IOException { printRequestInfo(t); String response = \"This is the response\"; HttpsExchange httpsExchange = (HttpsExchange) t; httpsExchange.getResponseHeaders().add(\"Access-Control-Allow-Origin\", \"*\"); httpsExchange.sendResponseHeaders(200, response.getBytes().length); OutputStream os = httpsExchange.getResponseBody(); os.write(response.getBytes()); os.close(); } } private static void printRequestInfo(HttpExchange exchange) { System.out.println(\"-- headers --\"); Headers requestHeaders = exchange.getRequestHeaders(); requestHeaders.entrySet().forEach(System.out::println); System.out.println(\"-- protocol --\"); String protocol = exchange.getProtocol(); System.out.println(protocol); System.out.println(\"-- principle --\"); HttpPrincipal principal = exchange.getPrincipal(); System.out.println(principal); System.out.println(\"-- HTTP method --\"); String requestMethod = exchange.getRequestMethod(); System.out.println(requestMethod); System.out.println(\"-- query --\"); URI requestURI = exchange.getRequestURI(); String query = requestURI.getQuery(); System.out.println(query); InputStream requestBody = exchange.getRequestBody(); if (requestBody == null) { return; } int available = 0; try { available = requestBody.available(); } catch (IOException e) { e.printStackTrace(); } System.out.println(\"request body available:\" + available); printMessage(requestBody); } private static void printMessage(InputStream requestBody) { byte[] buffer = new byte[1024]; try { while (true) { int read = requestBody.read(buffer); if (!(read \u003e 0)) break; System.out.println(\"body content is: \" + new String(buffer)); } } catch (IOException e) { e.printStackTrace(); } } } 末尾 如果知道实现了Http2的,还望告知. ","date":"2020-04-20","objectID":"/2020/04/jdk-httpserver/:2:2","tags":["Android","Java"],"title":"jdk携带的一个HttpServer实现","uri":"/2020/04/jdk-httpserver/"},{"categories":null,"content":"Purpose 为学日益,记录自己的读书,学习,工作,生活的点滴. ","date":"2020-04-09","objectID":"/about/:1:0","tags":null,"title":"about","uri":"/about/"},{"categories":null,"content":"Profile 颜廷庚 Android Developer一枚 坐标：上海 ","date":"2020-04-09","objectID":"/about/:2:0","tags":null,"title":"about","uri":"/about/"},{"categories":null,"content":"Skills Android Java C Python Gradle SQL JavaScript Thanks 人初做事，如鸡伏卵，不舍而生气渐充。如燕营巢，不息而结构渐牢。如滋培之木，不见其长，有时而大。如有本之泉，不舍昼夜，盈科而后进，放乎四海。——曾国藩 ​ ","date":"2020-04-09","objectID":"/about/:3:0","tags":null,"title":"about","uri":"/about/"},{"categories":["Android"],"content":"Override 本篇是对于 Google NDK GUIDES 中 JNI tips 的总结,是关于 JNI 开发过程 中的一些原则和注意点,没有原理. 所有的内容适用于 Java 和 Kotlin. 约定 - managed code (Java/kotlin编写的代码) - native code (C/C++编写的代码) Tips ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:0:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"General 整体上大的原则是: 尽量减少 JNI 层的操作. 故而有以下3点注意事项,重要性由高到低依次为: JNI 层调用传递的数据尽量少,调用的频率尽量低; JNI Java 调用 native 避免异步调用,异步操作都放在 Java 层.这指的是 JNI 调用,不包含 native 库自身有些异步操作; JNI 操作涉及到的线程越少越好.即使要用线程池,也是由线程池的管理者负责JNI之间的交互,而不是由工作线程直接负责交互; 为了方便维护和重构, 保证JNI相关的代码在固定的位置,容易辨认,且接口尽量少; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:1:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"JavaVM \u0026 JNIEnv 二者本质上都是指向函数表的指针的指针. 虽然理论上来说,每个进程可以有多个 JavaVM 对象,但是 Android 规定,每个进程只能有一个 JavaVM ; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:2:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"注意点 JNIEnv 是个线程局部变量,线程不可共享,请勿在线程之间共享 JNIEnv 对象; 如若无其他方式获取 JNIEnv,可以采如下方式; JNIEnv* env; vm-\u003eAttachCurrentThread(\u0026env, nullptr); // 此处的 vm 即为JavaVM 对象,可以处理成全局单例; 由于 JavaVM \u0026 JNIEnv 在 C 和 C++ 中的定义是不一样(“jni.h” 中包含了二者的不同定义,根据包含\"jni.h\"的是C还是C++),所以,如果头文件会在 C/C++ 中共享的话,则不能简单的 include,头文件中的方法声明就需要根据C/C++做区分处理; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:2:1","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"Thread 所有的线程都是 Linux 线程,都归属内核调度 Java/kotlin 创建; native 创建,然后 AttachCurrentThread 到 JavaVM 上; 创建线程最好的方式是通过 Java/kotlin 创建 好处一: 有充足的栈空间; 好处二: 相对 native 创建线程,可以分配正确的 ThreadGroup; 好处三: 通过 JNI 调用的 native 代码可以使用和 Java 中相同的 classloader; 好处四: 相对 native 创建线程,方便设置线程 name,在 debug 的时候很方便; native 方式创建线程,并 attach 在 Java 层相应的创建一个 java.lang.Thread 对象; 新建的线程添加进 “main” ThreadGroup,debug 时,就可以看到了; 对一个 AttachCurrentThread 过的线程上再次 AttachCurrentThread 无副作用; Android 不会挂起正在执行 native 代码的线程 GC 或者 debug 的时候,即使发出了挂起的请求,也只会在下次进行 JNI 请求的时候挂起; 已经 attach 过的线程退出时,必须调用 DetachCurrentThread 方法 如果调用不方便,可以通过 pthread_key_create 定义一个 析构函数,在线程退出的时候,调用 DetachCurrentThread; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:3:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"注意点 在 native 层线程在未 attach 之前,是没有 JNIEnv 的,不能进行 JNI 操作; 线程资源优先通过 Java 层创建; JNI 调用的 native 方法过于耗时会影响 CPU 调度,间接影响主线程,注意 native 方法的耗时; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:3:1","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"jclass, jmethodID, and jfieldID JNI native 层访问 Java 层的属性的时候,则需要以下三个步骤; jclass,引用实例对应的 jclass 对象,通过 findclass 获取; jfieldID,属性对应的 ID,通过 GetFieldID 获取; 根据属性的变量类型,通过对应方法获取该对象实例的属性的值,如 GetIntField; JNI native 层访问 Java 层的方法的时候,则需要以下三个步骤; jclass,引用实例对应的 jclass 对象,通过 findclass 获取; jmethodID,方法对应的 ID,通过 GetMethodID 获取; 根据方法的签名,通过对应方法调用方法,如 CallIntMethod; 关于 jfieldID 和 jmethodID 的查找是需要经过字符串比较的,然一旦已经存在 jfieldID 和 jmethodI,获取值/方法调用 是很快的. jfieldID 和 jmethodID 本质上,只是指向内部运行时数据结构的指针; jfieldID 和 jmethodID 只要 class 没有被卸载,是一直有效的; 但是在 Android 上,虽然概率很低,但是 class 也是可能被卸载的,所以,需要做好安全防护工作; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:4:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"注意点 为了性能考虑,缓存 jfieldID 和 jmethodID; 因为每个进程只有一个 JavaVM,所以在 native 代码中的 static 存储区域中缓存是合适的. 与 jfieldID 和 jmethodID 不同,jclass 是个 class 的引用,缓存的时候,必须用 GlobalRef 进行保护; 综上,缓存 ID的最佳方式如下: /* * We use a class initializer to allow the native code to cache some * field offsets. This native function looks up and caches interesting * class/field/method IDs. Throws on failure. */ private static native void nativeInit(); static { nativeInit(); } 在 C/C++ 层面实现 nativeInit 方法,进行 ID 的查找和缓存,这样只会在 class 加载时候调用一次,卸载重新加载也会得到调用,可以保证安全; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:4:1","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"Local and global references 该特性适用于所有继承了 jobject 类的对象: jclass,jstring,jarray; 如未特殊说明,以下的对象也都是指的 jobject 或者其子类对应的对象; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:5:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"Local references 通过 JNI 传递到 native 方法的所有 object 参数以及 native 方法返回的 object 对象,都是 “local reference”. 特点: 在 当前线程 的 当前 native 方法生命周期内 (条件),该 “local reference” 是有效的.不满足这个条件,即使对象依旧存活,依然是无效的. 换句话说:在 return java 之前都是有效的; Local 的限制 native 函数结束之后, local 引用就会失效,但是有时候需要使用大量的 local 引用.典型的像在遍历数组的时候,需要大量创建 local 引用,这时就需要手动释放(DeleteLocalRef),而不应该依赖 JNI 处理. 例外: 一个 native 创建的线程,执行过 AttachCurrentThread 操作,在 detach 之前,程序并不会自动删除 local 引用,创建的任何local 都需要自己手动删除. 8.0 之前(和具体版本相关) 只预留了 16 个了 local 引用的 slot(槽位),超过的,要自己手动释放,否则会crash.也可以使用 EnsureLocalCapacity/PushLocalFrame 来增加槽位. 实测下来: 每个槽位对应 32 个引用,所以,16个槽位,可以存放 512 个 local 引用; 8.0 之后 不限制数量. ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:5:1","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"global references global 正好是为了突破 local 所产生的限制: 当前线程 与 当前 native 方法; 通过 NewGlobalRef 和 NewWeakGlobalRef (可以接收 local 和 global 引用作为参数) 来创建 global 引用,只有调用在 DeleteGlobalRef 之后才会失效; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:5:2","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"引用的适用范围 对于接收引用的 native 方法,可以接收 local 引用 和 global 引用,除了生命周期以外,用法一致; 版本限制 从 Android4.0 开始,weak global 引用才可像其他的引用一样使用,在此之前,只可用于 NewLocalRef, NewGlobalRef, and DeleteWeakGlobalRef. ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:5:3","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"引用之间的比较 对于指向相同对象的不同引用的值是很可能不一样的.例如,针对同一个对象连续调用 NewGlobalRef 返回的引用,值就可能不同.所以对于两个不同的引用,判断是否指向同一个对象,用 IsSameObject 函数判断,千万不要用 == . 特性带来的影响: 不能假设 native 层中的对象引用是常量或者唯一的; 同一个方法的两次调用,表示对象的引用可能是不同; 不同对象的引用可能具有相同的值; 故而,切勿将 jobject 作为键; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:5:4","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"注意点: 引用仅针对 jobject 及其子类. 而 jfieldID 和 jmethodID 不适用,不应该传递给 NewGlobalRef GetStringUTFChars 和 GetByteArrayElements 返回的是原始数据指针,非对象引用,他们可以在线程间传递,在执行对应的 release 之前,一直有效 总的来说, native 代码中创建的 local 引用,及时的显式 delete 谨慎使用全局引用,太多的全局引用会导致调试困难 引用是否指向同一个对象,用 IsSameObject 方法 典型的使用代码: jclass localClass = env-\u003eFindClass(\"MyClass\"); jclass globalClass = reinterpret_cast\u003cjclass\u003e(env-\u003eNewGlobalRef(localClass)); ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:5:5","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"UTF-8 and UTF-16 strings ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:6:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"Java 与 JNI 编码不一致 Java 中用的字符编码是 UTF-16 JNI 为了方便起见,采用的是 Modified UTF-8(将 \\u0000 编码成 0xc0 0x80 ,而不是 0x00,这样得到的字符串,就是一个 C-style 的字符串) 利弊 优点: JNI 中可以直接用 libc 字符串相关的函数; 缺点: 标准的 UTF-8 的数据传递给 JNI 函数时,可能无法正常工作; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:6:1","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"注意点 如果可行的话,就全部转成 UTF-16,这样操作的最快. GetStringChars:返回的是 UTF-16 的数据,UTF-16 的字符串是没有结尾的符号的,C style 的字符串函数是没法判断结尾的,所以,如果用 UTF-16 的话,需要自己维护一个字符串长度和 jchar 指针. GetStringUTFChars:返回的是 Modified UTF-8 的数据,可以直接用 C style 的字符串函数. GetStringChars 返回值是 jchar 指针,GetStringUTFChars 返回的是 char*,都是原始数据的指针,而不是前一个section里的 reference,在调用对应的 release 方法之前,都是有效的,不用担心作用域问题;相应的,不用时,及时 release; NewStringUTF:参数必须是 Modified UTF-8 格式的,切勿将文件流或者网络下载的标准 UTF-8 格式的数据直接传; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:7:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"处理建议 ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:8:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"策略一: JNI jstring 通过 Java 层的 String 的 getBytes(“UTF-8”) 方法来获取标准 UTF-8 格式的字符串; 当 JNI 返回 Java 层数据时,Java 层可以通过 String 对应的构造方法处理; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:8:1","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"策略二: 在 native 层面进行编码的转换,JNI 不变,依旧使用 Modified UTF-8,通过算法处理编码转换. ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:8:2","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"Primitive arrays JNI 提供的数组操作需要一个一个的操作,有些麻烦.原生数组可以使得数组像被 native 中定义的数组一样,可以被直接操作. 为了高效 GetArrayElements(array,isCopy) 系列的函数,既可以返回真实数组的指针,也可以分配内存,拷贝到 native; 无论哪种,指针在调用 release 之前,都是有效的. 如果未采用复制方式,返回的真实数组指针,那么,数组的对象将会固定不变,即使是在 GC 进行堆压缩的时候. get 的数组,需要进行 release,并且不能对一个空指针进行 release. release 方法有个 mode 参数,执行的效果取决于 GetArrayElements 方法返回的指针是指向的原始数据,还是复制的内存拷贝; 0 a. Actual: 数组对象取消固定. b. Copy: 数据重新拷贝回去,原先分配的内存空间释放. JNI_COMMIT a. Actual: does nothing. b. Copy: 数据重新拷贝回去,原先分配的内存空间并不释放. JNI_ABORT a. Actual: 数组对象取消固定. 之前的写入已经生效. b. Copy: 原先分配的内存空间释放,数据操作丢失. 一个常见的错误是: 如果 isCopy 是 false,则可以省略 release 操作,这个是非常错误的做法,因为不进行 release 的话,则原始数据将会一直固定,得不到回收器的回收. 其次需要注意: JNI_ABORT 并不会释放数组,需要以其他的 mode 再次调用 release 进行释放,这个是很容易犯错的;比如, JNI_ABORT 之后,再调用 0; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:9:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"注意点 根据需求,决定 GetArrayElements 是否 copy 数组到 native 无论何种方式获取的数组,都需要 release release(JNI_ABORT) 并不会释放数组,需要再调用 release(0) ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:9:1","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"Region calls 如对 GetArrayElements 和 GetStringChars 的需求都是 copy=true 的话,则 Region call 会是个不错的替代方案,提供了更多的灵活性和更好的性能. ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:10:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"考虑一个场景: 需要字节数组中的 len 长度的部分 采用 GetArrayElements // jbyte* data = env-\u003eGetByteArrayElements(array, true); if (data != NULL) { memcpy(buffer, data, len); // extra,copy part env-\u003eReleaseByteArrayElements(array, data, JNI_ABORT); } 采用 GetByteArrayRegion env-\u003eGetByteArrayRegion(array, 0, len, buffer); 对比 方案 代码书写 JNI调用次数 固定Java数组 方式一 复杂,需要执行额外的一次复制操作 2 固定 方式二 简洁,出错率低 1 不固定 有 Get,也同样有对应的 Set 方法,用于将数据复制回数组或者字符串; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:10:1","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"注意点 当需要对数组或者字符串进行copy操作时候,优先用对应的 Region 操作 ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:10:2","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"Exceptions ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:11:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"限制 当发生异常的时候,大多数的 JNI 方法将不能调用,只有固定的几个方法能调用,参见 仍可以调用的方法 由代码中断触发的异常,并不会释放 native 的栈信息,Android 目前也不支持 C++ 的 Exception; JNI 通过 Throw 和 ThrowNew 指令,只是在当前的线程中设置了一个异常的指针,等到 native 方法结束,返回 Java 层的时候,这时候才会被处理. JNI 无法持有 Throwable 这个对象,如果需要在 native 层处理异常,需要 findclass Java 层的 Throwable 类,通过相关方法处理. ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:11:1","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"处理方式 少部分可以通过检查返回值,检查比较简单,比如 NewString,判断返回值是否为 null,进行判断. 大部分需要主动检查异常,比如 CallObjectMethod 函数,因为一旦抛出异常,此时的返回值是无效的. ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:11:2","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"涉及到的 JNI 方法 ExceptionCheck 与 ExceptionOccurred, 进行异常的检查和捕获. ExceptionClear 可以清除异常,但是清除异常不是一个好的处理手段. ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:11:3","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"注意点 通过 ExceptionCheck 检测是否有异常,通过 Throw 抛出到 Java 层进行处理. 如果异常是可以忽略的,先 ExceptionClear,再继续执行其他 JNI 操作,否则会 crash. ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:11:4","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"Extended checking JNI 对错误的检查很少,所以 Android 提供了一种称为 CheckJNI 的模式,通过修改 JavaVM 和 JNIEnv 的函数表指针,实现在调用所有的 JNI 函数之前,都会进行一系列的检查. 具体的检查项 : ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:12:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"注意点 模拟器: 默认开启 rooted device adb shell stop adb shell setprop dalvik.vm.checkjni true adb shell start 开启后会在 logcat 里看到 D AndroidRuntime: CheckJNI is ON regular device: 不会影响正在运行的App,而且开启时,所有启动的App都会检查. // 设备重启后失效 adb shell setprop debug.checkjni 1 开启后会在 logcat 里看到 D Late-enabling CheckJNI 针对单个App进行检查 android:debuggable 设置为 true 即可,正常的 debug版本不需要手动配置,Android build-tool 会自动设置; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:12:1","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"Native libraries ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:13:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"加载动态库的方式 以下以打包出的动态so文件为: lib名字.so 为例. 系统默认方式加载 static { System.loadLibrary(\"名字\"); } 官方推荐 ReLinker 方式 在旧版本 Android 的 PackageManager 有 bug 在 App 升级时 so 库可能没有成功复制到 /data/data/packageName/lib/ 下,导致 “java.lang.UnsatisfiedLinkError”,故而 Google 推荐用 ReLinker ReLinker.loadLibrary(context, \"名字\"); Facebook SoLoader ReLinker 不能解决 so 依赖问题, SoLoader 可以解决这个问题. PS: 接入复杂,我还没玩过.可以参考 Facebook 的 RN 和 fresco. ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:13:1","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"确保运行时可以查找 native 方法 RegisterNatives 显式的注册 实现 JNIEXPORT jint JNI_OnLoad(JavaVM* vm, void* reserved) 在 JNI_OnLoad 方法中,使用 RegisterNatives 注册所有的 native方法 加参数 -fvisibility=hidden 可以保证 只有 JNI_OnLoad 被导出,这样的 so 文件更小,更快,且能避免和App中加载的其他so冲突,但是这会带来一个问题,crash的时候,栈信息会更少 JNIEXPORT jint JNI_OnLoad(JavaVM* vm, void* reserved) { JNIEnv* env; if (vm-\u003eGetEnv(reinterpret_cast\u003cvoid**\u003e(\u0026env), JNI_VERSION_1_6) != JNI_OK) { return JNI_ERR; } // Find your class. JNI_OnLoad is called from the correct class loader context for this to work. jclass c = env-\u003eFindClass(\"com/example/app/package/MyClass\"); if (c == nullptr) return JNI_ERR; // Register your class' native methods. static const JNINativeMethod methods[] = { {\"nativeFoo\", \"()V\", reinterpret_cast\u003cvoid*\u003e(nativeFoo)}, {\"nativeBar\", \"(Ljava/lang/String;I)Z\", reinterpret_cast\u003cvoid*\u003e(nativeBar)}, }; int rc = env-\u003eRegisterNatives(c, methods, sizeof(methods)/sizeof(JNINativeMethod)); if (rc != JNI_OK) return rc; return JNI_VERSION_1_6; } 优点: 前端即可检查方法是否存在. 可以仅导出 JNI_OnLoad 方法,使得共享库更小,更快. 使用 dlsym 动态查找 Java 类中声明一个 native 标识的方法. 借助 AndroidStudio 自动生成对应的 native 方法,方法名的生成规则为: Java_点全部换成下划线的packageName_methodName. 目前 AndroidStudio 自动生成这类代码的能力很强了. extern \"C\" JNIEXPORT jstring JNICALL Java_me_ele_wp_ndkstudy_MainActivity_stringFromJNI( JNIEnv *env, jobject /* this */) { std::string hello = \"Hello from C++\"; return env-\u003eNewStringUTF(hello.c_str()); } 优点: 优点在于编写的代码较少,尤其借助 AndroidStudio,快捷方便. 缺点: 即使是一个参数的错误,也只能等到运行时调用的时候,才能发现. ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:13:2","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"native 中加载 Java 类 JNI_OnLoad 方法中的 FindClass FindClass 函数的调用,用来查找和加载 Java 类所用的 classloader 与加载 so 文件的那个类所用的 classloader 是同一个,也就是说,在哪个类加载 so 文件,就用哪个类的 classloader. 其他地方 FindClass 函数的调用 使用的是 Java 栈顶关联的 classloader 如果不存在 Java 栈(native 线程,attach 到 VM 上),则使用 system classloader. 所以,在 JNI_OnLoad 中,查找出所有的 jclass,并进行缓存,是最好的选择.一旦成功获取 jclass,可以任何线程中共享 jclass; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:13:3","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"注意点 优先选择 ReLinker 进行 so 文件加载. 如果只有一个类有 native 的方法,so 文件的加载,则可以选择放在在该类的静态代码块中进行加载;否则,请在 Application 中进行加载,以确保 App 调用native 方法前,so 文件已经得到正确的加载. 方法的注册,看自己的选择. RegisterNatives 优点相对明显些,如果 native 方法数量不多,二者皆可. native 如果用到 jclass,建议在 JNI_OnLoad 方法中进行缓存,避免出错. ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:13:4","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"64-bit considerations ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:14:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"注意点 为了支持 64 位的架构,Java 层存储 native 层的指针时,需要用 long 类型,而不是 int类型. QA ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:14:1","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"UnsatisfiedLinkError 如何处理? ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:15:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"Library 名字 not found java.lang.UnsatisfiedLinkError: Library 名字 not found 如日志所述,确实没找到 so 文件; so 文件存在,App 无权访问; 通过 adb shell ls -l 检查 so 文件是否存在,并检查App 是否有访问的权限; so 库不是通过 NDK 打包的,库中有些函数,在设备上找不到. ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:15:1","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"No implementation found for functionName java.lang.UnsatisfiedLinkError: myfunc at Foo.myfunc(Native Method) at Foo.main(Foo.java:10) W/dalvikvm( 880): No implementation found for native LFoo;.myfunc ()V so 库未成功加载,可以通过 logcat 检查加载 so 库的日志; 方法的名字或者签名不匹配; a. 函数未 extern “C JNIEXPORT; b. 显式注册时,签名不对. javap -s JavaClassName 这个命令可以检查Java方法的签名. ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:15:2","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"FindClass 失败 检查类名,方法名,签名等字符串是否写错,同时检查是否被混淆; classloader 的问题: findclass 想在 native 代码关联的 classloader 中搜索类.如果此时是自己创建的 native 线程,再 attach 到 javavm 上,则会在系统 classloader 中查找,如果是自定义的类,必然失败; ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:16:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"解决方案 JNI_OnLoad 中执行一次 FindClass 查找，然后缓存类引用,各个线程则可以放心使用,优先推荐. 通过声明 native 方法来获取 Class 参数: 声明一个有 class 参数的 native 方法,Java 层将 class 传入.这个有些麻烦. ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:16:1","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["Android"],"content":"native 层和 Java 层共享原始数据 存在以下几种方式 数据转换成 byte 数组,两边都处理 byte 数组 Java 层处理起来是很快的,但是 native 层是无法保证不进行 copy 操作的. GetByteArrayElements 和 GetPrimitiveArrayCritical 可以返回 Java 堆上的原始数据的指针,然而有时候,是会在 native 的堆上分配一块空间,再将数据 copy 到 native 堆上的这块空间. 直接字节缓存. 用 java.nio.ByteBuffer.allocateDirect,JNI 中的 NewDirectByteBuffer 函数来创建直接字节缓存,这个不像常规的 Java 字节 buffer 分配,这部分内存不是在 Java 堆上分配,这部分内存空间,可以交由 native 直接访问(通过 GetDirectBufferAddress 方法地址). 这个的弊端是: Java 层对这部分数据分访问可能很慢; 使用哪种方法取决于 大部分的数据访问是否是通过 Java/C++ ? 这部分数据最终是否需要传给系统 API?这部分 API 接收的数据格式是什么?(例如，如果数据最终传递给采用 byte[] 的函数，则采用 ByteBuffer 就不合适) 如果二者差不多,优先使用直接字节缓存. 参考文献 Android JNI Tip Java Native Interface Specification ","date":"2020-02-13","objectID":"/2020/02/ndk-jni-tip/:17:0","tags":["NDK","JNI"],"title":"NDK学习之JNI_Tip","uri":"/2020/02/ndk-jni-tip/"},{"categories":["HTTP"],"content":"概述 记录另外一个mockserver的库使用方式. API 更加丰富. 添加依赖 compile group: 'org.mock-server', name: 'mockserver-netty', version: '5.6.1' compile group: 'log4j', name: 'log4j', version: '1.2.17' 使用方式 ","date":"2019-10-14","objectID":"/2019/10/mockserver-java-primer/:0:0","tags":["mock"],"title":"一个开源的Java版的mockserver","uri":"/2019/10/mockserver-java-primer/"},{"categories":["HTTP"],"content":"最简单的使用方式, 请求 -\u003e 返回mock的response Server端 public class MockServerTest { public static void main(String[] args) { // 1. 8000端口启动服务 ClientAndServer.startClientAndServer(8000); // 2. new 一个操作服务端行为的实例 MockServerClient serverClient = new MockServerClient(\"localhost\", 8000); // 3. 定义服务端的行为 serverClient .when(request() .withMethod(\"GET\") .withPath(\"/path1/function1\")) .respond(response() .withStatusCode(200) .withBody(\"body200\")); serverClient .when(request() .withMethod(\"GET\") .withPath(\"/path2/function2\") .withCookies(cookie(\"session\", \"4930456C-C718-476F-971F-CB8E047AB349\")) .withQueryStringParameters(param(\"cartId\", \"055CA455-1DF7-45BB-8535-4F83E7266092\"))) .respond(response() .withStatusCode(307) .withBody(\"body307\")); } } Client 端 public class MockTestClient { public static void main(String[] args) { OkHttpClient client = new OkHttpClient(); Request request = new Request.Builder().url(\"http://localhost:8000/path1/function1\") .build(); Response response = null; try { response = client.newCall(request).execute(); System.out.println(response.body().string()); } catch ( IOException e) { e.printStackTrace(); } } } 以上先记录最简单的使用,还有forward,callback,verify,retrieve,感觉用的不多,暂不记录,需要的时候再说吧. 参考 mockserverRepo mockserverPage ","date":"2019-10-14","objectID":"/2019/10/mockserver-java-primer/:1:0","tags":["mock"],"title":"一个开源的Java版的mockserver","uri":"/2019/10/mockserver-java-primer/"},{"categories":["HTTP"],"content":"概述 本篇记录okhttp自带的mockserver这个库的使用方式. 作为一个网络库,okhttp自身也实现了一个mockserver,以方便写测试用例,这个库是独立的,也可以单独使用. 用作平时简单的mock数据,进行测试,很方便 使用方式 此处以Android为例,Java除了依赖方式有点差异,其他一致; 添加依赖 androidTestImplementation('com.squareup.okhttp3:mockwebserver:3.13.1') 代码使用 public class MockRes { public final MockWebServer server = new MockWebServer(); public OkHttpClient client = new OkHttpClient(); @Test public void simpleTest() { // 构造一个mock的 response MockResponse mockResponse = new MockResponse().setBody(\"abc\"); // 添加到 server 中,server中将会按照FIFO的方式进行返回 // enqueue 一个,下次请求就返回队列中最靠前的,是同步的 server.enqueue(mockResponse); // 同步发起请求,虽然此处添加了path,实则在不自定义dispatcher的请求下,是不会影响前一步mockresponse的返回的 Response executeRes = executeSynchronously(\"/a\"); // 消费mock的结果 assertNotNull(executeRes); try { assertEquals(\"abc\", executeRes.body().string()); } catch (IOException e) { e.printStackTrace(); } } @Test public void customDispatch() { // 采用自定义 dispatcher 之后,就不能再 调用 server.enqueue(mockResponse) 方法,所有的mock行为均定义在 Dispatcher 类中 server.setDispatcher(new Dispatcher() { @Override public MockResponse dispatch(RecordedRequest request) throws InterruptedException { if (\"/a\".equals(request.getPath())) { return new MockResponse().setBody(\"A\"); } return new MockResponse().setBody(\"O\"); } }); // 同步发起请求,path 为 /a 怎么应该返回body 是 A Response executeRes = executeSynchronously(\"/a\"); // 消费mock的结果 assertNotNull(executeRes); try { assertEquals(\"A\", executeRes.body().string()); } catch (IOException e) { e.printStackTrace(); } // 同步发起请求,path 为 /b 怎么应该返回body 是 O Response bRes = executeSynchronously(\"/b\"); // 消费mock的结果 assertNotNull(bRes); try { assertEquals(\"O\", bRes.body().string()); } catch (IOException e) { e.printStackTrace(); } } private Response executeSynchronously(String path, String... headers) { Request.Builder builder = new Request.Builder(); builder.url(server.url(path)); for (int i = 0, size = headers.length; i \u003c size; i += 2) { builder.addHeader(headers[i], headers[i + 1]); } Call call = client.newCall(builder.build()); try { return call.execute(); } catch (IOException e) { return null; } } } 参考 okhttp测试 ","date":"2019-10-13","objectID":"/2019/10/mockserver_primer/:0:0","tags":["mock"],"title":"okhttp自带的mockserver教程","uri":"/2019/10/mockserver_primer/"},{"categories":["Engineering"],"content":"概述 刚在InfoQ上看到一篇介绍C4Model的文章,觉得这个模型设计的很赞,很有指导意义,做个简单的记录. Why,为什么需要架构图? ThoughtWorks中国 文章中有几句话我觉得很有道理,这里直接摘抄. “纸上的不是架构，每个人脑子里的才是” ; “那些精妙的方案之所以落不了地，是因为没有在设计上兼容人类的愚蠢”。 我觉得,软件工程,或者软件中的术语发明的原因就是为了减少沟通的障碍,让大家在一个 平台 上对话. 而架构图可以起到如下作用; 一方面: 让软件的开发人员自己,以及和软件开发相关的用户,PM等人员都能快速了解一个系统的业务模型; 另一方面: 利于开发人员相互之间协作,定下方案,因为自然语言是有模糊地带的,难以无歧义的传达; 利于软件系统的维护,一图胜千言. What,C4 是什么呢? 详细的讲解,可以参考InfoQ的文章,这里做个总结. C4 4个单词的首字母为C的单词的代表, 分别为: 上下文(Context),容器(Container),组件(Component)和代码(Code); 依据不同的受众,分别抽象出了这四个级别.其中容器（应用程序、数据存储、微服务等,组件和代码来描述一个软件系统的静态结构. ","date":"2019-04-13","objectID":"/2019/04/engineering-c4model/:0:0","tags":["Engineering","C4"],"title":"工程能力之C4模型","uri":"/2019/04/engineering-c4model/"},{"categories":["Engineering"],"content":"第 1 层：系统上下文 显示了正在构建的软件系统，以及构建的系统与用户及其他软件系统之间的关系。 这个层级的图,关注的是用户层面看到的关系,注重的是和准备开发的系统与外部系统和交互人之间的关系. 将用户,你的代建系统,已有的其他系统用不同的颜色进行区分; ","date":"2019-04-13","objectID":"/2019/04/engineering-c4model/:1:0","tags":["Engineering","C4"],"title":"工程能力之C4模型","uri":"/2019/04/engineering-c4model/"},{"categories":["Engineering"],"content":"第 2 层：容器 将软件系统放大，显示组成该软件系统的容器（应用程序、数据存储、微服务等）。 在这个层级,已经关注系统本身了,开始关注这个系统有哪些部分组成,不过粒度非常粗. ","date":"2019-04-13","objectID":"/2019/04/engineering-c4model/:2:0","tags":["Engineering","C4"],"title":"工程能力之C4模型","uri":"/2019/04/engineering-c4model/"},{"categories":["Engineering"],"content":"第 3 层：组件 将单个容器放大，以显示其中的组件。这些组件映射到代码库中的真实抽象（例如一组代码）。 在这个层级,关注的已经是系统中的模块具体的功能了,这部分可能对应了具体的功能模块. ","date":"2019-04-13","objectID":"/2019/04/engineering-c4model/:3:0","tags":["Engineering","C4"],"title":"工程能力之C4模型","uri":"/2019/04/engineering-c4model/"},{"categories":["Engineering"],"content":"第 4 层：代码 如若必要,可以放大个别组件，以显示该组件的实现方式。 一般以UML图的形式展示; 这个层级,是具体的开发人员关注的实现细节了,用于具体的功能逻辑的分析和展示. How,怎能画图呢? 在C4官网,下有个Tooling节点,讲述了目前已有的几个画图工具. 参考 用于软件架构的C4模型 可视化架构设计——C4介绍 C4官网 ","date":"2019-04-13","objectID":"/2019/04/engineering-c4model/:4:0","tags":["Engineering","C4"],"title":"工程能力之C4模型","uri":"/2019/04/engineering-c4model/"},{"categories":["Network","H2"],"content":"概述 HTTP/2 仍是对之前 HTTP 标准的扩展,而非替代.HTTP 的应用语义不变，提供的功能不变,HTTP 方法、状态代码、URI 和标头字段等这些核心概念也不变. 背景 本文是对Google博客上文章的翻译和笔记.以及一些待解决的问题记录. Google 博客上这篇文章的中文版有很多翻译错误. ","date":"2019-04-09","objectID":"/2019/04/h2-first/:0:0","tags":["Network"],"title":"HTTP2初探","uri":"/2019/04/h2-first/"},{"categories":["Network","H2"],"content":"HTTP/2 的主要目标是: 通过支持完整的请求与响应的多路复用来减少延迟; 通过有效压缩 HTTP 标头字段将协议开销降至最低; 增加对请求优先级和服务器推送的支持; ","date":"2019-04-09","objectID":"/2019/04/h2-first/:1:0","tags":["Network"],"title":"HTTP2初探","uri":"/2019/04/h2-first/"},{"categories":["Network","H2"],"content":"重要的两点 HTTP/2 没有改动 HTTP 的应用语义。HTTP 方法、状态代码、URI 和标头字段等核心概念一如往常; HTTP/2 修改了数据格式化(分帧)以及在客户端与服务器间传输的方式; 这两点统帅全局，通过新的分帧层向我们的应用隐藏了所有复杂性。可以实现在同一连接上 进行多个并发交换. Binary framing layer: 二进制分帧层 HTTP/2 所有性能增强的核心在于新的二进制分帧层，它定义了如何封装 HTTP 消息并在客户端与服务器之间传输。 这里所谓的“层”，指的是位于套接字接口与应用可见的高级HTTP API之间一个经过优化的新编码机制:HTTP 的语义（包括各种动词、方法、标头）都不受影响，不同的是传输期间对它们的编码方式变了。 HTTP/1.x 协议以换行符作为纯文本的分隔符，而 HTTP/2 将所有传输的信息分割为更小的消息和帧，并采用二进制格式对它们编码。 数据流、消息和帧 数据流：已建立的连接内的双向字节流，可以承载一条或多条消息。 消息：与逻辑请求或响应消息对应的完整的一系列帧。 帧：HTTP/2 通信的最小单位，每个帧都包含帧头，至少也会标识出当前帧所属的数据流。 ","date":"2019-04-09","objectID":"/2019/04/h2-first/:2:0","tags":["Network"],"title":"HTTP2初探","uri":"/2019/04/h2-first/"},{"categories":["Network","H2"],"content":"简单概括一下: 所有通信都在一个 TCP 连接上完成，此连接可以承载任意数量的双向数据流。 每个数据流都有一个唯一的标识符和可选的优先级信息，用于承载双向消息。 每条消息都是一条逻辑 HTTP 消息(例如请求或响应)，包含一个或多个帧。 帧是最小的通信单位，承载着特定类型的数据，例如 HTTP 标头、消息负载等等.来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装. HTTP/2 将 HTTP 协议通信分解为二进制编码帧的交换，这些帧对应着特定数据流中的消息。所有这些都在一个 TCP 连接内复用。 Request and response multiplexing: 请求与响应复用 在 HTTP/1.x 中，如果客户端要想发起多个并行请求以提升性能，则必须使用多个 TCP 连接. 即: 多个并行请求 == 多个 TCP 连接; H2 中客户端和服务端将HTTP消息分解为互不依赖的帧,在一条TCP连接上交替发送,在最后一端进行重新组装.这样可以实现请求和相应复用. 图中展示了三个数据流正在并行传输. 客户端正在向服务器传输一个 DATA 帧（数据流 5）. 服务器正向客户端交错发送数据流 1 和数据流 3 的一系列帧。 优点:显著提高效率; Stream prioritization:数据流优先级 将数据分解为帧之后,这些帧就可以实现多路复用,故而,这些帧的顺序就很重要. 所以H2允许每个数据流都有一个关联的优先级和依赖关系. H2 允许: 每个数据流可以分配一个1到256之间的一个整数,作为权重; 每个数据流可以和其他的数据流存在明确的依赖关系; 权重和依赖关系的设定,可以让客户端构造和传达一个优先级树,以表示客户端想要如何接受响应; 相对的,服务端可以通过这个优先级树,来控制CPU,内存和其他资源的,以达到设置流优先级的目的;一旦 response 资源可用, 控制带宽的分配可以达到最佳的方式传递高优先级的数据传递到 客户端; 一个流的依赖关系通过引用另外一个流的唯一标识符作为parent,来达到依赖; 如果parent 被省略,则 parent就是root 流; 声明流的依赖关系,意味着, parent 流资源分配优先级需要在依赖方之前; 如图: 图中 D 需要在 C 之前得到处理. 对于共享一个parent的兄弟节点,则根据他的权重比例进行资源的分配; 图中的A和B,需要按照 12/16 和 4/16 的比例进行资源的分配; 图中需要解释的有 D依赖于root stream; A 和 B 依赖于 C; E 和 C 依赖于 D; 所以: D优先于E和 C得到全部的资源; E和C 优先于AB得到全部的资源; E和C按照等比例拿到资源; C优先于AB 拿到全部资源,此时与权重无关,由依赖关系决定. 除此之外,优先级和依赖关系还允许客户端在任意的时间点进行修改.这样就允许了浏览器更进一步的优化;换句话中,我们可以在和用户的交互的过程中,修改依赖关系和权重,来达到用户的交互和其他的一些信号. PS: 对于权重和依赖关系,只是客户端请求的一个偏好,服务端并不保证一定会按照这个依赖关系和权重进行资源的分配; 虽然看上去似乎有违直觉,可是,我们不能因为高优先级的请求block了,而不顾低优先级的任务; One connection per origin: 每个源,都有个连接 即多路复用. 有了新的分帧机制后，HTTP/2 不再依赖多个 TCP 连接去并行复用数据流； 每个数据流都拆分成很多帧，而这些帧可以交错，还可以分别设定优先级。 因此，所有 HTTP/2 连接都是持久化的，而且每个来源仅需一个连接. 大多数的HTTP连接都是急促而短暂的,但是TCP对于长连和批量数据进行了优化. 通过复用连接,提高了连接的利用率,也降低了协议的开销. 可以减少占用的内存和处理空间，也可以缩短完整连接路径; 连接数量减少,可以减少开销较大的 TLS 连接数、提升会话重用率，以及从整体上减少所需的客户端和服务器资源。 Flow control: 流控制 流控制是为了防止出现,接收方繁忙,负载较高,或者仅仅只想为特定的数据流分配固定的资源,然而发送方已经不停的发送; 这和TCP的控制流类似,然而H2的多个数据流在单一的TCP连接上复用,然而TCP的控制不够精细,也为提供应用级别的API来控制单一流的传输控制. H2提供了一组简单的构建块, 来允许客户端和服务端各自的流级别和连接级别的控制; 流控制是有方向性的. 每个接收方都可以为每个流或者整个连接设置自己期望的窗口大小. 流控制是基于信用的. 每个接收方通告自己的初始连接,初始流的控制窗口的大小(以字节为单位). 任何时候,发送方可以通过发射一个 DATA 帧来减少窗口的大小; 接收方可以发送一个 WINDOW_UPDATE 帧来实现窗口的增大; 流控制是不能禁用的. 当H2的连接建立之后,客户端和服务端相互交换了 SETTINGS 帧,这个帧交换起到了设置双方在两个方向上窗口的大小. 默认的控制窗口的大小是65535字节,但是接收方是可以在收到任何数据时,通过发送WINDOW_UPDATE帧来设置一个大的 “最大窗口大小”: 2^31-1 个字节来维持这一窗口大小. 流控制是跳到跳的,而不是端到端的. 也就是说,一个中间人可以基于自身的条件和启发式的算法,使用流控制来控制资源使用和实现资源费分配机制. H2未指定任何的流控制算法,替代的,提供了构建块将具体的算法实现交给了客户端和服务端,实现自定义的策略,以实现资源分配和资源的使用; 也可以实现自定义的传输能力以提高真实和感知性能. 举例: 应用层流控制允许浏览器将流控制窗口设置为0 ,以达到暂停一部分流的加载,先加载优先级更高的流,等到适当的时候再通过调整窗口的大小以重新恢复低优先级的资源加载. Server push: 服务器推送 H2可以实现向客户端发送多个响应. 即可实现无需客户端主动请求的情况,实现对客户端的推送. 如图所示,除了stream1 是主动请求,其他的都是服务端主动推送的. 注意: H2打破了原先的请求响应语义;支持一对多和服务器发起的工作流, PUSH_PROMISE 101: 所有服务器推送数据流都由PUSH_PROMISE帧发起，以表明了服务器向客户端推送所述资源的意图，并且需要先于客户端对于该推送资源的请求。 故而传输顺序非常重要：客户端需要了解服务器打算推送哪些资源，以免对这些资源创建重复请求。 满足此要求的最简单策略是,先于父响应（即,DATA帧）发送所有PUSH_PROMISE帧，其中包含所承诺资源的 HTTP 标头,这样客户端就知道哪些资源是服务端打算推送的。 在客户端接收到PUSH_PROMISE帧 后，它可以根据自身情况选择拒绝数据流（通过RST_STREAM帧）。 （例如，如果资源已经位于缓存中，便可能会发生这种情况。）. 这是一个相对于 HTTP/1.x 的重要提升。 相比之下，使用资源内联（一种受欢迎的 HTTP/1.x“优化”）等同于“强制推送”：客户端无法选择拒绝、取消或单独处理内联的资源。 使用 HTTP/2，客户端仍然完全掌控服务器推送的使用方式。 客户端可以 限制并行推送的数据流数量； 调整初始的流控制窗口以控制在数据流首次打开时推送的数据量； 或完全停用服务器推送。 这些偏好设置在 HTTP/2 连接开始时通过SETTINGS帧传输，也可以随时更新。 推送的每个资源都是一个数据流，客户端可以对推送的流进行多路复用,设定优先级。 浏览器强制执行的唯一安全限制是，推送的资源必须符合原点相同这一政策：服务器对所提供内容必须具有权威性。 Header compression: header 压缩 传统H1的 header 使用的是纯文本,这会对传输过程带来500–800 字节的额外开销. H2使用了 HPACK 压缩方式,对请求头和响应头的元数据进行压缩,进而减少开销. 采用两种技术: 对传输的header进行静态哈夫曼编码,可以有效减少独立传输的大小; 客户端和服务端同时维护和更新一份之前出现过的header字段的索引表;,随后对之前传输过的值进行编码,这份索引表将会作为参考,以提高效率; 哈夫曼编码允许对单个值在传输的时候进行压缩, 对传输过的值进行索引,这样可以在传递重复的值时,只需索引值,根据索引值,可以快速的查找和重构完整的header 的 key 和 value. 作为一个深远的优化,哈夫曼编码包含了动态表和静态表. 静态表包含了一些常用的HTPP header字段,这些字段是所有连接都可能使用的. 动态表默认是空的,在不同的连接过程中,根据交换的值不同而进行更新. 进而带来的结果是,每次请求,因为对未曾出现过的值使用了静态哈夫曼编码,对在两侧静态或者动态表中都出现的使用了索引值而不是直接的原始值,因而这次请求会因此而减小; H2中的请求和相应的header字段的定义保持不变,仅有的一个小例外是: 所有的 header 字段的名字必须是小写, 请求行被分割成独立: :method, :scheme, :authority, 和 :path 等伪header字段. 读完文章后的待解决问题,需要更进一步的研究 H2中的request line最终变成的格式是什么样的? message被切割成frame,这些frame是按照什么规则切割的?文章中的举例是 header 和 data payload . head-of-line blocking 是什么? One connection per or","date":"2019-04-09","objectID":"/2019/04/h2-first/:3:0","tags":["Network"],"title":"HTTP2初探","uri":"/2019/04/h2-first/"},{"categories":["Mobile","Android"],"content":"概述 Activity 在横竖屏切换的时候,生命周期是不一样的,本地通过打印 log 的方式,看下区别.测试的机器是 Android6.0 . 不做任何配置的情况下 ","date":"2018-04-26","objectID":"/2018/04/activitylifecycle/:0:0","tags":["Activity"],"title":"Activity 在横竖屏切换情况下的生命周期变化","uri":"/2018/04/activitylifecycle/"},{"categories":["Mobile","Android"],"content":"第一次启动 D/LifeCircleActivity: onCreate() called with: savedInstanceState = [null]Activity对象的地址:cn.steve.activitylifecycle.LifeCircleActivity@de950fc D/LifeCircleActivity: onStart() called D/LifeCircleActivity: onResume() called ","date":"2018-04-26","objectID":"/2018/04/activitylifecycle/:1:0","tags":["Activity"],"title":"Activity 在横竖屏切换情况下的生命周期变化","uri":"/2018/04/activitylifecycle/"},{"categories":["Mobile","Android"],"content":"第一次切换成横屏 D/LifeCircleActivity: onPause() called D/LifeCircleActivity: onSaveInstanceState() called with: outState = [Bundle[{android:viewHierarchyState=Bundle[{android:views={16908290=android.view.AbsSavedState$1@80a47f5, 2131296581=android.view.AbsSavedState$1@80a47f5, 2131296815=android.view.AbsSavedState$1@80a47f5}}], key=x}]] D/LifeCircleActivity: onStop() called D/LifeCircleActivity: onDestroy() called D/LifeCircleActivity: onCreate() called with: savedInstanceState = [Bundle[{android:viewHierarchyState=Bundle[{android:views={16908290=android.view.AbsSavedState$1@80a47f5, 2131296581=android.view.AbsSavedState$1@80a47f5, 2131296815=android.view.AbsSavedState$1@80a47f5}}], key=x}]]Activity对象的地址:cn.steve.activitylifecycle.LifeCircleActivity@266fbfb D/LifeCircleActivity: onStart() called D/LifeCircleActivity: onRestoreInstanceState() called with: savedInstanceState = [Bundle[{android:viewHierarchyState=Bundle[{android:views={16908290=android.view.AbsSavedState$1@80a47f5, 2131296581=android.view.AbsSavedState$1@80a47f5, 2131296815=android.view.AbsSavedState$1@80a47f5}}], key=x}]] D/LifeCircleActivity: onResume() called ","date":"2018-04-26","objectID":"/2018/04/activitylifecycle/:2:0","tags":["Activity"],"title":"Activity 在横竖屏切换情况下的生命周期变化","uri":"/2018/04/activitylifecycle/"},{"categories":["Mobile","Android"],"content":"再切换成竖屏 D/LifeCircleActivity: onPause() called D/LifeCircleActivity: onSaveInstanceState() called with: outState = [Bundle[{android:viewHierarchyState=Bundle[{android:views={16908290=android.view.AbsSavedState$1@80a47f5, 2131296581=android.view.AbsSavedState$1@80a47f5, 2131296815=android.view.AbsSavedState$1@80a47f5}}], key=x}]] D/LifeCircleActivity: onStop() called D/LifeCircleActivity: onDestroy() called D/LifeCircleActivity: onCreate() called with: savedInstanceState = [Bundle[{android:viewHierarchyState=Bundle[{android:views={16908290=android.view.AbsSavedState$1@80a47f5, 2131296581=android.view.AbsSavedState$1@80a47f5, 2131296815=android.view.AbsSavedState$1@80a47f5}}], key=x}]]Activity对象的地址:cn.steve.activitylifecycle.LifeCircleActivity@7e6e82e D/LifeCircleActivity: onStart() called D/LifeCircleActivity: onRestoreInstanceState() called with: savedInstanceState = [Bundle[{android:viewHierarchyState=Bundle[{android:views={16908290=android.view.AbsSavedState$1@80a47f5, 2131296581=android.view.AbsSavedState$1@80a47f5, 2131296815=android.view.AbsSavedState$1@80a47f5}}], key=x}]] D/LifeCircleActivity: onResume() called ","date":"2018-04-26","objectID":"/2018/04/activitylifecycle/:3:0","tags":["Activity"],"title":"Activity 在横竖屏切换情况下的生命周期变化","uri":"/2018/04/activitylifecycle/"},{"categories":["Mobile","Android"],"content":"小结 默认情况下，每次旋转屏幕都会销毁当前的Activity对象，同时调用 onSaveInstanceState 方法，保存当前的界面状态；之后重新创建 Activity对象， onCreate 参数不为空，回调 onRestoreInstanceState 方法进行恢复。 配置 configChanges=“orientation” ","date":"2018-04-26","objectID":"/2018/04/activitylifecycle/:4:0","tags":["Activity"],"title":"Activity 在横竖屏切换情况下的生命周期变化","uri":"/2018/04/activitylifecycle/"},{"categories":["Mobile","Android"],"content":"第一次启动 D/LifeCircleActivity: onCreate() called with: savedInstanceState = [null]Activity对象的地址:cn.steve.activitylifecycle.LifeCircleActivity@de950fc D/LifeCircleActivity: onStart() called D/LifeCircleActivity: onResume() called ","date":"2018-04-26","objectID":"/2018/04/activitylifecycle/:5:0","tags":["Activity"],"title":"Activity 在横竖屏切换情况下的生命周期变化","uri":"/2018/04/activitylifecycle/"},{"categories":["Mobile","Android"],"content":"第一次切换成横屏 D/LifeCircleActivity: onPause() called D/LifeCircleActivity: onSaveInstanceState() called with: outState = [Bundle[{android:viewHierarchyState=Bundle[{android:views={16908290=android.view.AbsSavedState$1@80a47f5, 2131296581=android.view.AbsSavedState$1@80a47f5, 2131296815=android.view.AbsSavedState$1@80a47f5}}], key=x}]] D/LifeCircleActivity: onStop() called D/LifeCircleActivity: onDestroy() called D/LifeCircleActivity: onCreate() called with: savedInstanceState = [Bundle[{android:viewHierarchyState=Bundle[{android:views={16908290=android.view.AbsSavedState$1@80a47f5, 2131296581=android.view.AbsSavedState$1@80a47f5, 2131296815=android.view.AbsSavedState$1@80a47f5}}], key=x}]]Activity对象的地址:cn.steve.activitylifecycle.LifeCircleActivity@266fbfb D/LifeCircleActivity: onStart() called D/LifeCircleActivity: onRestoreInstanceState() called with: savedInstanceState = [Bundle[{android:viewHierarchyState=Bundle[{android:views={16908290=android.view.AbsSavedState$1@80a47f5, 2131296581=android.view.AbsSavedState$1@80a47f5, 2131296815=android.view.AbsSavedState$1@80a47f5}}], key=x}]] D/LifeCircleActivity: onResume() called ","date":"2018-04-26","objectID":"/2018/04/activitylifecycle/:6:0","tags":["Activity"],"title":"Activity 在横竖屏切换情况下的生命周期变化","uri":"/2018/04/activitylifecycle/"},{"categories":["Mobile","Android"],"content":"再切换成竖屏 D/LifeCircleActivity: onPause() called D/LifeCircleActivity: onSaveInstanceState() called with: outState = [Bundle[{android:viewHierarchyState=Bundle[{android:views={16908290=android.view.AbsSavedState$1@80a47f5, 2131296581=android.view.AbsSavedState$1@80a47f5, 2131296815=android.view.AbsSavedState$1@80a47f5}}], key=x}]] D/LifeCircleActivity: onStop() called D/LifeCircleActivity: onDestroy() called D/LifeCircleActivity: onCreate() called with: savedInstanceState = [Bundle[{android:viewHierarchyState=Bundle[{android:views={16908290=android.view.AbsSavedState$1@80a47f5, 2131296581=android.view.AbsSavedState$1@80a47f5, 2131296815=android.view.AbsSavedState$1@80a47f5}}], key=x}]]Activity对象的地址:cn.steve.activitylifecycle.LifeCircleActivity@7e6e82e D/LifeCircleActivity: onStart() called D/LifeCircleActivity: onRestoreInstanceState() called with: savedInstanceState = [Bundle[{android:viewHierarchyState=Bundle[{android:views={16908290=android.view.AbsSavedState$1@80a47f5, 2131296581=android.view.AbsSavedState$1@80a47f5, 2131296815=android.view.AbsSavedState$1@80a47f5}}], key=x}]] D/LifeCircleActivity: onResume() called ","date":"2018-04-26","objectID":"/2018/04/activitylifecycle/:7:0","tags":["Activity"],"title":"Activity 在横竖屏切换情况下的生命周期变化","uri":"/2018/04/activitylifecycle/"},{"categories":["Mobile","Android"],"content":"小结 配置 orientation 的情况下，和默认情况一致。 配置 configChanges=“orientation|screenSize” 根据官方的介绍，这个两个值，在api大于13 之后，应该一起使用 ","date":"2018-04-26","objectID":"/2018/04/activitylifecycle/:8:0","tags":["Activity"],"title":"Activity 在横竖屏切换情况下的生命周期变化","uri":"/2018/04/activitylifecycle/"},{"categories":["Mobile","Android"],"content":"第一次启动 D/LifeCircleActivity: onCreate() called with: savedInstanceState = [null]Activity对象的地址:cn.steve.activitylifecycle.LifeCircleActivity@de950fc D/LifeCircleActivity: onStart() called D/LifeCircleActivity: onResume() called ","date":"2018-04-26","objectID":"/2018/04/activitylifecycle/:9:0","tags":["Activity"],"title":"Activity 在横竖屏切换情况下的生命周期变化","uri":"/2018/04/activitylifecycle/"},{"categories":["Mobile","Android"],"content":"第一次切换成横屏 D/LifeCircleActivity: onConfigurationChanged() called with: newConfig = [{1.0 ?mcc?mnc zh_CN ldltr sw360dp w640dp h336dp 320dpi nrml long land finger -keyb/v/h -nav/h s.11 themeChanged=0 themeChangedFlags=0}] ","date":"2018-04-26","objectID":"/2018/04/activitylifecycle/:10:0","tags":["Activity"],"title":"Activity 在横竖屏切换情况下的生命周期变化","uri":"/2018/04/activitylifecycle/"},{"categories":["Mobile","Android"],"content":"再切换成竖屏 D/LifeCircleActivity: onConfigurationChanged() called with: newConfig = [{1.0 ?mcc?mnc zh_CN ldltr sw360dp w360dp h616dp 320dpi nrml long port finger -keyb/v/h -nav/h s.12 themeChanged=0 themeChangedFlags=0}] ","date":"2018-04-26","objectID":"/2018/04/activitylifecycle/:11:0","tags":["Activity"],"title":"Activity 在横竖屏切换情况下的生命周期变化","uri":"/2018/04/activitylifecycle/"},{"categories":["Mobile","Android"],"content":"小结 当配置了 screenSize 。则不会再销毁重建了，而是回调 onConfigurationChanged 方法。 总结 在不做配置默认的情况下,Activity 是被销毁,然后重新启动的.但是在 manifest 中进行相应的配置之后,就表示 Activity 自行处理配置的更改,将阻止 Activity 的销毁重新启动,而是保持运行状态,并且回调 onConfigurationChanged 方法.官方的建议是万不得已的情况下才能使用. 参考 AndroidDeveloper 处理运行时变更 ","date":"2018-04-26","objectID":"/2018/04/activitylifecycle/:12:0","tags":["Activity"],"title":"Activity 在横竖屏切换情况下的生命周期变化","uri":"/2018/04/activitylifecycle/"},{"categories":["Mobile","Android"],"content":"概述 Service 有两种启动方式,一种是 startService ;一种是 bindService.这两种的启动的 Service 的生命周期有些许差异,并且当二者混用的时候,有一些需要注意的地方.这里用打印 log 日志的方式记录下生命周期的差异. 仅 startService ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:0:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"触发 startService 方法 D/ServiceLifeService: onCreate() called D/ServiceLifeService: onStartCommand() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }], flags = [0], startId = [1] ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:1:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"退出APP 无回调 ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:2:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"再次进入APP，触发startService 方法 D/ServiceLifeService: onStartCommand() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }], flags = [0], startId = [2] ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:3:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"杀死 App 进程 没有回调，直接被系统杀死。只有一些AMS系统回调 W/ActivityManager: Scheduling restart of crashed service cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService in 1000ms I/ActivityManager: Force stopping service ServiceRecord{38ffaacf u0 cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService} ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:4:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"调用 stop 方法 D/ServiceLifeService: onDestroy() called ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:5:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"小结 对于 startService 而言 当要启动的 Service 没有创建时，就会创建，而后回调 onCreate 和 onStartCommand 方法； 当要启动的 Service 已经存在，则只会回调 onStartCommand 方法； 退出 App，Service 依旧存活 调用 stop 方法，回调 onDestroy 仅 bindService ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:6:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"触发 bindService 方法 D/ServiceLifeService: onCreate() called D/ServiceLifeService: onBind() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }] D/ServiceLifeService: onServiceConnected() called with: name = [ComponentInfo{cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService}], service = [ServiceBinder:cn.steve.servicelifecycle.ServiceLifeService$ServiceBinder@4bb38ec] ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:7:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"多次触发 bindService 方法 对于同一个 ServiceConnection 只会进行一次 ServiceConnection 中的方法回调。 若不同的 ServiceConnection ，则会进行 ServiceConnection 中的 方法回调 ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:8:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"退出APP D/ServiceLifeService: onUnbind() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }] D/ServiceLifeService: onDestroy() called ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:9:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"退出前，主动调用 unbind 方法 D/ServiceLifeService: onUnbind() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }] D/ServiceLifeService: onDestroy() called ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:10:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"小结 对于 bindService 而言 当要启动的 Service 没有创建时，就会创建，而后回调 onCreate 和 onBind 方法； 当要启动的 Service 已经存在，则只会回调 onBind 方法； 退出 App，Service 将自动解绑，并回调 onDestroy 方法 退出 App 和主动 unbind 的回调一致 先 startService ，再 bindService ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:11:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"触发 startService 方法，再触发 bindService 方法 D/ServiceLifeService: onCreate() called D/ServiceLifeService: onStartCommand() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }], flags = [0], startId = [1] D/ServiceLifeService: onBind() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }] D/ServiceLifeService: onServiceConnected() called with: name = [ComponentInfo{cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService}], service =[ServiceBinder:cn.steve.servicelifecycle.ServiceLifeService$ServiceBinder@598f7d8] ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:12:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"退出APP D/ServiceLifeService: onUnbind() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }] ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:13:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"调用 unbind 方法 D/ServiceLifeService: onUnbind() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }] ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:14:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"在 unbind 之前，调用 stop 方法 无回调 ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:15:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"调用 stop 方法，再调 unbind D/ServiceLifeService: onUnbind() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }] D/ServiceLifeService: onDestroy() called ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:16:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"调用 unbind，再调用 stop 方法 D/ServiceLifeService: onUnbind() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }] D/ServiceLifeService: onDestroy() called ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:17:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"小结 和前面的方式类似，有以下几点需要注意 bindService 只会导致 Service 回调 onBind 方法，因为 Service本身已经存在，所以，不会再回调 onCreate 方法，也说明 Service 是同一个 Service 退出 App 后只会让 Service 回调 onUnbind 方法，受 startService 方法的影响， Service 依旧存活，故而不会回调 onDestroy。 先 bindService ，再 startService ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:18:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"触发 bindService 方法，再触发 startService 方法 D/ServiceLifeService: onCreate() called D/ServiceLifeService: onBind() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }] D/ServiceLifeService: onServiceConnected() called with: name = [ComponentInfo{cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService}], service = [ServiceBinder:cn.steve.servicelifecycle.ServiceLifeService$ServiceBinder@4bb38ec] D/ServiceLifeService: onStartCommand() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }], flags = [0], startId = [1] ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:19:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"退出APP D/ServiceLifeService: onUnbind() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }] ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:20:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"调用 unbind 方法 D/ServiceLifeService: onUnbind() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }] ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:21:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"在 unbind 之前，调用 stop 方法 无回调 ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:22:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"调用 stop 方法，再调 unbind D/ServiceLifeService: onUnbind() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }] D/ServiceLifeService: onDestroy() called ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:23:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"调用 unbind，再调用 stop 方法 D/ServiceLifeService: onUnbind() called with: intent = [Intent { cmp=cn.steve.study/cn.steve.servicelifecycle.ServiceLifeService }] D/ServiceLifeService: onDestroy() called ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:24:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Mobile","Android"],"content":"小结 和前面的方式类似，有以下几点需要注意 bindService 调用产生的回调和单独 调用 bindService 一样； startService 调用时，因为 Service 对象已经存在，所以只回调 onStartCommand 方法 退出 App 后只会让 Service 回调 onUnbind 方法，受 startService 方法的影响， Service 依旧存活，故而不会回调 onDestroy。 总结 已经创建成功的 Service，在运行期间，无论是 start 还是 bind，都不会调用 onCreate； Service 在运行期间，每次调用 start 都会触发 onStartCommand 方法；而多次用同一个 ServiceConnection 进行bind 调用时，只会触发一次 onBind ；对于用不同的 ServiceConnection 进行 bind 时，都会触发 ServiceConnection 中的 onServiceConnected 方法，但并不会触发 onBind 方法，所以，相遇于多次触发 onStartCommand 触发，对于 bind 操作来说，onBind 只会触发一次。 当 start 和 bind 混合调用时，要想停止，必须要调用 unbind 才会回调 onDestory 方法。若先调用 stop，此时没有任何回调，再调用unbind时，会回调onUnbind，同时进行 onDestroy 回调。反之，若先调用 unbind，再调用 stop，回调顺序一致。 ","date":"2018-04-26","objectID":"/2018/04/servicelifecycle/:25:0","tags":["Service"],"title":"Service 的生命周期","uri":"/2018/04/servicelifecycle/"},{"categories":["Programming","Java"],"content":"概述 本文记录使用 javapoet 以及 auto-service 进行编译时注解的过程以及注意点. 最近又使用了一次编译时注解,期间产生了不少问题. 术语的解释 ","date":"2018-01-02","objectID":"/2018/01/annotation2/:0:0","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2018/01/annotation2/"},{"categories":["Programming","Java"],"content":"Element 这个代表被注解的元素.这个类有个很重要的方法,getEnclosingElement:这方法的含义是获取 包裹 element 最外围的元素.比如类的最外围的元素是 package. PackageElement pkgElement = (PackageElement) element.getEnclosingElement(); 其他方法都很简单. ","date":"2018-01-02","objectID":"/2018/01/annotation2/:1:0","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2018/01/annotation2/"},{"categories":["Programming","Java"],"content":"javapoet 库中一些重要的接口和方法 TypeName: 对应了 java 代码中的一个类型元素,常用于声明一个方法参数,还有一些 collection 范型使用. // 用来定一个 ComponentInfo 类的元素类型 TypeName mComponentInfoClassName = ClassName.get(ComponentInfo.class); ParameterizedTypeName 用来声明一个方法的参数.有个 get 方法,这个方法第一个参数是声明原生的类型,后面一个可变参数,声明第一个参数的参数. // 声明一个参数的类型是 Map\u003cString,List\u003cComponentInfo\u003e\u003e ParameterizedTypeName paramListComponent = ParameterizedTypeName.get(ClassName.get(List.class), mComponentInfoClassName); ParameterizedTypeName moduleLoaderParameter = ParameterizedTypeName.get( ClassName.get(Map.class), ClassName.get(String.class), paramListComponent ); ParameterSpec 这个类代表方法的参数 // 声明一个方法的参数是:final Map\u003cString,List\u003cComponentInfo\u003e\u003e targetMap. ParameterSpec injectParameterSpec = ParameterSpec.builder(moduleLoaderParameter, \"targetMap\", Modifier.FINAL).build(); MethodSpec.Builder 方法的构造器,用来构造一个方法. // 用来构造一个私有方法,名字叫 inject ,参数是 Map\u003cString,List\u003cComponentInfo\u003e\u003e targetMap,String group,String pkg,String name,int type MethodSpec.Builder injectElementBuilder = MethodSpec.methodBuilder(\"inject\") .addModifiers(Modifier.PRIVATE) .addParameter(injectParameterSpec) .addParameter(String.class, \"group\") .addParameter(String.class, \"pkg\") .addParameter(String.class, \"name\") .addParameter(int.class, \"type\"); 这个构造还可以继续添加语句 injectElementBuilder.addStatement(\"List\u003c$T\u003e list = targetMap.get(name)\", ComponentInfo.class) .beginControlFlow(\"if( list == null )\") .addStatement(\"list = new $T\u003c\u003e()\", ArrayList.class) .addStatement(\"targetMap.put(group, list)\") .endControlFlow() .addStatement(\"ComponentInfo info = new ComponentInfo(type, group, pkg, name)\") .beginControlFlow(\"try\") .addStatement(\" info.setClazz(Class.forName(pkg + name))\") .nextControlFlow(\"catch(Exception e)\") .addStatement(\"e.printStackTrace()\") .endControlFlow() .addStatement(\"list.add(info)\"); 注意其中的两个 ControlFlow . TypeSpec 用来声明一个类的描述 // 声明一个类,类名是 className,里面有两个方法 TypeSpec typeSpec = TypeSpec.classBuilder(\"className\") .addModifiers(Modifier.PUBLIC) .addMethod(injectElementMethod) .addMethod(injectMethodSpec) .build(); JavaFile 代表一个输出的 java 文件. // 声明一个包名为 : com.steve.pkg 的java 文件.文件描述用的是一个 TypeSpec JavaFile javaFile = JavaFile.builder(\"com.steve.pkg\", typeSpec).build(); 使用的注意事项 新版的 studio 以及不需要 android-apt 对于注解器的依赖可以通过 annotationProcessor project(’:processor’) 来对注解器工程进行依赖 对于注解配置选项可以在 gradle 中进行配置 defaultConfig { minSdkVersion rootProject.ext.android.minSdkVersion targetSdkVersion rootProject.ext.android.targetSdkVersion versionCode rootProject.ext.android.versionCode versionName rootProject.ext.android.versionName javaCompileOptions { annotationProcessorOptions { arguments = [moduleName: project.getName()] } } } 对于注解器的注册,@AutoService(Processor.class),不要写错了,写成 process 注解器的配置项需要在注解器中声明 @SupportedOptions(“moduleName”) 注解器中的 log 不要随便打 error,不然就会停止解析,这点和 android 中的 log 有些差异. ","date":"2018-01-02","objectID":"/2018/01/annotation2/:2:0","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2018/01/annotation2/"},{"categories":["Mobile","Android"],"content":"背景 由于 H5 页面打开都比较慢,为了减少返回时候的刷新,所以有时候需要多开,就是每个 url 都是在一个新的 activity 中打开.一般的处理方式是在 shouldOverrideUrlLoading() 方法中进行处理,这个方法按照 SDK 中的说明是当 url 发生变化时就会回调,当遇到服务端重定向的时候,就会出现一个空白页面的情况,所以我们需要判断是否是重定向,对于重定向进行特殊的处理. 困难 public boolean shouldOverrideUrlLoading(WebView view, WebResourceRequest request) { return shouldOverrideUrlLoading(view, request.getUrl().toString()); } 在 Android7.0 ,新增了 WebResourceRequest 接口,接口中有个判断是否是重定向的方法,但对于低版本的该如何判断呢? 可以做如下判断. WebViewClient webViewClient = new WebViewClient() { private boolean mLoaded = false; @Override public boolean shouldOverrideUrlLoading(WebView view, String url) { if (mLoaded){ //not redirect }else { // is redirect } return true; } @Override public void onPageFinished(WebView webView, String url) { mLoaded = true; } }; 因为能回调 onPageFinished 方法,都是有渲染页面的操作,说明页面是有内容的,对于服务端重定向而言,是没有内容的,所以就不会走 onPageFinished 方法,通过这个间接的判断页面是否是重定向的.目前还未发现有什么不对的地方. 参考 stackoverflow ","date":"2017-08-10","objectID":"/2017/08/webview-judge-302/:0:0","tags":["Webview","redirect"],"title":"webview中关于服务端重定向的判断","uri":"/2017/08/webview-judge-302/"},{"categories":["Mobile","Android"],"content":"概述 本文作为第一篇的补充,补充一下第一篇遗漏的内容,主要谈一下,缺少的概念,技术背景等内容. Why为什么需要Binder Binder 是 Android 系统进程间通信（IPC）方式之一。Android 是基于 Linux 内核的,Linux 已经有很多 IPC 方式,为何还需要一个新的 IPC 方式. Linux已经拥有 管道 system V IPC Socket 等IPC手段。 却还要倚赖Binder来实现进程间通信。 Binder具有无可比拟的优势。 或者可以说，Android系统对进程间有什么特殊的需求是传统其他 IPC 无法完成或者无法很好完成。 基于Client-Server的通信方式广泛应用于从互联网和数据库访问到嵌入式手持设备内部通信等各个领域。 智能手机平台特别是Android系统中，为了向应用开发者提供丰富多样的功能，这种通信方式更是无处不在，诸如媒体播放，视音频频捕获，到各种让手机更智能的传感器（加速度，方位，温度，光亮度等）都由不同的Server负责管理，应用程序只需做为Client与这些Server建立连接便可以使用这些服务，花很少的时间和精力就能开发出令人眩目的功能。 Client-Server 方式的广泛采用对进程间通信（IPC）机制是一个挑战。 只有socket支持Client-Server的通信方式。当然也可以在这些底层机制上架设一套协议来实现Client-Server通信，但这样增加了系统的复杂性，在手机这种条件复杂，资源稀缺的环境下可靠性也难以保证. ","date":"2017-07-04","objectID":"/2017/07/ipc-binder-java-2/:0:0","tags":["IPC","Binder"],"title":"IPC_Binder_java_2","uri":"/2017/07/ipc-binder-java-2/"},{"categories":["Mobile","Android"],"content":"传输性能角度： socket作为一款通用接口，其传输效率低，开销大，主要用在跨网络的进程间通信和本机上进程间的低速通信。 消息队列和管道采用存储-转发方式，即数据先从发送方缓存区拷贝到内核开辟的缓存区中，然后再从内核缓存区拷贝到接收方缓存区，至少有两次拷贝过程。 共享内存虽然无需拷贝，但控制复杂，难以使用。 ","date":"2017-07-04","objectID":"/2017/07/ipc-binder-java-2/:1:0","tags":["IPC","Binder"],"title":"IPC_Binder_java_2","uri":"/2017/07/ipc-binder-java-2/"},{"categories":["Mobile","Android"],"content":"安全性角度： Android作为一个开放式，拥有众多开发者的的平台，应用程序的来源广泛，确保智能终端的安全是非常重要的。终端用户不希望从网上下载的程序在不知情的情况下偷窥隐私数据，连接无线网络，长期操作底层设备导致电池很快耗尽等等。 传统IPC没有任何安全措施，完全依赖上层协议来确保。 传统IPC的接收方无法获得对方进程可靠的UID/PID（用户ID/进程ID），从而无法鉴别对方身份。Android为每个安装好的应用程序分配了自己的UID，故进程的UID是鉴别进程身份的重要标志。使用传统IPC只能由用户在数据包里填入UID/PID，但这样不可靠，容易被恶意程序利用。可靠的身份标记只有由IPC机制本身在内核中添加才能确保安全性。 传统IPC访问接入点是开放的，无法建立私有通道。比如命名管道的名称，system V的键值，socket的ip地址或文件名都是开放的，只要知道这些接入点的程序都可以和对端建立连接，不管怎样都无法阻止恶意程序通过猜测接收方地址获得连接。 ","date":"2017-07-04","objectID":"/2017/07/ipc-binder-java-2/:2:0","tags":["IPC","Binder"],"title":"IPC_Binder_java_2","uri":"/2017/07/ipc-binder-java-2/"},{"categories":["Mobile","Android"],"content":"效率角度 从对比图可以看出,Binder 在效率上是有优势的. What Binder 是什么 因为 Binder 也是 CS 架构的一种,而 CS 架构最典型的就是 TCP/IP 请求了.下面做个对比,顺带类比以下 Binder 中的几个关键的概念. 背景 在开发中，经常需要通过 getSystemService 的方式获取一个系统服务,那么这些系统服务的 Binder 引用是如何传递给客户端的呢？要知道，系统服务并不是通过 startService() 启动的。 ServiceManager 管理的服务 ServiceManager 是一个独立进程，其作用如名称所示，管理各种系统服务. ServiceManager 本身也是一个 Service ，Framework 提供了一个系统函数，可以获取该 Service 对应的 Binder 引用，那就是 BinderInternal.getContextObject().该静态函数返回 ServiceManager 后，就可以通过 ServiceManager 提供的方法获取其他系统 Service 的 Binder 引用。这种涉及模式在日常中是可见的， ServiceManager 就像一个公司的总机，这个号码是公开的，系统中任何进程都可以使用 BinderInternal.getContextObject() 获取该总机的 Binder 对象，而当用户想联系公司中的其他任何人(服务),则要警告总机再获得分机号。这种设计的好处是系统中仅暴露了一个全局 Binder 引用 (ServiceManager),而其他系统服务则可以隐藏起来，从而有助于系统服务的扩展，以及调用系统服务的安全检查。其他系统服务在启动时，首先把自己的 Binder 对象传递给 ServiceManager,即所谓的注册(addService). 举个具体的例子: ContextImpl.java @Override public Object getSystemService(String name) { if (WINDOW_SERVICE.equals(name)) { return WindowManagerImpl.getDefault(); } else if (LAYOUT_INFLATER_SERVICE.equals(name)) { synchronized (mSync) { LayoutInflater inflater = mLayoutInflater; if (inflater != null) { return inflater; } mLayoutInflater = inflater = PolicyManager.makeNewLayoutInflater(getOuterContext()); return inflater; } } else if (ACTIVITY_SERVICE.equals(name)) { return getActivityManager(); } else if (INPUT_METHOD_SERVICE.equals(name)) { return InputMethodManager.getInstance(this); } else if (ALARM_SERVICE.equals(name)) { return getAlarmManager(); } else if (ACCOUNT_SERVICE.equals(name)) { return getAccountManager(); } else if (POWER_SERVICE.equals(name)) { return getPowerManager(); } else if (CONNECTIVITY_SERVICE.equals(name)) { return getConnectivityManager(); } else if (THROTTLE_SERVICE.equals(name)) { return getThrottleManager(); } else if (WIFI_SERVICE.equals(name)) { return getWifiManager(); } else if (NOTIFICATION_SERVICE.equals(name)) { return getNotificationManager(); } else if (KEYGUARD_SERVICE.equals(name)) { return new KeyguardManager(); } else if (ACCESSIBILITY_SERVICE.equals(name)) { return AccessibilityManager.getInstance(this); } else if (LOCATION_SERVICE.equals(name)) { return getLocationManager(); } else if (SEARCH_SERVICE.equals(name)) { return getSearchManager(); } else if (SENSOR_SERVICE.equals(name)) { return getSensorManager(); } else if (STORAGE_SERVICE.equals(name)) { return getStorageManager(); } else if (VIBRATOR_SERVICE.equals(name)) { return getVibrator(); } else if (STATUS_BAR_SERVICE.equals(name)) { synchronized (mSync) { if (mStatusBarManager == null) { mStatusBarManager = new StatusBarManager(getOuterContext()); } return mStatusBarManager; } } else if (AUDIO_SERVICE.equals(name)) { return getAudioManager(); } else if (TELEPHONY_SERVICE.equals(name)) { return getTelephonyManager(); } else if (CLIPBOARD_SERVICE.equals(name)) { return getClipboardManager(); } else if (WALLPAPER_SERVICE.equals(name)) { return getWallpaperManager(); } else if (DROPBOX_SERVICE.equals(name)) { return getDropBoxManager(); } else if (DEVICE_POLICY_SERVICE.equals(name)) { return getDevicePolicyManager(); } else if (UI_MODE_SERVICE.equals(name)) { return getUiModeManager(); } return null; } InputMethodManager.java /** * Retrieve the global InputMethodManager instance, creating it if it * doesn't already exist. * @hide */ static public InputMethodManager getInstance(Context context) { return getInstance(context.getMainLooper()); } /** * Internally, the input method manager can't be context-dependent, so * we have this here for the places that need it. * @hide */ static public InputMethodManager getInstance(Looper mainLooper) { synchronized (mInstanceSync) { if (mInstance != null) { return mInstance; } IBinder b = ServiceManager.getService(Context.INPUT_METHOD_SERVICE); IInputMethodManager service = IInputMethodManager.Stub.asInterface(b); mInstance = new InputMethodManager(service, mainLooper); } return mInstance; } ServiceManager.java /** * Returns a reference to a service with the given name. * * @param name the name of the service to get * @","date":"2017-07-04","objectID":"/2017/07/ipc-binder-java-2/:3:0","tags":["IPC","Binder"],"title":"IPC_Binder_java_2","uri":"/2017/07/ipc-binder-java-2/"},{"categories":["Mobile","Android"],"content":"理解 Manager ServiceManager 所管理的所有 Service 都是以相应的 Manager 返回给客户端，所以简述下 Framework 层对于 Manager 的定义。在Android 中，Manager 的含义类似于现实生活中的经纪人，Manager 所 manage 的对象是服务本身，因为每个具体的服务一般都会提供多个 API 接口，而 manager 所 manage 的正式这些 API。客户端一般不能直接通过 Binder 引用去访问具体的服务，而是要警告一个 Manager，相应的 Manager 类对客户端是可见的，而远程的服务端对客户端来说则是隐藏的。 而这些 Manager 的类内部都会有一个远程服务 Binder 的变量，而且在一般情况下，这些 Manager 的构造函数参数中都会包含这个 Binder 对象。简单讲，即先通过 ServiceManager 获取远程服务的 Binder 引用，然后使用这个 Binder 引用构造一个客户端本地可以访问的经纪人，然后客户端就可以通过该经纪人访问远程的服务了。 这种设计的作用是屏蔽了直接访问远程服务，从而给应用程序提供灵活的，可控的 API 接口，比如 AMS ，吸引不希望用户直接访问 AMS，而是经过 ActivityManager 类去访问，而 ActivityManager 内部提供了一些更具可操作性的数据结构化，不如 RecentTaskInfo 数据类封装了最近访问过的 Task 列表；MemoryInfo 数据类封装了和内存相关的信息。 感激,非常感激，万分的感激！ 柯元旦 ","date":"2017-07-04","objectID":"/2017/07/ipc-binder-java-2/:4:0","tags":["IPC","Binder"],"title":"IPC_Binder_java_2","uri":"/2017/07/ipc-binder-java-2/"},{"categories":["Mobile","Android"],"content":"why 在做 hybrid 框架的时候,发现以 file 协议打开的文件,存在 cookie 跨域的问题.以做记录. what 以 file 协议打开的文件,页面内存在新的跳转,跳转数据通过 cookie 传递,发现cookie 不能正常传递. how CookieManager 存在一个静态方法,可以打开 file 协议的 cookie. boolean allowFileSchemeCookies () 这是个静态方法,打开之后,整个 APP 的 webview 就都打开了. 参考文献 [官方文档](https://developer.android.com/reference/android/webkit/CookieManager.html#allowFileSchemeCookies() ","date":"2017-03-19","objectID":"/2017/03/webviewlocalcookie/:0:0","tags":["Webview","cookie"],"title":"记录WebView的file协议的cookie跨域问题","uri":"/2017/03/webviewlocalcookie/"},{"categories":["Mobile","Android"],"content":"why 在项目中，比如推送了一个具体的产品，肯定是打算显示具体的产品详情页，这时候点击返回，也自然打算让用户返回首页,还是让用户留在 APP 内。 最近项目在接入华为推送的时候，遇到一个问题,我们的默认启动 Activity 是一个广告页,在从详情页返回到主页的时候,在主页再返回,出现了广告页. 类似于如图. How 看到这个现象猜测,是不是当栈中有 Activity 实例的时候,进程是会自动重启.为此做了一个实验，A-\u003eB，在 B 中关闭虚拟机，这时候，虚拟机自动重启。打开了 A 页面。 A-\u003eB-\u003eC，在 C 中关闭虚拟机。 这时候,栈中的信息如下. 此时在 C 中执行关闭虚拟机的操作,然后进程重启.下图是虚拟机重启之后的栈信息。发现,除了之前栈顶的 C 销往了,栈下的 B,C 都还在.并且 B 的状态信息还是重启之前的,除了 pid 不一样了. 这时候按下返回,栈信息如下. Conclusion 为何会出现欢迎页 目前发现,华为推送在点击通知的时候,会自动启动 APP 的默认 Activity. 关于为何进程会重启 目前发现的现象是,当栈底还有 Activity 的时候,就会重启. Google 了一些博客,还是未发现有合理的解释. 为何重启后 task 中原有栈顶的 Activity 的信息和重启之前一模一样? 原因是什么?目前不知道怎么下手分析,仅仅是猜测,应该是和 ActivityRecord 有关,系统在重启的时候直接复用了. ","date":"2017-02-25","objectID":"/2017/02/activitytaskproblem/:0:0","tags":["Activity","Task"],"title":"记录一个进程重启的问题","uri":"/2017/02/activitytaskproblem/"},{"categories":["Mobile","Android"],"content":"why BottomNavigationView 这个概念很早之前就被提出,之后出一个第三方库.但是一直未有官方的支持,今天正好看到有官方支持,记录一下. what BottomNavigationView 是 material design 中的设计的实现，这种设计很早就出现了。 how 添加依赖 compile 'com.android.support:design:25.1.1' 在menu下新建 menu配置文件，顺序就是 bottom bar 显示的顺序 \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cmenu xmlns:android=\"http://schemas.android.com/apk/res/android\"\u003e \u003citem android:id=\"@+id/recents\" android:title=\"Recents\" android:icon=\"@drawable/ic_recents\"/\u003e \u003citem android:id=\"@+id/favorites\" android:title=\"Favorites\" android:icon=\"@drawable/ic_favorites\"/\u003e \u003citem android:id=\"@+id/nearby\" android:title=\"Nearby\" android:icon=\"@drawable/ic_nearby\"/\u003e \u003c/menu\u003e 在 drawable 和 drawable-v21下新建item的背景文件。 \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003c!-- in drawable for lower then 21 API--\u003e \u003cselector xmlns:android=\"http://schemas.android.com/apk/res/android\"\u003e \u003citem android:state_pressed=\"true\" android:drawable=\"@android:color/white\"/\u003e \u003citem android:drawable=\"@android:color/transparent\"/\u003e \u003c/selector\u003e \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003c!--in drawable-v21 folder, for greater or equal then 21 API--\u003e \u003cripple xmlns:android=\"http://schemas.android.com/apk/res/android\" android:color=\"@android:color/white\"\u003e \u003c/ripple\u003e 在 layout 下新建布局文件，用来添加 BottomNavigationView \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cRelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:app=\"http://schemas.android.com/apk/res-auto\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\"\u003e \u003candroid.support.design.widget.BottomNavigationView android:id=\"@+id/bottomNavigationView\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:layout_alignParentBottom=\"true\" android:background=\"@android:color/holo_blue_bright\" app:itemBackground=\"@drawable/navigationbar_item_bg\" app:itemIconTint=\"@android:color/white\" app:itemTextColor=\"@android:color/white\" app:menu=\"@menu/menu_bottom_navigation_view\"/\u003e \u003c/RelativeLayout\u003e 在 Activity 或者 fragment 中添加监听即可。 bottomNavigationView = (BottomNavigationView) findViewById(R.id.bottomNavigationView); this.bottomNavigationView.setOnNavigationItemSelectedListener(new BottomNavigationView.OnNavigationItemSelectedListener() { @Override public boolean onNavigationItemSelected(@NonNull MenuItem item) { Toast.makeText(BottomNavigationViewActivity.this, item.getTitle(), Toast.LENGTH_SHORT).show(); return true; } }); #　Ｃonclusion 官方的这个支持，可扩展性不强，也没什么特别的新意，可参考学习第三方库BottomBar . ","date":"2017-02-18","objectID":"/2017/02/bottomnavigationview/:0:0","tags":["BottomNavigationView"],"title":"BottomNavigationView 的使用","uri":"/2017/02/bottomnavigationview/"},{"categories":["Tool","Gradle"],"content":"Why AndroidStudio 编译速度慢,已经是人神共愤的事情了.本文是一篇译文，讲述如果利用 build cache 技术加快编译速度。分成两部分,一部分是第三方博文,另外一部分是官方文档.援引文章在结尾给出. Using build cache in Android Studio makes Gradle build faster ","date":"2017-02-07","objectID":"/2017/02/buildcache/:0:0","tags":["AndroidStudio"],"title":"加快 AndroidStudio 编译速度之 build cache","uri":"/2017/02/buildcache/"},{"categories":["Tool","Gradle"],"content":"为何关心 build cache? 因为 build cache 可以加快 clean 和 build 的速度。当你执行 ‘gradle clean build’ 或者类似的命令的时候。 ","date":"2017-02-07","objectID":"/2017/02/buildcache/:1:0","tags":["AndroidStudio"],"title":"加快 AndroidStudio 编译速度之 build cache","uri":"/2017/02/buildcache/"},{"categories":["Tool","Gradle"],"content":"How does it make the build faster? 通过缓存已经分包的 libraries，这个过程是不在 Gradle 的缓存管理范围内的。无论是通过 Android studio 或者 命令行的方式执行 clean 操作，build-cache 内的包都会被保留，等到下次 build apk 的时候，被复用。可以在 build-cache 目录下查看缓存的结构。 这是文件夹下列出的是一系列命名比较奇怪的文件和文件夹。文件大小是 0 字节的文件是用来锁定文件使用的。这个是非常必要的，因为同一个缓存文件可以被不同的项目使用。锁文件，可以防止两个项目同时对一个缓存文件进行读写操作。 ","date":"2017-02-07","objectID":"/2017/02/buildcache/:2:0","tags":["AndroidStudio"],"title":"加快 AndroidStudio 编译速度之 build cache","uri":"/2017/02/buildcache/"},{"categories":["Tool","Gradle"],"content":"Exploded aar caches aar 缓存以文件夹的形式展现。有两种类型的缓存，一种是 dex 缓存，一种是解压完的 aar 形式的缓存。解压完的 aar 将直接保存在对应的 output 文件夹下。比如 220674f5fc7186b424e032744f0eeb413d469b54 文件夹的 input 文件 包含以下内容： COMMAND=PREPARE_LIBRARY MAVEN_COORDINATES=com.google.maps.android:android-maps-utils:aar:0.3.4 文件夹的名字是 input file 的 sha1sum 值。在这个例子里，就是 android-maps-utils 库。解压完的 aar 在依赖的分析过程中（若未被缓存）会被缓存。 ","date":"2017-02-07","objectID":"/2017/02/buildcache/:3:0","tags":["AndroidStudio"],"title":"加快 AndroidStudio 编译速度之 build cache","uri":"/2017/02/buildcache/"},{"categories":["Tool","Gradle"],"content":"Dexed caches 对于分包缓存，有着和 aar 缓存相似的结构。 COMMAND=PREDEX_LIBRARY FILE_PATH=/Users/Sten/.android/build-cache/220674f5fc7186b424e032744f0eeb413d469b54/output/jars/classes.jar FILE_HASH=cf251baf39f5c5138224b67b4106eb6331abbd13 BUILD_TOOLS_REVISION=25.0.0 JUMBO_MODE=false OPTIMIZE=true MULTI_DEX=false 文件中的 FILE_PATH 指向的就是我们上面所说的文件夹。文件中包含了 android-maps-utils 库的分包版本。input file 中的键值对定义了每个缓存实体。举个例子，build tools revision 是 25.0.0 和 25.0.1 将会有不同的分包缓存，因为 BUILD_TOOLS_REVISION 值不同。但是对于 aar 缓存而言，则会是同一个，因为对于 aar 缓存的 input file 而言，command 未变，maven 地址也没有变，输入文件未变。 这里的输出是一个文件，而不是一个文件夹。解压之后的文件结构如下： 73 12-06-16 16:07 META-INF/MANIFEST.MF 0 12-06-16 16:07 META-INF/ 87000 12-06-16 16:07 classes.dex 0 12-06-16 16:07 com/ 0 12-06-16 16:07 com/google/ 0 12-06-16 16:07 com/google/maps/ 0 12-06-16 16:07 com/google/maps/android/ 0 12-06-16 16:07 com/google/maps/android/clustering/ 0 12-06-16 16:07 com/google/maps/android/clustering/algo/ 0 12-06-16 16:07 com/google/maps/android/clustering/view/ 0 12-06-16 16:07 com/google/maps/android/geometry/ 0 12-06-16 16:07 com/google/maps/android/heatmaps/ 0 12-06-16 16:07 com/google/maps/android/projection/ 0 12-06-16 16:07 com/google/maps/android/quadtree/ 0 12-06-16 16:07 com/google/maps/android/ui/ 如你所见，这个只是文件夹结构和 classes.dex 文件。 ","date":"2017-02-07","objectID":"/2017/02/buildcache/:4:0","tags":["AndroidStudio"],"title":"加快 AndroidStudio 编译速度之 build cache","uri":"/2017/02/buildcache/"},{"categories":["Tool","Gradle"],"content":"Multidex and API level 21 根据 multidex 和 target API 是否高于 21 的不同组合，分包缓存的使用方式也不一样。 第一种情况是，不使用分包。在这种情况下，API 级别无论是否高于 21 都无关。将会使用分包缓存，也会进行 dex 文件的 merge 操作。在 apk 文件中，我们将会看到只有一个 classes.dex 文件，这个 classes.dex 包含了所有的 application 类和 libraries。 第二种情况是，minSdkVersion 低于 21 并且 multidex 无法使用 build cache 下的 predex libraries .这是因为兼容包里的 multidex 并不支持 predex.Gradle 插件总是将所有的 application 和 library classes 都放到一个 dex 包里. 最后一种情况是使用了 multidex 并且 API 级别高于 21.在这种情况下,build-cache文件夹下的分包文件将会被直接打包进 apk 文件中.每个库都将分别拥有一个将被打包进 apk 中的 classes.dex 文件.这也是为什么 API 21 是编译时期最佳的选择 . ","date":"2017-02-07","objectID":"/2017/02/buildcache/:5:0","tags":["AndroidStudio"],"title":"加快 AndroidStudio 编译速度之 build cache","uri":"/2017/02/buildcache/"},{"categories":["Tool","Gradle"],"content":"Performance measurements 针对2015年的 iosched app 在没有 multidex 和 API 最低版本 21 下分别进行测试.打开 Gradle 守护进程,启用和禁用 build cache,分别在命令行下运行 5 次 clean,build 操作.以下是五次运行结果的中位数报告. 从上图可以看到,编译时间很明显的从 18.7 降到了 6.5秒.从图上也可以很清晰的看到 android:transformClassesWithDexForDebug task 所花的时间,从 12.1 降到了 1.7 秒.节省的时间取决于项目中使用的依赖包数. 如果还没尝试 Android studio 2.3 ,建议现在尝试.你将会很明显的看到节省的时间.如果你对非正式版的没有兴趣,也可以在 Android studio 2.2 和 Android Gradle plugin 2.2 上实验,通过向项目根目录下的 gradle.properties 文件中添加 android.enableBuildCache=true . 下面是官方的译文. Build Cache ","date":"2017-02-07","objectID":"/2017/02/buildcache/:6:0","tags":["AndroidStudio"],"title":"加快 AndroidStudio 编译速度之 build cache","uri":"/2017/02/buildcache/"},{"categories":["Tool","Gradle"],"content":"Introduction 在 Android Studio 2.2 Beta3 中介绍了一种可以减少编译时间的新 build cache 缓存特性，这个新特性可以加快包括全量编译，增量编译和 instant run 的编译时间，通过保存和复用前一次由同一个项目或者其他项目 build 产生的文件或者文件夹。 build cache 目的是为了在所有的 Android 项目中共用。开发者可以通过修改 gradle.properties 文件，实现是否启用 build cache 和指定缓存的位置。当前 build cache 只包含 pre-dexed 库，未来，Android studio 团队会支持其他类型的文件。 注意：build cache 的实现是和 gradle cache 管理（例如,reporting up-to-date statuses）是相互独立的。当执行一个 task 的时候，无论是否使用 build cache 对于 Gradle 而言都是未知的（即：即使命中了缓存，Gradle 也不会认为是 up-to-date）。然而，当使用 build cache 的时候，还是希望加快编译速度的。 即使目前还未发现有任何问题，我们希望给社区更多的时间以提供更多的反馈。目前这个特性仍旧作为实验性的特性，目前默认还是禁用的。（Android Studio 2.3 Canary 1 开始默认启用）。根据未来的反馈情况，当我们觉得这个特性稳定了，将会在 Android Studio 2.3 或者 2.4 中默认启动。 ","date":"2017-02-07","objectID":"/2017/02/buildcache/:7:0","tags":["AndroidStudio"],"title":"加快 AndroidStudio 编译速度之 build cache","uri":"/2017/02/buildcache/"},{"categories":["Tool","Gradle"],"content":"How to use the Build Cache ","date":"2017-02-07","objectID":"/2017/02/buildcache/:8:0","tags":["AndroidStudio"],"title":"加快 AndroidStudio 编译速度之 build cache","uri":"/2017/02/buildcache/"},{"categories":["Tool","Gradle"],"content":"Step 0 确保 android.dexOptions.preDexLibraries 已经设置为 true。否则 libraries 不会被 pre-dexed，因而 build cache 并不会被使用。 ","date":"2017-02-07","objectID":"/2017/02/buildcache/:8:1","tags":["AndroidStudio"],"title":"加快 AndroidStudio 编译速度之 build cache","uri":"/2017/02/buildcache/"},{"categories":["Tool","Gradle"],"content":"Step 1 在 Android 项目中打开 gradle.properties，添加以下两个参数 android.enableBuildCache=true # true:启用 build cache，反之禁用。如果这个参数未设置，默认是禁用 build cache. android.buildCacheDir=\u003cpath-to-build-cache-directory\u003e # 这个是个可选项，用来指定 build cache 目录的绝对路径。如果设置成项目路径，那么是项目于项目的根目录而言的。如果这个参数未被设置，那么默认的目录是 \u003cuser-home-directory\u003e/.android/build-cache。如果使用相同的缓存目录，那么多个项目可以共用相同的缓存，所以，推荐使用默认的路径或者使用一个项目外的绝对路径。任何情况下，build cache 的路径都不应该放在 \"build\" 文件夹下，除非每次运行 clean 之后，都能删除 build cache 。如果 android.enableBuildCache 被设置成 false，则这个参数将会被忽略。 ","date":"2017-02-07","objectID":"/2017/02/buildcache/:8:2","tags":["AndroidStudio"],"title":"加快 AndroidStudio 编译速度之 build cache","uri":"/2017/02/buildcache/"},{"categories":["Tool","Gradle"],"content":"Step 2 build 项目，或者在命令行下执行 ./gradlew assemble,检查以下位置，查看 build cache 是否起作用。 缓存的文件被存储在了上述 android.buildCacheDir 指定的文件夹下。默认情况下，是在 /.android/build-cache. 最终的 pre-dexed 文件被存储在了 \u003cproject-dir/module-dir\u003e/build/intermediates/pre-dexed/debug 和 \u003cproject-dir/module-dir\u003e/build/intermediates/pre-dexed/release.。可以在命令行下运行指令查看 “pre-dexed” 文件夹。如果点击的是 Android Studio 面板上的 “Run” 按钮，时无法看到这个文件夹的，因为这个文件夹背会被删除。 注意: 如果使用 Multi-dex 并且 minSdk \u003e= 21 ，那么 dexed files 将会被直接保存在 \u003cproject-dir/module-dir\u003e/build/intermediates/transforms/dex 目录下， 而不是在 \u003cproject-dir/module-dir\u003e/build/intermediates/pre-dexed. ** Cleaning the Build Cache 如果想要清除 build cache， 可以直接删除 build cache 文件夹内的内容。 build cache 文件夹在 android.buildCacheDir 指定的目录下,或者在默认的 /.android/build-cache 文件夹下. 从 Android Studio 2.3 Canary 1 开始，Gradle task 中新增了一个叫做 cleanBuildCache 的任务，可以更加便利的删除 build cache 。 ./gradlew cleanBuildCache 感激,非常感激，万分的感激！ 感谢以下的文章以及其作者和翻译的开发者们,排名不分先后 Build Cache Using build cache in Android Studio makes Gradle build faster ","date":"2017-02-07","objectID":"/2017/02/buildcache/:8:3","tags":["AndroidStudio"],"title":"加快 AndroidStudio 编译速度之 build cache","uri":"/2017/02/buildcache/"},{"categories":["Programming","Java"],"content":"Why 理解 JMM 就需要理解 JVM 中的运行时内存区域分为哪几部分,以及各个部分的区别. 内存区域是什么? Java 虚拟机在执行 Java 程序的过程中会把它所管理的内存划分为若干个不同的数据区域.这些区域都有各自的用于,以及创建和销毁的时间,有的区域随着虚拟机进程的启动而存在,有些区域则依赖用户县城的启动和结束而建立和销毁. 上图展示了 JVM 虚拟机所管理的几个运行时数据区域. 分为两类: 所有线程都共享的,即 JVM 虚拟机就一份 线程隔离的数据区,即每个线程所特有的一份,每份线程都会创建一份.它的生命周期与线程相同. ","date":"2017-01-28","objectID":"/2017/01/javamemorymodel-2/:0:0","tags":["JMM"],"title":"Java 内存模型_2","uri":"/2017/01/javamemorymodel-2/"},{"categories":["Programming","Java"],"content":"1. 程序计数器 程序计数器是一块儿较小的内存空间,它可以看做是当前线程所执行的字节码的行号指示器.在虚拟机的概念模型里,字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令,分支,循环,跳转,异常处理,线程恢复等基础功能都需要依赖这个计数器来完成. Java 虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的,在任何一个确定的时刻,一个处理器(对于多核处理器来说是一个内核)都会执行一条线程中的指令.因此,为了线程切换之后,能恢复到正确的执行位置,每条线程都需要一个独立的程序计数器,各条线程之间的计数器互不影响,独立存储,我们称这类内存区域为\"线程私有\"的内存. 如果线程正在执行的是一个 Java 方法,这个计数器记录的是正在执行的虚拟机字节码指令的地址;如果执行的是 native 方法,这个计数器的值则为空. 程序计数器是唯一一个在 Java 虚拟机规范中没有规定任何 OOM 情况的区域. ","date":"2017-01-28","objectID":"/2017/01/javamemorymodel-2/:1:0","tags":["JMM"],"title":"Java 内存模型_2","uri":"/2017/01/javamemorymodel-2/"},{"categories":["Programming","Java"],"content":"2. Java 虚拟机栈 虚拟机栈描述的是 Java 方法执行的内存模型:每个方法在执行的同时都会创建一个栈帧,栈帧是用于存储 局部变量表,操作数栈,动态链接,方法出口等 信息.每个方法从调用直至执行完成的过程,就对应着一个栈帧在虚拟机栈中的入栈到出栈的过程. 局部变量表存放编译器可知的各种基本数据类型(boolean、byte、char、short、int、float、long、double),对象引用(reference类型,它不等同于对象本身,可能是一个指向对象起始地址的引用指针,也可能是指向代表对象的句柄或者其他与次对象相关的位置) 和 returnAddress 类型(指向了一条字节码指令的地址). 局部变量表所需要的内存空间在编译期完成分配,当进入一个方法时,这个方法需要在帧中分配多大的局部变量空间是完全确定的,在方法运行期间不会改变局部变量的大小. 这个区域存在两种异常状况:如果线程的栈深度大于虚拟机允许的深度,讲抛出 StackOverflowError 异常;如果虚拟机栈是可以扩展的(当前大部分的 Java 虚拟机都可以动态扩展,只不过 Java 规范也允许固定长度的虚拟机栈),如果扩展时无法申请到足够的内存,就会抛出 OOM 异常. ","date":"2017-01-28","objectID":"/2017/01/javamemorymodel-2/:2:0","tags":["JMM"],"title":"Java 内存模型_2","uri":"/2017/01/javamemorymodel-2/"},{"categories":["Programming","Java"],"content":"3. 本地方法栈 本地方法栈的作用与虚拟机栈所发挥的作用是非常相似的,它们之间的区别不过是虚拟机栈为虚拟机执行 Java 方法(字节码) 服务,而本地方法栈则为虚拟机使用到 Native 方法服务.虚拟机规范中并未对本地方法栈中的使用的语言,使用方式与数据结果有强制规定,因此具体的虚拟机可以自由实现,甚至有的虚拟机直接将本地方法栈和虚拟机栈合二为一. 本地方法栈也会抛出和虚拟机栈一样的异常: StackOverflowError 和 OutOfMemoryError 异常. ","date":"2017-01-28","objectID":"/2017/01/javamemorymodel-2/:3:0","tags":["JMM"],"title":"Java 内存模型_2","uri":"/2017/01/javamemorymodel-2/"},{"categories":["Programming","Java"],"content":"4. Java 堆 Java 堆是 JVM 虚拟机管理的内存中最大的一块儿.Java 堆是被所有的线程共享的一块儿内存区域,在虚拟机创建的时候就创建.这个区域的唯一目的: 存放对象的实例,几乎所有的对象实例都在这里分配. 虚拟机规范的描述: 所有的对象实例以及数组都要在堆上分配. 随着 JIT 编译器的发展与逃逸分析技术逐渐成熟,栈上分配,标量替换优化技术将会导致一些微妙的变化发生,所有的对象都在堆上分配也逐渐变得不是那么的\"绝对\". Java 堆是垃圾收集器管理的主要区域,因此也会称 Java 堆为 “GC堆”. 从内存回收的角度来看,由于现在的收集器基本都采用分代收集算法,所以 Java 堆还可以细分为: 新生代和老年代;再细致一点的有 Eden 空间、From Survivor 空间、To Survivor 空间等。 从内存分配的角度来看,线程共享的 Java 堆中可能换分出多个线程私有的分配缓冲区(Thread Local Allocation Buffer,TLAB). 不过无论怎么划分,都与存放内容无关,无论哪个区域,存储的都仍然是对象实例,进一步划分的目的是为了更好的内存回收,或者更快地分配内存. 根据 Java 虚拟机规范的规定,Java 堆可以处于物理上不连续的内存空间中,只要逻辑上连续即可,就像我们的磁盘空间一样.在实现的时候,既可以实现成固定大小的,也可以是可扩展的,不过当前主流的虚拟机都是按照可扩展的来实现的. 如果堆中没有内存完成实例分配,并且堆也无法再扩展时,将会抛出 OutOfMemoryError 异常. ","date":"2017-01-28","objectID":"/2017/01/javamemorymodel-2/:4:0","tags":["JMM"],"title":"Java 内存模型_2","uri":"/2017/01/javamemorymodel-2/"},{"categories":["Programming","Java"],"content":"5. 方法区 方法区与 Java 堆一样,是各个线程共享的内存区域,它用于存储已被虚拟机加载的类信息,常量,静态变量,即时编译器编译后的代码等数据.虽然虚拟机规范把方法区描述成堆的一个逻辑部分,但是它却有一个叫做 Non-Heap(非堆)的名字,目的应该就是为了与堆区分开来. 习惯了在 HotSpot 虚拟机上开发,部署程序的开发者来说,很多人都更愿意把方法区成为永久代,本质上两者并不等价,仅仅是因为 HotSpot 虚拟机的设计选择将 GC 分代收集扩展至方法区,或者说使用永久代来实现方法区而已,这样 HotSpot 的垃圾收集器可以像管理 Java 堆一样管理这部分内存,能够省去专门为方法区编写内存管理代码的工作了.对于其他虚拟机来说则是不存在永久代这个概念的.永久代现在看来并非是一个好主意,对于 HotSpot 虚拟机,正在放弃永久代,并逐步采用 Native Memory 来实现方法区的规划了,目前在 JDK1.7 中,,已经将原本放在永久代的字符串常量池移出. 相对而言,垃圾收集行为在方法区是比较少见的,但并非数据进入方法就如永久代的名字一样,真的是永久的存在.这个区域的内存回收目标主要是针对常量池的回收和堆类型的卸载,一般来说,这个区域的内存回收是难以令人满意的,尤其是类型的卸载,条件相当苛刻,但是这个部分的内存回收却又不是非常必要的. 方法区无法满足内存分配需求时,将抛出 OutOfMemoryError 异常. ","date":"2017-01-28","objectID":"/2017/01/javamemorymodel-2/:5:0","tags":["JMM"],"title":"Java 内存模型_2","uri":"/2017/01/javamemorymodel-2/"},{"categories":["Programming","Java"],"content":"6. 运行时常量池 运行时常量池是方法区的一部分! class 文件中除了有类的版本,字段,方法,接口等描述信息外,还有一项信息是常量池,用于存在编译期生成的各种字面量和符号引用,这部分内存将在类加载后进入方法区的运行时常量池中存放. Java 虚拟机对 class 文件每一部分的格式都有严格规定,每一个字节用于存储哪种数据都必须符合规范上的要求才会被虚拟机认可,装载和执行,但对于运行时常量池,Java 虚拟机规范没有做任何细节的要求,不同的虚拟机可以按照自己的需要来实现这个内存区域.一般来说,除了保存 class 文件中描述的符号引用外,还会把翻译出来的直接引用也存储在运行时常量池中. 运行时常量池对于 class 文件常量池的另外一个重要特征是具备动态性,Java 语言并不要求敞亮一定只有编译期才能产生,也就是并非预置入 class 文件中常量池的内容才能进入方法区运行时常量池,运行期间也可能将新的常量放入常量池中,这种特性被开发人员利用得比较多的便是 String 类的 intern () 方法. 既然运行时常量池是方法区的一部分,自然受到方法区内存的限制,当常量池无法再申请到内存的时候,就会抛出 OutOfMemoryError 异常. ","date":"2017-01-28","objectID":"/2017/01/javamemorymodel-2/:6:0","tags":["JMM"],"title":"Java 内存模型_2","uri":"/2017/01/javamemorymodel-2/"},{"categories":["Programming","Java"],"content":"7. 直接内存 直接内存并非是运行时数据区的一部分,也不是 Java 虚拟机规范中定义的内存区域.但是这部分内存也被频繁的使用,而且可能导致 OutOfMemoryError 异常出现. 在 Java1.4 之后新加入了 NIO 类,引入了一种基于通道与缓存区的 I/O 方法,它可以使用 Native 函数库直接分配堆外内存,然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作.这样能在一些场景中显著的提高性能,因为避免了在 Java 堆中和 Native 堆中来回复制数据. 显然,本机直接内存分配不会受到 Java 堆大小的限制,但是,既然是内存,肯定还是会受到本机总内存的大小和处理器寻址空间的限制.所以,也是会出现 OutOfMemoryError 异常. ","date":"2017-01-28","objectID":"/2017/01/javamemorymodel-2/:7:0","tags":["JMM"],"title":"Java 内存模型_2","uri":"/2017/01/javamemorymodel-2/"},{"categories":["Programming","Java"],"content":"感激,非常感激，万分的感激！ 感谢以下的文章以及其作者和翻译的开发者们,排名不分先后 深入理解Java虚拟机（第2版） ","date":"2017-01-28","objectID":"/2017/01/javamemorymodel-2/:8:0","tags":["JMM"],"title":"Java 内存模型_2","uri":"/2017/01/javamemorymodel-2/"},{"categories":["Programming","Java"],"content":"概述 本文记录 Java 中的内存模型的基础部分1。 本篇作为学习 Java 内存模型基础部分的笔记,加上些许自己的理解和解释. ","date":"2017-01-15","objectID":"/2017/01/javamemorymodel1/:0:0","tags":["JMM"],"title":"Java 内存模型_1","uri":"/2017/01/javamemorymodel1/"},{"categories":["Programming","Java"],"content":"为什么需要理解 Java 内存模型 结论:并发产生的内存可见性问题. 并发编程中的两个关键问题: 线程之间如何通行(以何种机制来交换信息) 线程之间如何同步 已有的通信机制: 共享内存: 线程之间共享程序的公共状态,线程之间通过读写内存中的公共状态来隐式进行通信. 消息传递: 在这种模型中,线程之间没有公共状态,线程之间必须通过发送消息显式地通信. 同步,指的是控制不同线程之间操作发生的相对顺序的机制: 在共享内存模型中,程序员必须显式的指定某个方法或者某段代码需要在线程之间互斥执行. 在消息传递的模型里,由于消息的发送必须在消息的接收之前,因此,同步是隐式进行的. java 采用的是共享内存模型,而 java 线程之间的通信总是隐式进行,整个通信过程对程序员完全是透明的. 对于 java 程序员而言,如果不了解 java 内存模型,在编写多线程程序的时候,就会遇到各种各样的内存可见性的问题.所以,对 java 的内存模型需要有一定的了解. ","date":"2017-01-15","objectID":"/2017/01/javamemorymodel1/:1:0","tags":["JMM"],"title":"Java 内存模型_1","uri":"/2017/01/javamemorymodel1/"},{"categories":["Programming","Java"],"content":"Java 采用的共享内存模型是什么样的 Java 采用的是共享内存模型作为线程间的通信机制. 共享内存: 堆内存,在 java 中,所有的 实例域,静态域和数组元素 存储在堆内存中,堆内存在线程之间共享. 局部变量,方法定义的参数和异常处理参数,不会在线程之间共享,它们不会有内存可见性问题,也不受内存模型的影响. Java 线程之间的通信由 Java内存模型(JMM)控制,JMM 决定了一个线程对共享变量的写入何时对另个线程可见.从抽象的角度来看,JMM 定义了线程和主内存之间的抽象关系:线程之间的共享变量存储在主内存中,每个线程都有一个私有的本地内存,本地内存中存储了该线程以读写共享变量的副本.本地内存是 JMM 的一个抽象概念,并不真实存在.它涵盖了缓存,写缓冲区,寄存器以及其他的硬件和编译器优化. 分析: 线程 A 和线程 B 通信过程 线程 A 将本地内存 A 中更新过的共享变量刷新到主内存中去. 线程 B 去主内存中读取线程 A 更新过的共享变量. 本地内存 A 和本地内存 B 都有主内存中共享的变量 x 的副本.假设初始时,这个三个内存中的 x 的值都是 0.线程 A 在执行时,把已经更新的 x 值(假设为1) 临时存放在自己的本地内存 A 中. 当线程 A 和线程 B 需要通信的时,线程 A 首先会把本地内存中修改后的 x 值刷新到主内存中,此时主内存中的 x 值变为 1.随后,线程 B 到主内存中读取线程 A 更新之后的 x 值,此时线程 B 的本地内存的 x 值也变为 1. 从整体上看,这两个步骤实质上是线程 A 在向线程 B 发送消息,而且这个通信过程必须经过主内存.JMM 通过控制主内存与每个线程的本地内存之间的交互,来为 java 程序员提供内存可见性保证. ","date":"2017-01-15","objectID":"/2017/01/javamemorymodel1/:2:0","tags":["JMM"],"title":"Java 内存模型_1","uri":"/2017/01/javamemorymodel1/"},{"categories":["Programming","Java"],"content":"重排序(即 java 如何实现同步) 为什么需要重排序 在执行程序的时候,为了提高性能,编译器 和 处理器 常常会对指令做重排序.有三种重排序. 什么是重排序 编译器优化重排序(编译器重排序).编译器在不改变单线程程序语义的前提下,重新安排语句的执行顺序. 指令级并行重排序(处理器重排序).现代处理器采用指令级并行技术来执行多条指令重叠执行.在不存在数据依赖的前提下,处理器可以改变语句对应的指令的执行顺序. 内存系统的重排序(处理器重排序).由于处理器使用缓存和读写缓冲区,这使得加载和存储操作看上去可能是在错乱执行. 所以,从 java 源代码到执行阶段,会一次经过三个重排序.以上所述的三个重排序,一个属于编译器重排序,两个属于处理器重排序. 如何避免重排序带来的问题 三个重排序,都可能导致多线程出现内存可见性的问题. 一个例子,说明重排序产生的问题 假设处理器 A 和处理器 B 按程序的顺序并行执行内存访问，最终却可能得到 x = y = 0 的结果。具体的原因如下图所示： 这里处理器 A 和处理器 B 可以同时执行赋值操作 A1,B1,将共享变量写入各自的写缓冲区（缓冲区 A ，缓冲区 B）,此时处理器 A 中的写缓冲区中的变量 a 值为1,处理器 B 写缓冲区中的变量 b 值为2,但是还未刷新到内存中; 然后执行 A2,B2 操作,从内存中读取变量 b 和变量 a 的值(此时的变量 a 和变量 b 的值还是初始状态,都为0),并赋值给 x 和 y,所以,此时的 x 和 y 的值都为 0. 最后执行 A3 和 B3 操作，把处理器 A 和 处理器 B 写缓存区中保存的脏数据刷新到内存中,此时内存中的变量 a 和变量 b 就是 1 和 2 了。 执行完所有操作之后, x = y = 0 . 从内存操作实际发生的顺序来看，直到处理器 A 执行 A3 来刷新自己的写缓存区，写操作 A1 才算真正执行了。虽然处理器 A 执行内存操作的顺序为：A1-\u003eA2，但内存操作实际发生的顺序却是：A2-\u003eA1。此时，处理器 A 的内存操作顺序被重排序了（处理器 B 的情况和处理器 A 一样，这里就不赘述了）。 这里的关键是，由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。由于现代的处理器都会使用写缓冲区，因此现代的处理器都会允许对写-读操作重排序。 对于编译器, JMM 的编译器重排序规则会禁止特定类型的编译器重排序(并不是所有的编译器重排序都需要被禁止的). 对于处理器, JMM 的处理器重排序规则会要求 java 编译器在生成指令序列的时候,插入指定类型的内存屏障指令,通过内存屏障指令来禁止特定类型的处理器重排序(不是所有的处理器重排序都要禁止的). 处理器重排序 现代处理器使用写缓冲区来临时保存向内存写入的数据.写缓冲区可以保障指令流水线持续运行,它可以避免由于处理器停顿下来等待向内存写入数据而产生延迟.同时通过以批处理的方式刷新写缓冲区,以及合并写缓冲区中对同一个内存地址的多次写,可以减少对内存总线的占用. 缓冲区的这一特性是可以加速程序的运行,然而每个处理器的写缓冲区,仅仅对它所在的处理器可见.这个特性会对内存操作的执行顺序产生重要的影响:处理器对内存的读写操作的执行顺序,不一定与内存实际发生的读写顺序一致. 上表单元格中的 “N” 表示处理器不允许两个操作重排序，“Y” 表示允许重排序。 从上表我们可以看出：常见的处理器都允许 Store-Load 重排序；常见的处理器都不允许对存在数据依赖的操作做重排序。sparc-TSO 和 x86 拥有相对较强的处理器内存模型，它们仅允许对写-读操作做重排序（因为它们都使用了写缓冲区）。 注1：sparc-TSO 是指以 TSO(Total Store Order) 内存模型运行时，sparc 处理器的特性。 注2：上表中的 x86 包括 x64 及 AMD64。 注3：由于 ARM 处理器的内存模型与 PowerPC 处理器的内存模型非常类似，本文将忽略它。 注4：数据依赖性后文会专门说明。 内存屏障指令 为了保证内存可见性，java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM 把内存屏障指令分为下列四类： StoreLoad Barriers 是一个“全能型”的屏障，它同时具有其他三个屏障的效果。现代的多处理器大都支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（buffer fully flush）。 happens-before 从 JDK5 开始，java 使用新的 JSR -133 内存模型,JSR-133 使用 happens-before 的概念来阐述操作之间的内存可见性。在 JMM 中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在 happens-before 关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。 与程序员密切相关的 happens-before 规则如下： 程序顺序规则：一个线程中的每个操作，happens-before 于该线程中的任意后续操作。（注解：如果只有一个线程的操作，那么前一个操作的结果肯定会对后续的操作可见。) 监视器锁规则：对一个监视器锁的解锁，happens-before 于随后对这个监视器锁的加锁。 volatile 变量规则：对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 域的读。 传递性：如果 A happens-before B，且 B happens-before C，那么 A happens-before C。 注意，两个操作之间具有 happens-before 关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before 仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前(the first is visible to and ordered before the second). happens-before 与 JMM 的关系. 如上图所示，一个 happens-before 规则通常对应于多个编译器和处理器重排序规则。对于 java 程序员来说，happens-before 规则简单易懂，它避免 java 程序员为了理解 JMM 提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现。 ","date":"2017-01-15","objectID":"/2017/01/javamemorymodel1/:3:0","tags":["JMM"],"title":"Java 内存模型_1","uri":"/2017/01/javamemorymodel1/"},{"categories":["Programming","Java"],"content":"感激,非常感激，万分的感激！ 感谢以下的文章以及其作者和翻译的开发者们,排名不分先后 深入理解Java内存模型（一）——基础 ","date":"2017-01-15","objectID":"/2017/01/javamemorymodel1/:4:0","tags":["JMM"],"title":"Java 内存模型_1","uri":"/2017/01/javamemorymodel1/"},{"categories":["Mobile","Android"],"content":"背景 由于 Binder 很复杂,这个分多篇展开,目前先将零碎的知识整合,在后面几篇进行总结. 概述: Binder 用于进程间通信，而 Handler 消息机制用于同进程的线程间通信。 Binder 的英文涵义是别针，回形针的意思。 在 Android 中 Binder 的存在是为了完成进程间的通信，将进程\"别\" 在一起。比如说：普通应用可以调用播放器提供的服务：播放、暂停、停止等功能。 Binder 是工作在 Linux 层面，属于一个驱动，只是这个驱动是不需要硬件的，或者说是基于操作系统的一小块内存。从线程的角度来讲，Binder 驱动的代码是运行在内核态的，客户端程序调用 Binder 是通过系统调用完完成。 ","date":"2017-01-03","objectID":"/2017/01/ipc-binder-java-1/:0:0","tags":["IPC","Binder"],"title":"IPC_Binder_java_1","uri":"/2017/01/ipc-binder-java-1/"},{"categories":["Mobile","Android"],"content":"Binder 框架：一种架构 Binder 框架提供 服务端接口、Binder 驱动、客户端接口 三个模块。 从服务端的角度来说，一个 Binder 服务端实际上就是一个 Binder 类的对象，该类一旦创建，内部就会启动一个隐藏线程。该线程接下来就用于接收 Binder 驱动发送来的消息，收到消息之后，会执行到 Binder 对象中的 onTransact 方法，在这个方法中，根据不同的参数，执行不同的服务代码。因此，要实现一个 Binder 服务，就必须重载 onTransact 方法。 在 onTransact 方法中，会获取传递进来的参数，将其转换成服务函数的参数。onTransact 参数的来源于 客户端的调用 transact 方法。所以，如果 transact 方法的参数有固定的格式输入，那么 onTransact 就会有相应的固定格式输出。 从 Binder 驱动的角度来说。任何一个服务端的 Binder 对象被创建的时候，都同时会在 Binder 驱动中创建一个 mRemote 对象，这个对象也是 Binder 类。客户端想要访问远程服务的时候，都是通过这个 mRemote 对象。 从客户端的角度来说。要想访问远程服务，必须先获取远程服务在 Binder 驱动中对应的 mRemote 引用，在获取该对象之后，就可以调用 transact 方法，而在 Binder 驱动中，mRemote 对象也重载了 transact 方法。 以线程间消息通信的模式，向服务端发送客户端传递过来的参数。 挂起当前的线程，当前线程正是客户端线程，并等待服务端线程执行完指定服务函数之后通知。 接收服务端线程的通知，然后继续执行客户端线程，并返回客户端代码区。 从以上的叙述中，可以看出，对应用开发者来说，客户端似乎是在直接调用了远程服务对应的 Binder ，而事实上，则是通过 Binder 驱动中的 Binder 对象，不同的是， Binder 驱动中的对象不会额外产生一个线程。 简言之: 客户端将消息发至 -\u003e Binder 驱动 ，向服务端发送调用信息，驱动挂起当前线程 ，等待返回-\u003e 服务端 ，处理完消息，返回给驱动-\u003e 驱动接到完成的通知，继续客户端的线程 - \u003e返回结果给客户端。 连接他们的是一个叫 mRemote 的引用，这个引用存在于 Binder 驱动当中，每个服务端的都需要向 Binder 驱动注册，生成这个 mRemote 引用。 客户端利用这个引用去发送消息给驱动，驱动利用这个引用去发送消息给服务端， 整个过程像客户端直接调用了服务端，事实上是通过 Binder 驱动中转了，存在两个 Binder 对象，一个是服务端的 Binder 对象， 一个是 驱动中的 Binder 对象，区别中，Binder 驱动中不会产生额外的线程，而服务端的 Binder 在创建之初就有一个隐含的线程。 ","date":"2017-01-03","objectID":"/2017/01/ipc-binder-java-1/:1:0","tags":["IPC","Binder"],"title":"IPC_Binder_java_1","uri":"/2017/01/ipc-binder-java-1/"},{"categories":["Mobile","Android"],"content":"设计 Server 端 设计 server 端只需要新建一个继承 Binder 的 service 即可，当启动这个 service 的时候，在 ddms 中的 thread 会发现多了一个 Binder thread 。 定义完 service ，接下来需要重载 onTrasact 方法，并从 data 变量中读取客户端传递进来的参数。 假如，这里有很多参数，那么怎么知道参数的顺序呢？所以，这个需要一个双方的约定。 方法的第一个参数 code 是用来标记不同的服务端函数的。 如果想要返回结果，则在 reply 中调用相关的函数写入即可。 ","date":"2017-01-03","objectID":"/2017/01/ipc-binder-java-1/:2:0","tags":["IPC","Binder"],"title":"IPC_Binder_java_1","uri":"/2017/01/ipc-binder-java-1/"},{"categories":["Mobile","Android"],"content":"设计 Binder 客户端 对于客户端要想使用服务端的服务函数，则必须先获取服务端在 Binder 驱动中对应的 mRemote 对象。在获取到该对象之后，就可以调用该变量的 transact 方法。 public final boolean transact(int code, Parcel data, Parcel reply, int flags) data 是传递给服务端的数据，远程服务函数的参数，都是从这个 data 中取的。 data 中能放的类型都是常用的原子类型，String，int ，long 等，当然也包括实现了 Parcelable接口的类。 这里向 data 写入的数据的顺序，必须和 onTransact 取参数的顺序保持一致，需要实现约定好。 当调用客户端调用远程方法，经由 mRemote 调用 transact 的时候，客户端线程进入 Binder 驱动， Binder 驱动就会挂起当前线程，并向远程服务发送一个消息，消息中包含了客户端传进来的包裹数据。 当服务端 service 执行 onTrasact 的时候，就可以对包裹 data 进行拆解，然后根据参数执行相应的 服务函数，执行完之后，会将执行的结果放入 reply 中。 当这一切都执行完之后，服务端会向 Binder 驱动发送一个 notify 的消息（客户端线程在调用 transact 的时候，客户端线程会被挂起），从使得客户端线程从 Binder 驱动代码区返回到客户端代码区。 对于最后一个参数 flags ，表示的是 IPC 调用的模式，分为：双向，用0 表示，含义是服务端执行完之后会返回一定的数据；还有一种是单向，用1 表示，含义是不返回任何数据。 同样的，返回到结果都是在 reply 中，客户端从这个 reply 中取的数据，这部分顺序也必须实现约定好。 ","date":"2017-01-03","objectID":"/2017/01/ipc-binder-java-1/:3:0","tags":["IPC","Binder"],"title":"IPC_Binder_java_1","uri":"/2017/01/ipc-binder-java-1/"},{"categories":["Mobile","Android"],"content":"使用 service 在编写 Binder 服务端和客户端的过程中，会伴随着两个问题。 客户端如何获得服务端的 Binder 对象引用 客户端和服务端约定关于顺序的顺序和服务函数的 int 标志。 使用 Binder 的原因是想提供一个全局的服务，所谓的全局，意思是系统中的任何程序都可以访问 。很明显，这个应该属于操作系统需要提供的基本功能之一，所以有个方法就是 service。 无论是否使用 service类，都需要解决上面的两个问题。 当然完全可以不使用 service 类，而是仅仅基于 Binder 类编写服务程序，然而这个只是一部分。具体来说，可以仅仅使用 Binder 类扩展系统服务，对于客户端服务则必须是基于 service 类来编写的。系统服务是指那些通过 getSystemService 方法获取的服务，而客户端服务是指应用程序提供的自定义服务。 也就是说，扩展系统服务的时候，可以完全只使用 Binder 类；而对于客户端的服务则必须基于 service。 ","date":"2017-01-03","objectID":"/2017/01/ipc-binder-java-1/:4:0","tags":["IPC","Binder"],"title":"IPC_Binder_java_1","uri":"/2017/01/ipc-binder-java-1/"},{"categories":["Mobile","Android"],"content":"获取 Binder 对象 看下几个启动 service 相关的方法，这些方法在 android.app.ContextWrapper 类中。 public ComponentName startService(Intent service) { return mBase.startService(service); } 这个方法很熟悉，就是一个 启动服务的方法，然后启动之后，客户端并不能拿到服务端的 Binder 引用，因此并不能调用服务端的任何服务。 @Override public boolean bindService(Intent service, ServiceConnection conn, int flags) { return mBase.bindService(service, conn, flags); } public interface ServiceConnection { public void onServiceConnected(ComponentName name, IBinder service); public void onServiceDisconnected(ComponentName name); } bindService 方法第一个参数是启动 service 的intent ，第二个参数是一个接口，接口中有个方法叫 onServiceConnected 这个方法含有两个参数，第二个参数就是 Binder 。 具体的运行过程中，当客户端请求启动 service 的时候，请求就会通过 Ams 发出，若 service 正常去懂了，那么 Ams 就会远程调用 ActivityThread 类中的 ApplicationThread 对象，调用的参数就包含了 service 的 Binder 对象的引用，然后在 ApplicationThread 中回调 bindService 的第二个参数 ServiceConnection 的方法 onServiceConnected ，将 Binder 引用传递回客户端，这样客户端就拿到了远程服务的 Binder 对象引用，在实际操作中，常常可以这个 Binder 对象引用设置成一个全局变量，可以在客户端的任何地方都可以访问到。 ","date":"2017-01-03","objectID":"/2017/01/ipc-binder-java-1/:4:1","tags":["IPC","Binder"],"title":"IPC_Binder_java_1","uri":"/2017/01/ipc-binder-java-1/"},{"categories":["Mobile","Android"],"content":"保证参数顺序的工具-AIDL 在数据传递的过程中，需要实现约定好服务函数所对应的 code 的 int 值，需要约定好参数的写入顺序。在 Android 中的 AIDL 就是这么个工具。 AIDL 可以将一个 AIDL 文件转换成一个 Java 类文件，同时重载 transact 和 onTransact 方法。关于服务函数对应的 int 值和参数的读写书序，都统一做了处理。这样，开发者只需要专注于服务代码本身了。 可以看得出来，AIDL 并非是必须的，只是一个工具。 interface ICompute { void basicTypes(int anInt, long aLong, boolean aBoolean, float aFloat,double aDouble, String aString); int add(int a, int b); } 一般情况下，第一个字母是 I，这样是为了程序风格的统一，后面的 Compute 是服务的类名，AIDL 工具会以这个服务的名字生成 Java 类。( 当然这个是默认的，相应的也是可以修改的，具体的另行参照说明。 ) aidl 文件中可以引用其他的 Java 类，但是需要遵循以下要求： Java 原子类型，int，long，String 等。 Binder 引用。 实现了 parcelable 接口的对象。 运行 AIDL 工具之后，生成的文件中，包含了 Java interface，proxy，stub类。 Java interface 是以 aidl 文件命名的。比如 ICompute 。产生的 interface就是 ICompute 。并且该类继承了 IInterface 接口，即，需要实现 asBinder 方法。 在 Stub 内部还有一个内部静态类 proxy ， 该类具体实现了 AIDL 生成的接口，按照约定的顺序写入参数，可以注意到这里的顺序和 Stub 中重载的 onTransact 中读取的顺序是一致的。proxy 类中持有了一个 IBinder mRemote 对象，这个对象就是远程服务端的引用，Proxy 该类作为客户端访问服务端的代理，该类的代理产生的原因：主要是为了解决约定写入参数的顺序。 内部有一个静态内部抽象类 Stub，这个类主要是由服务端使用 ，之所以是抽象类，因为具体的服务函数必须由程序员自己去实现。该类继承 Binder 类，并且实现 AIDL 生成的接口，但是没有具体的实现这个接口。该类也重载了 onTransact 方法，这个方法是去按照约定的顺序取参数中的值，因为是 ADIL 自己生成的，所以顺序，它自己很清楚；并且定义了服务函数对应的 int 值。asBinder 方法返回的就是 Stub 自身。它内部还有个非常重要的方法 asInterface ，这个方法根据参数 IBinder 对象是否是自身进程中的对象，返回不同的对象。因为我们知道，服务端的服务函数，不仅仅是别的进程可以使用，与 服务端在一个进程内部也可以调用，这种场景下，显然是不需要 IPC 的，而是直接调用。反之，则返回一个 proxy，交由跨进程的客户端引用。在 Binder 内部提供了 queryLocalInterface 方法根据描述符判断当前的 Binder 对象时不是本地的 Binder 引用。因为每当新创建一个 Binder 对象的时候，服务端进程内部会创建一个 Binder 对象，同时在 Binder 驱动中也会创建一个 Binder 对象。如若是跨进程调用，远程访问的时候，返回的 Binder 就会是 Binder 驱动中的 Binder 对象，如若是进程内部获取 Binder 对象，则会是服务端本身的 Binder 对象。所以，asInterface 是对外提供了一个 统一的接口，保证无论进程内还是进程外都能访问，返回的对象就两种，一个是 Proxy 类对象，一个就直接使用 Stub 本身，强制类型转换成 接口类型。 总结 本篇最后,放一张图进行总结. 感激,非常感激，万分的感激！ 感谢以下的文章以及其作者和翻译的开发者们,排名不分先后 柯元旦 gityuan ","date":"2017-01-03","objectID":"/2017/01/ipc-binder-java-1/:5:0","tags":["IPC","Binder"],"title":"IPC_Binder_java_1","uri":"/2017/01/ipc-binder-java-1/"},{"categories":["Mobile","Android"],"content":"概述 本文记录 Android 的消息机制在 java 层的原理分析. 背景 在学习 Binder,IPC 的时候,涉及到消息机制,顺带整理一下. ","date":"2016-12-17","objectID":"/2016/12/messgaemechanism/:0:0","tags":["Message","Handler","消息机制"],"title":"Android消息机制_Java层","uri":"/2016/12/messgaemechanism/"},{"categories":["Mobile","Android"],"content":"概述 进程:系统进行资源分配和调度的基本单位. 在 Andrid 中,对于每个 App 运行时前,系统都会为其创建一个进程，App 就运行在一个进程中. 线程: 作为程序执行的最小单元。 该线程与 App 所在进程之间资源共享，从 Linux 角度来说进程与线程除了是否共享资源外，并没有本质的区别，都是一个 task_struct 结构体，在 CPU 看来进程或线程无非就是一段可执行的代码. Android 主线程: 一个进程中就一个主线程,这个主线程负责更新 UI. Why 目前对为什么需要消息机制,还没认真的研究,个人觉得系统的运转和程序的运行说到底都是消息的传递,如何让这些程序的消息传递高效地的运转,于是产生了消息机制一说. What 什么是消息机制?消息机制的三大要素: 消息队列 消息循环 消息类型 How 在 Android 中是如何使用消息机制的? Android 中典型的消息机制就是 Handler. 以下是我们平时使用 Handler 经常使用的方式. private Handler mHandler = new Handler(new Callback() { @Override public boolean handleMessage(Message msg) { System.out.println(\"截断消息\"); return true; } }) { @Override public void handleMessage(Message msg) { System.out.println(\"再处理消息\"); } }; mHandler.post(new Runnable() { @Override public void run() { System.out.println(\"second\" + Thread.currentThread()); textView.setText(\"upate\"); } }); 原理 前面的概述中说到,对于系统而言,无论是线程还是进程,对其而言,都是一段可执行的代码而已,没有那么既然是可执行的代码,执行完,线程生命周期也就结束了. 在 Android 中,对于主线程，我们是绝不希望会被运行一段时间就结束了，我们希望它能一直的运行下去,直到用户主动的退出 APP 或者出现其他意外. 那如何才能实现这样的效果呢?不就是为了能一直运行吗?死循环便能保证不会被退出. 但这里可能又引发了另一个问题，既然是死循环又如何去处理其他事务呢？通过创建新线程的方式。 我们看下在 ActivityThread 中的 main 方法： public static void main(String[] args) { .... Looper.prepareMainLooper(); ActivityThread thread = new ActivityThread(); thread.attach(false); Looper.loop(); throw new RuntimeException(\"Main thread loop unexpectedly exited\"); } ActivityThread 并不是线程，并没有真正继承 Thread 类，只是运行在主线程，其实承载 ActivityThread 的主线程就是由 Zygote fork 而创建的进程。 从这里的代码可以看到,主线程是一个死循环,主线程的死循环一直运行是不是特别消耗 CPU 资源呢？ 其实不然，这里就涉及到 Linux pipe/epoll 机制.下面分析 loop 函数的时候遇到再说. 下面分别看下消息机制的三个要素. ","date":"2016-12-17","objectID":"/2016/12/messgaemechanism/:1:0","tags":["Message","Handler","消息机制"],"title":"Android消息机制_Java层","uri":"/2016/12/messgaemechanism/"},{"categories":["Mobile","Android"],"content":"Looper 对于 looper 的典型例子: Looper.prepare(); mHandler = new Handler() { public void handleMessage(Message msg) { // handle message } }; Looper.loop(); 上面就是一个典型的 Looper 的使用步骤 - 调用 prepare 方法 - 创建 Handler 对象 - 调用 loop 方法 对于 prepare 方法，每个线程只能执行一次，当检测到当前的线程已经执行过这个方法，则会抛出异常。 static final ThreadLocal\u003cLooper\u003e sThreadLocal = new ThreadLocal\u003cLooper\u003e(); // .............. private static void prepare(boolean quitAllowed) { if (sThreadLocal.get() != null) { throw new RuntimeException(\"Only one Looper may be created per thread\"); } sThreadLocal.set(new Looper(quitAllowed)); } 对于 ThreadLocal 类，这个称为线程本地存储，以线程为单位，实现资源的共享。每个线程有自己的私有区域，线程间是不能互相访问的。有的地方也能看到用 ThreadLocal 实现线程内的单例。 其中对应的 set 和 get 方法，这样就能实现一个线程只有一个 looper ，检查的时候只要判断当前的线程本地存储是否有 looper 就能确定当前的线程是否执行过 prepare 。 public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } public T get() { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) return (T)e.value; } return setInitialValue(); } Looper 的构造方法中需要传递一个 boolean 值的参数，表示创建的这个 looper 是否可以被取消，直观上说就是是否可以调用 quit 方法。 private Looper(boolean quitAllowed) { mQueue = new MessageQueue(quitAllowed); mThread = Thread.currentThread(); } 对于默认的 looper 构造传的是 true。 /** Initialize the current thread as a looper. * This gives you a chance to create handlers that then reference * this looper, before actually starting the loop. Be sure to call * {@link #loop()} after calling this method, and end it by calling * {@link #quit()}. */ public static void prepare() { prepare(true); } 有个 looper 之后，就可以创建熟知的 handler 对象了。handler 在创建的时候，都是会检查当前的线程是否有 looper ，如果没有，则会抛出异常，不能正常的创建，毕竟这是一个消息机制必不可少的元素。 public Handler(Callback callback, boolean async) { if (FIND_POTENTIAL_LEAKS) { final Class\u003c? extends Handler\u003e klass = getClass(); if ((klass.isAnonymousClass() || klass.isMemberClass() || klass.isLocalClass()) \u0026\u0026 (klass.getModifiers() \u0026 Modifier.STATIC) == 0) { Log.w(TAG, \"The following Handler class should be static or leaks might occur: \" + klass.getCanonicalName()); } } mLooper = Looper.myLooper(); if (mLooper == null) { throw new RuntimeException( \"Can't create handler inside thread that has not called Looper.prepare()\"); } mQueue = mLooper.mQueue; mCallback = callback; mAsynchronous = async; } 接下来就可以调用 loop 方法进入循环模式。 public static void loop() { final Looper me = myLooper(); if (me == null) { throw new RuntimeException(\"No Looper; Looper.prepare() wasn't called on this thread.\"); } final MessageQueue queue = me.mQueue; // Make sure the identity of this thread is that of the local process, // and keep track of what that identity token actually is. Binder.clearCallingIdentity(); final long ident = Binder.clearCallingIdentity(); for (;;) { Message msg = queue.next(); // might block if (msg == null) { // No message indicates that the message queue is quitting. return; } // This must be in a local variable, in case a UI event sets the logger final Printer logging = me.mLogging; if (logging != null) { logging.println(\"\u003e\u003e\u003e\u003e\u003e Dispatching to \" + msg.target + \" \" + msg.callback + \": \" + msg.what); } final long traceTag = me.mTraceTag; if (traceTag != 0) { Trace.traceBegin(traceTag, msg.target.getTraceName(msg)); } try { msg.target.dispatchMessage(msg); } finally { if (traceTag != 0) { Trace.traceEnd(traceTag); } } if (logging != null) { logging.println(\"\u003c\u003c\u003c\u003c\u003c Finished to \" + msg.target + \" \" + msg.callback); } // Make sure that during the course of dispatching the // identity of the thread wasn't corrupted. final long newIdent = Binder.clearCallingIdentity(); if (ident != newIdent) { Log.wtf(TAG, \"Thread identity changed from 0x\" + Long.toHexString(ident) + \" to 0x\" + Long.toHexString(newIdent) + \" while dispatching to \" + msg.target.getClass().getName() + \" \" + msg.callback + \" what=\" + msg.what); } msg.recycleUnchecked(); } } 直观上我们就可以看到这是一个死循环，不断的通过 queue.next() 取出消息，而后通过 msg.target.dispa","date":"2016-12-17","objectID":"/2016/12/messgaemechanism/:2:0","tags":["Message","Handler","消息机制"],"title":"Android消息机制_Java层","uri":"/2016/12/messgaemechanism/"},{"categories":["Mobile","Android"],"content":"MessageQueue: 对于期初构造 looper 的时候传递了一个参数，表示了是否可以退出，在构造 looper 的时候 ，这个参数，也会传递到 MessageQueue 的构造方法中。 looper 中的 quit 方法最终调用的是 MessageQueue 中的 quit 方法，在 quit 方法中，假如当初传递的参数是 false，则会抛出异常，即表示不能退出的含义。 MessageQueue(boolean quitAllowed) { mQuitAllowed = quitAllowed; mPtr = nativeInit(); } void quit(boolean safe) { if (!mQuitAllowed) { throw new IllegalStateException(\"Main thread not allowed to quit.\"); } synchronized (this) { if (mQuitting) { return; } mQuitting = true; if (safe) { removeAllFutureMessagesLocked(); } else { removeAllMessagesLocked(); } // We can assume mPtr != 0 because mQuitting was previously false. nativeWake(mPtr); } } 在quit 方法中也区分了 safe 和 unsafe。安全的方式只移除那些还未开始的消息，非安全的方式是移除所有的消息。 再细看 MessageQueue 的构造方法中有个 nativeInit();说明这里有涉及 native 方法。这里注下,在整个消息机制中 只有 MessageQueue 是涉及 Java 层和 Native 层的。 当 MessageQueue 没有消息的时候,便阻塞在 nativePollOnce() 方法里，此时主线程会释放 CPU 资源进入休眠状态，直到下个消息到达或者有事务发生，通过往 pipe 管道写端写入数据来唤醒主线程工作,看 native 代码的话,是一个 “w” 字符.上面说过,这叫做 epoll 机制，是一种 IO 多路复用机制，可以同时监控多个描述符，当某个描述符就绪(读或写就绪)，则立刻通知相应程序进行读或写操作，本质同步 I/O，即读写是阻塞的。所以,当消息队列中没有消息的时候,主线程就会释放 CPU ,不会继续占用 CPU ,这里就解释了为什么主线程是个死循环,还能继续处理其他事情. Message next() { // Return here if the message loop has already quit and been disposed. // This can happen if the application tries to restart a looper after quit // which is not supported. final long ptr = mPtr; if (ptr == 0) { return null; } int pendingIdleHandlerCount = -1; // -1 only during first iteration int nextPollTimeoutMillis = 0; for (;;) { if (nextPollTimeoutMillis != 0) { Binder.flushPendingCommands(); } nativePollOnce(ptr, nextPollTimeoutMillis); synchronized (this) { // Try to retrieve the next message. Return if found. final long now = SystemClock.uptimeMillis(); Message prevMsg = null; Message msg = mMessages; if (msg != null \u0026\u0026 msg.target == null) { // Stalled by a barrier. Find the next asynchronous message in the queue. do { prevMsg = msg; msg = msg.next; } while (msg != null \u0026\u0026 !msg.isAsynchronous()); } if (msg != null) { if (now \u003c msg.when) { // Next message is not ready. Set a timeout to wake up when it is ready. nextPollTimeoutMillis = (int) Math.min(msg.when - now, Integer.MAX_VALUE); } else { // Got a message. mBlocked = false; if (prevMsg != null) { prevMsg.next = msg.next; } else { mMessages = msg.next; } msg.next = null; if (DEBUG) Log.v(TAG, \"Returning message: \" + msg); msg.markInUse(); return msg; } } else { // No more messages. nextPollTimeoutMillis = -1; } // Process the quit message now that all pending messages have been handled. if (mQuitting) { dispose(); return null; } // If first time idle, then get the number of idlers to run. // Idle handles only run if the queue is empty or if the first message // in the queue (possibly a barrier) is due to be handled in the future. if (pendingIdleHandlerCount \u003c 0 \u0026\u0026 (mMessages == null || now \u003c mMessages.when)) { pendingIdleHandlerCount = mIdleHandlers.size(); } if (pendingIdleHandlerCount \u003c= 0) { // No idle handlers to run. Loop and wait some more. mBlocked = true; continue; } if (mPendingIdleHandlers == null) { mPendingIdleHandlers = new IdleHandler[Math.max(pendingIdleHandlerCount, 4)]; } mPendingIdleHandlers = mIdleHandlers.toArray(mPendingIdleHandlers); } // Run the idle handlers. // We only ever reach this code block during the first iteration. for (int i = 0; i \u003c pendingIdleHandlerCount; i++) { final IdleHandler idler = mPendingIdleHandlers[i]; mPendingIdleHandlers[i] = null; // release the reference to the handler boolean keep = false; try { keep = idler.queueIdle(); } catch (Throwable t) { Log.wtf(TAG, \"IdleHandler threw exception\", t); } if (!keep) { synchronized (this) { mIdleHandlers.remove(idler); } } } // Reset the idle handler count to 0 so we do not run them again. pendingIdleHandlerCount = 0; // While calling an idle handler, a new message could have been delivered // so go back and look again for a pending message without waiting. nextPollTimeoutMillis = 0; } } 这里稍微记录下这个方法，怎么看这个方法可能都是消息机制在 Java 层相对难以理解的一个。 MessageQueue 通过 next 方法从消息队列中取出 消息执行，","date":"2016-12-17","objectID":"/2016/12/messgaemechanism/:3:0","tags":["Message","Handler","消息机制"],"title":"Android消息机制_Java层","uri":"/2016/12/messgaemechanism/"},{"categories":["Mobile","Android"],"content":"Handler: 看下 Handler 的构造函数 public Handler(Callback callback, boolean async) { if (FIND_POTENTIAL_LEAKS) { final Class\u003c? extends Handler\u003e klass = getClass(); if ((klass.isAnonymousClass() || klass.isMemberClass() || klass.isLocalClass()) \u0026\u0026 (klass.getModifiers() \u0026 Modifier.STATIC) == 0) { Log.w(TAG, \"The following Handler class should be static or leaks might occur: \" + klass.getCanonicalName()); } } mLooper = Looper.myLooper(); if (mLooper == null) { throw new RuntimeException( \"Can't create handler inside thread that has not called Looper.prepare()\"); } mQueue = mLooper.mQueue; mCallback = callback; mAsynchronous = async; } public Handler(Looper looper, Callback callback, boolean async) { mLooper = looper; mQueue = looper.mQueue; mCallback = callback; mAsynchronous = async; } 主要是这两种构造函数，第一种可以可以指定回调函数和消息的处理方式(是否是异步处理)。第二种可以指定 Looper ，回调函数 和消息的处理方式。 上面说到 Looper 的 loop 方法在循环取出消息和处理的时候提到一个 msg.target.dispatchMessage(msg); 分发处理。平时的使用经验让我们知道这个 target 其实是个 Handler 。 所以接下来看下这个 dispatchMessage 分发消息的方法。 public void dispatchMessage(Message msg) { if (msg.callback != null) { handleCallback(msg); } else { if (mCallback != null) { if (mCallback.handleMessage(msg)) { return; } } handleMessage(msg); } } 从代码中可以，假如 Message 有回调的情况下， 优先执行的是 Message 的回调方法。其次，如果没有回调的情况下，检查 Handler 构造的时候是否有设置回调，如果有优先调用这个回调。再次，才会去调用子类覆写的 handleMessage 方法。我们平时使用的时候，常常就是使用的这个再次的方式。 上面有说过消息队列是负责消息的排队的，接下来看下到底是怎么产生消息，怎么进入队列的。 首先看下几个常用的产生消息的方式。 public final Message obtainMessage() { return Message.obtain(this); } public final boolean sendMessage(Message msg) { return sendMessageDelayed(msg, 0); } public final boolean sendEmptyMessage(int what) { return sendEmptyMessageDelayed(what, 0); } public final boolean post(Runnable r) { return sendMessageDelayed(getPostMessage(r), 0); } 平时常用的就这四种种方式产生消息并且发送消息，对于 Message 的 sendToTarget 方法，本质上还是调用的 sendMessage 这个后面再说，这个几个方法最后都会走 sendMessageAtTime 方法。 public boolean sendMessageAtTime(Message msg, long uptimeMillis) { MessageQueue queue = mQueue; if (queue == null) { RuntimeException e = new RuntimeException( this + \" sendMessageAtTime() called with no mQueue\"); Log.w(\"Looper\", e.getMessage(), e); return false; } return enqueueMessage(queue, msg, uptimeMillis); } private boolean enqueueMessage(MessageQueue queue, Message msg, long uptimeMillis) { msg.target = this; if (mAsynchronous) { msg.setAsynchronous(true); } return queue.enqueueMessage(msg, uptimeMillis); } 在 sendMessageAtTime 方法中进行了一些检查，检查是否已经有 MessageQueue ，如果没有则抛出异常， 毕竟 MessageQueue 也是消息机制不可或缺的元素。 检查通过之后就会进入 enqueueMessage 方法， 这个方法中会调用 MessageQueue 的 enqueueMessage 方法将消息添加入队列中(这个方法后面详细再说)，同时会根据构造 Handler 的时候设置的消息处理方式来为 message 设置相应的属性。 从分析中可以看出，Handler 本身没有太多实质性的操作，都是借助于 Meesage ，MessageQueue ，Looper 这个几个类。说明 Handler 只是一个很强的辅助类而已，方便开发者 产生消息-\u003e发送消息-\u003e处理消息。 ","date":"2016-12-17","objectID":"/2016/12/messgaemechanism/:4:0","tags":["Message","Handler","消息机制"],"title":"Android消息机制_Java层","uri":"/2016/12/messgaemechanism/"},{"categories":["Mobile","Android"],"content":"其他: ","date":"2016-12-17","objectID":"/2016/12/messgaemechanism/:5:0","tags":["Message","Handler","消息机制"],"title":"Android消息机制_Java层","uri":"/2016/12/messgaemechanism/"},{"categories":["Mobile","Android"],"content":"IdleHandler: 空闲时处理器，这个只有在 looper 执行消息循环的第一次会执行。 ","date":"2016-12-17","objectID":"/2016/12/messgaemechanism/:5:1","tags":["Message","Handler","消息机制"],"title":"Android消息机制_Java层","uri":"/2016/12/messgaemechanism/"},{"categories":["Mobile","Android"],"content":"Message： 作为消息的封装类，是消息的载体。 public Message() { } public int what; public int arg1; public int arg2; public Object obj; public Messenger replyTo; long when; Handler target; Runnable callback; private static Message sPool; private static final int MAX_POOL_SIZE = 50; 以上是 Message 的构造方法和比较重要的属性。 静态变量 sPool 的数据类型为 Message，通过 next 成员变量，维护一个消息池；静态变量 MAX_POOL_SIZE 代表消息池的可用大小；消息池的默认大小为50。 看下几个比较重要的方法 public static Message obtain() { synchronized (sPoolSync) { if (sPool != null) { Message m = sPool; sPool = m.next; m.next = null; m.flags = 0; // clear in-use flag sPoolSize--; return m; } } return new Message(); } 还有其他几个带参 的 obtain 方法，但是都需要调用这个无参的，可以看到 从静态变量 sPool 中取出一个 Message 即返回，若是 sPool 为空，则新建一个 Message 返回。 public void recycle() { if (isInUse()) { if (gCheckRecycle) { throw new IllegalStateException(\"This message cannot be recycled because it \" + \"is still in use.\"); } return; } recycleUnchecked(); } void recycleUnchecked() { // Mark the message as in use while it remains in the recycled object pool. // Clear out all other details. flags = FLAG_IN_USE; what = 0; arg1 = 0; arg2 = 0; obj = null; replyTo = null; sendingUid = -1; when = 0; target = null; callback = null; data = null; synchronized (sPoolSync) { if (sPoolSize \u003c MAX_POOL_SIZE) { next = sPool; sPool = this; sPoolSize++; } } } 当调用回收方法的时候，就会将当前的消息插入到静态变量 sPool 的头部，实现循环利用。 ","date":"2016-12-17","objectID":"/2016/12/messgaemechanism/:5:2","tags":["Message","Handler","消息机制"],"title":"Android消息机制_Java层","uri":"/2016/12/messgaemechanism/"},{"categories":["Mobile","Android"],"content":"期待 下次总结 Binder 在 Java 层的知识. 感激,非常感激，万分的感激！ 感谢以下的文章以及其作者和翻译的开发者们,排名不分先后 柯元旦 gityuan ","date":"2016-12-17","objectID":"/2016/12/messgaemechanism/:6:0","tags":["Message","Handler","消息机制"],"title":"Android消息机制_Java层","uri":"/2016/12/messgaemechanism/"},{"categories":["Programming","Java"],"content":"概述 本文记录注解 Annotation 的概念和使用. Annotation 注解 ","date":"2016-11-16","objectID":"/2016/11/annotation/:0:0","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2016/11/annotation/"},{"categories":["Programming","Java"],"content":"Why 需要注解 在代码中常有些重复的代码，这些代码纯手工太耗时。可以通过一定的标记，然后处理即可。 ","date":"2016-11-16","objectID":"/2016/11/annotation/:1:0","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2016/11/annotation/"},{"categories":["Programming","Java"],"content":"What 是注解? Annotation 分类 标准 Annotation 包括 Override, Deprecated, SuppressWarnings，是 java 自带的几个注解，他们由编译器来识别，不会进行编译，不影响代码运行。 元 Annotation @Retention, @Target, @Inherited, @Documented，它们是用来定义 Annotation 的 Annotation。也就是当我们要自定义注解时，需要使用它们。 自定义 Annotation 自定义的 Annotation。 ","date":"2016-11-16","objectID":"/2016/11/annotation/:2:0","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2016/11/annotation/"},{"categories":["Programming","Java"],"content":"自定义的注解也分为三类，通过元Annotation - @Retention 定义： @Retention(RetentionPolicy.SOURCE) 源码时注解，一般用来作为编译器标记。如 Override, Deprecated, SuppressWarnings。 @Retention(RetentionPolicy.RUNTIME) 运行时注解，在运行时通过反射去识别的注解，这种注解最大的缺点就是反射消耗性能。 @Retention(RetentionPolicy.CLASS) 编译时注解，在编译时被识别并处理的注解，相当于自动生成代码，没有反射，和正常的手写代码无二。 ","date":"2016-11-16","objectID":"/2016/11/annotation/:2:1","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2016/11/annotation/"},{"categories":["Programming","Java"],"content":"Annotation 的工作原理 APT(Annotation Processing Tool) 根据不同类型的注解，采取不同的处理方式，对于 SOURCE 类型的注解，它只会存在代码中，当进行编译成 class 的时候，就会被抛弃了。 RUNTIME 类型的则一直存到 class 文件中，一直存在虚拟机的运行期。CLASS 类型的注解只存到编译期，会根据 处理器的要求进行处理，生成代码或者其他处理方式，处理完只会，就不会存在了，而如果生成了文件，则会一直存在，被打包。 ","date":"2016-11-16","objectID":"/2016/11/annotation/:3:0","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2016/11/annotation/"},{"categories":["Programming","Java"],"content":"术语解释 Element: 表示一个程序元素，比如包、类或者方法。每个元素都表示一个静态的语言级构造（不表示虚拟机的运行时构造）。 元素应该使用 equals(Object)方法进行比较。不保证总是使用相同的对象表示某个特定的元素。要实现基于 Element 对象类的操作，可以使用 visitor 或者使用 getKind() 方法的结果。使用 instanceof 确定此建模层次结构中某一对象的有效类未必可靠，因为一个实现可以选择让单个对象实现多个 Element 子接口。 在 JDK 1.6 新增的 javax.lang.model 包中定义了16类 Element，包括了 Java 代码中最常用的元素，如：“包（PACKAGE）、枚举（ENUM）、类（CLASS）、注解（ANNOTATION_TYPE）、接口（INTERFACE）、枚举值（ENUM_CONSTANT）、字段（FIELD）、参数（PARAMETER）、本地变量（LOCAL_VARIABLE）、异常（EXCEPTION_PARAMETER）、方法（METHOD）、构造函数（CONSTRUCTOR）、静态语句块（STATIC_INIT，即static{}块）、实例语句块（INSTANCE_INIT，即{}块）、参数化类型（TYPE_PARAMETER，既泛型尖括号内的类型）和未定义的其他语法树节点（OTHER）”。 TypeElement ： TypeElement 表示一个类或接口程序元素。提供对有关类型及其成员的信息的访问。注意，枚举类型是一种类，而注释类型是一种接口. TypeElement 代表了一个 class 或者 interface 的 element 。 DeclaredType 表示一个类或接口类型，后者(DeclaredType)将成为前者(TypeElement)的一种使用（或调用）。这种区别对于一般的类型是最明显的，对于这些类型，单个元素可以定义一系列完整的类型。 例如，元素 java.util.Set 对应于参数化类型 java.util.Set 和 java.util.Set（以及其他许多类型），还对应于原始类型 java.util.Set。 TypeElement,DeclaredType 为什么需要 TypeElement 呢？ TypeElement 表示一个类或接口程序元素,重点它是一个 element ，是类或者接口的 element。 我们知道 element 有多达16种类型，这些 element 形式各异。各有各的特点，TypeElement 表示的是类或者接口，对于类或者接口，他有很多独有的信息，比如全路径名，超类等等，而对于 method 就没有这个，方法也有个特有的 element ExecutableElement，出现的原因就同理可得了。 为什么需要 DeclaredType 呢？ DeclaredType 表示一个类或接口类型，重点它是一个具体的类型。 DeclaredType 有个方法，asElement()方法，这个方法返回的是一个 element，通过这个方法我们就可以获取一些作为 element 才能获取的信息。比如 MirroredTypeException 异常会携带回 TypeMirror，可以强制转换成 DeclaredType，就可以获取一些信息。 根据目前已有的数据和自身的理解。 TypeMirror typeMirror = element.asType(); DeclaredType declaredType = (DeclaredType) typeMirror; messager.printMessage(Diagnostic.Kind.NOTE, \"Annotation class : typeMirror instanceof DeclaredType = \" + (typeMirror instanceof DeclaredType)); // 这里的输出为 true 这也就解释了为什么 oracle 文档上说的前者调用后者的意思。 ","date":"2016-11-16","objectID":"/2016/11/annotation/:3:1","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2016/11/annotation/"},{"categories":["Programming","Java"],"content":"How 使用，自定义注解 前提：自定义注解一定要是 Java library，不能用 Android library。 IDE： AS 新建一个 Android Project 插件：此外我们还需要另外一个库，这个库是为了在 Android 上只用注解而使用的: android-apt。 这个插件可以自动的帮你为生成的代码创建目录, 让生成的代码编译到APK 里面去, 而且它还可以让最终编译出来的APK里面不包含注解处理器本身的代码。 允许配置只在编译时作为注解处理器的依赖，而不添加到最后的 APK 或 library 设置源路径，使注解处理器生成的代码能被 Android Studio 正确的引用 ","date":"2016-11-16","objectID":"/2016/11/annotation/:4:0","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2016/11/annotation/"},{"categories":["Programming","Java"],"content":"编译时注解 对于编译时注解，在编译项目之前执行的代码，可以生成代码或者生成其他文件，生成的文件将会被打包进项目，但是之前的注解将会被删除，不会进入 class 文件。 传统方式 新建一个 Java module，设置该 module 的 gradle 文件 apply plugin: 'java' dependencies { compile fileTree(dir: 'libs', include: ['*.jar']) } sourceCompatibility = \"1.7\" targetCompatibility = \"1.7\" 同时设置 project 的 gradle buildscript { repositories { jcenter() } dependencies { classpath 'com.android.tools.build:gradle:2.2.2' classpath 'com.neenbedankt.gradle.plugins:android-apt:1.8' } } 新建一个注解 NameGenerate @Retention(RetentionPolicy.CLASS) public @interface NameGenerate { } 接下来就是重点了，需要编写注解的处理器 public class NameGenerateProcessor extends AbstractProcessor { public static final String CLASSNAME = \"NameGeneateList\"; public static final String PACKAGENAME = \"com.lvmama.router\"; @Override public boolean process(Set\u003c? extends TypeElement\u003e annotations, RoundEnvironment env) { Messager messager = processingEnv.getMessager(); try { // 以新建文件的文件名为参数新建一个 JavaFileObject 对象 JavaFileObject f = processingEnv.getFiler().createSourceFile(CLASSNAME); Writer w = f.openWriter(); PrintWriter pw = new PrintWriter(w); // 将新建文件的内容就以拼接的方式输入即可。 pw.println(\"package \" + PACKAGENAME + \";\"); pw.println(\"\\npublic class \" + CLASSNAME + \" { \"); for (Element element : env.getElementsAnnotatedWith(NameGenerate.class)) { PackageElement packageElement = (PackageElement) element.getEnclosingElement(); String packageName = packageElement.getQualifiedName().toString(); TypeElement classElement = (TypeElement) element; String className = classElement.getSimpleName().toString(); String fullClassName = classElement.getQualifiedName().toString(); pw.print(\"public String \" + className + \"=\\\"\" + fullClassName + \"\\\";\"); } pw.println(\"}\"); pw.flush(); pw.close(); } catch (IOException x) { processingEnv.getMessager().printMessage(Diagnostic.Kind.ERROR, x.toString()); } return true; } @Override public Set\u003cString\u003e getSupportedAnnotationTypes() { Set\u003cString\u003e types = new LinkedHashSet\u003c\u003e(); types.add(NameGenerate.class.getCanonicalName()); return types; } } ","date":"2016-11-16","objectID":"/2016/11/annotation/:4:1","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2016/11/annotation/"},{"categories":["Programming","Java"],"content":"关键方法 process 解释 public boolean process(Set\u003c? extends TypeElement\u003e annotations, RoundEnvironment roundEnv) { // annotations 当前注解器需要处理的注解的集合 // roundEnv 可以用来访问当前的 Round 中的语法树的节点，每个语法树中的节点都表示为一个 element。 } “processingEnv” 它是 AbstractProcessor 中的一个 protected 变量，在注解处理器初始化的时候（init（）方法执行的时候）创建，继承了 AbstractProcessor 的注解处理器代码可以直接访问到它。它代表了注解处理器框架提供的一个上下文环境，要创建新的代码、向编译器输出信息、获取其他工具类等都需要用到这个实例变量。 @SupportedAnnotationTypes 和 @SupportedSourceVersion 前者代表了这个注解处理器对哪些注解感兴趣，可以使用星号“*”作为通配符代表对所有的注解都感兴趣，后者指出这个注解处理器可以处理哪些版本的 Java 代码。 方法返回值的含义 每一个注解处理器在运行的时候都是单例的，如果不需要改变或生成语法树的内容，process（）方法就可以返回一个值为 false 的布尔值，通知编译器这个 Round 中的代码未发生变化，无须构造新的 JavaCompiler 实例。 ","date":"2016-11-16","objectID":"/2016/11/annotation/:4:2","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2016/11/annotation/"},{"categories":["Programming","Java"],"content":"对于注解循环引起的错误的解释 不做任何处理，直接运行上面的程序的话，就会在控制台输出一个错误。 Attempt to recreate a file for type com.steve.RouterList * 此处解释引用自《深入Java虚拟机_JVM高级特性与最佳实践》P307。 将插入式注解处理器看做一个插件，如果这些插件在处理注解期间对语法树进行了修改，编译器将回到解析及填充符号表的过程重新处理，直到所有插入式注解处理器都没有再对语法树进行修改为止，每一次的循环称为一个 round。 注册处理器 在 src/main 目录下，新建一个和 Java 文件夹平级的文件夹 “resources”, 在 resources 文件夹下新建 META-INF 文件夹，在 META-INF 文件夹下新建 services 文件夹， 在 services 文件夹下新建 javax.annotation.processing.Processor 文件，文件夹的内容就是刚刚编写的处理的全路径名，例如 com.steve.NameGenerateProcessor 使用 有两种方式，一是直接在 gradle 中依赖 注解项目。 dependencies { compile fileTree(dir: 'libs', include: ['*.jar']) compile project(':lib_processor') } 另外一种方式就是直接将注解的项目打出 jar 文件，让 app 依赖这个 jar 文件。 build app 项目，就会生成对应的文件。文件的路径:\\app\\build\\generated\\source\\apt\\debug 想在代码中使用生成的 java 文件很简单，像正常自己写的文件一样，直接引用即可。 借助 Google 和 square 的库 传统的方式，过程比较繁琐，借助 Google 的 auto-service 和 square 的 javapoet 可以省一些事。 Auto 用来注解 Processor 类，生成对应的 META-INF 的配置信息，省去注册处理器这一步，只要在自定义的 Processor 上面加上 @AutoService(Processor.class) javapoet 只是一个方便生成代码的一个库，比起简单的字符串拼接，这个看上去更加友好。 总体来说，和传统的方式区别不大，只是修改编写注解的 module 的依赖即可。 修改 Processor 所在 Java module 的 gradle 依赖。 apply plugin: 'java' dependencies { compile fileTree(dir: 'libs', include: ['*.jar']) compile 'com.google.auto.service:auto-service:1.0-rc2' compile 'com.squareup:javapoet:1.7.0' } sourceCompatibility = \"1.7\" targetCompatibility = \"1.7\" 借助 javapoet 生成 Java 代码 有一点需要说清楚，在 AndroidStudio 中用 javapoet 有问题，并不能完全的支持。这个 jake 在 github 上有解释 。如果想要完整的使用，最好能使用 intellij idea。 所以这里我们切换到 intellij idea 去开发。 重点还是在注解处理器的处理 需要注意一点的时，即使在注解处理这个看似特别的程序上，依旧是个 Java 程序，也就必然符合面向对象的原则。我将每个注解我需要的信息封装成一个对象，交给一个工具类，由工具类统一完成代码的生成。 public class NameGenerateAnnotatedClass { private TypeElement annotatedClassElement; private String packageName; private String className; public NameGenerateAnnotatedClass(TypeElement annotatedClassElement) { this.annotatedClassElement = annotatedClassElement; className = annotatedClassElement.getSimpleName().toString(); packageName = annotatedClassElement.getQualifiedName().toString(); } public String getPackageName() { return packageName; } public String getClassName() { return className; } } 这个类很简单，就单纯的记录了每个被注解元素的类名和包名，因为待会儿我自动生成的代码，我只需要这个两样。 public class ProcessorUtil { public static final String CLASSNAME = \"RouterList\"; public static final String PACKAGENAME = \"com.lvmama.router\"; public ProcessorUtil(Messager messager) { this.messager = messager; } private Messager messager; private ArrayList\u003cNameGenerateAnnotatedClass\u003e list = new ArrayList\u003c\u003e(); private void error(Element e, String msg, Object... args) { messager.printMessage(Diagnostic.Kind.ERROR, String.format(msg, args), e); } public void generateCode() { TypeSpec.Builder builder = TypeSpec.classBuilder(CLASSNAME).addModifiers(Modifier.PUBLIC); for (NameGenerateAnnotatedClass annotatedClass : list) { FieldSpec fieldSpec = FieldSpec.builder(String.class, annotatedClass.getClassName()) .addModifiers(Modifier.PUBLIC, Modifier.STATIC, Modifier.FINAL) .initializer(\"$S\", annotatedClass.getPackageName()) .build(); builder.addField(fieldSpec); } TypeSpec typeSpec = builder.build(); JavaFile.Builder javaFileBuilder = JavaFile.builder(PACKAGENAME, typeSpec); JavaFile javaFile = javaFileBuilder.build(); try { // javaFile.writeTo(System.out); //输出到控制台 javaFile.writeTo(filer); //输出到默认的目录 } catch (IOException e) { e.printStackTrace(); } } public void addNameGenerateAnnotatedClass(NameGenerateAnnotatedClass item) { list.add(item); } public void clear() { list.clear(); } } 这个类是负责生成代码的，在获取到每个被注解的元素的时候，都会添加到这个类的 list 中，在 generateCode() 方法中生成的代码。 这里用的就是 javapoet 来生成的代码。 TypeSpec 代表的是一个类。 FieldSpec 代表了一个类中的字段。 JavaFile 代表了一个 Java 文件。 javaFile.writeTo 就是将我们自身组装的这些元素输出，javaFile.writeTo(System.out); 是输出到控制台。 javaFile.writeTo(filer); 输出到默认的目录下。 和传统方式一样，运行 build 命令，在生成的目录下就可以看到生成的文件。 ","date":"2016-11-16","objectID":"/2016/11/annotation/:4:3","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2016/11/annotation/"},{"categories":["Programming","Java"],"content":"运行时注解 对于运行时注解都是通过反射来实现的。 ","date":"2016-11-16","objectID":"/2016/11/annotation/:4:4","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2016/11/annotation/"},{"categories":["Programming","Java"],"content":"源码注解 ","date":"2016-11-16","objectID":"/2016/11/annotation/:4:5","tags":["Annotation"],"title":"Annotation 使用备忘","uri":"/2016/11/annotation/"},{"categories":["Tool","Editor"],"content":"概述 本文记录 Markdown 写作时常用的一些语法. Why 平时人们都会进行一些简单的笔记记录，这些文字如果用 Word 就会感觉太复杂，用 txt 又显得单薄，一点格式都没有，不利于书写。自然人们希望有一种方法，能消除这两个缺点的方法，既能有常用的格式，又能方便记忆，简单快捷. Markdown 是满足这种需要的，所以记录总结一些常用的 Markdown 符号，方便记忆. What Markdown 是一种轻量级的「标记语言」，Markdown 简单快捷，导出格式也随心所欲，你可以导出 HTML 格式的文件用来网站发布，也可以十分方便的导出 PDF 格式，方便阅读。 How ","date":"2016-10-17","objectID":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/:0:0","tags":["Markdown"],"title":"Markdown 常用语法","uri":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/"},{"categories":["Tool","Editor"],"content":"1. 标题级别的 语法： # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 ###### 六级标题 标题的级别根据#的个数来区分。正常的文本内容不需要取管，直接输入即可。 效果: 一级标题 ","date":"2016-10-17","objectID":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/:1:0","tags":["Markdown"],"title":"Markdown 常用语法","uri":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/"},{"categories":["Tool","Editor"],"content":"二级标题 ","date":"2016-10-17","objectID":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/:2:0","tags":["Markdown"],"title":"Markdown 常用语法","uri":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/"},{"categories":["Tool","Editor"],"content":"三级标题 四级标题 五级标题 六级标题 ","date":"2016-10-17","objectID":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/:2:1","tags":["Markdown"],"title":"Markdown 常用语法","uri":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/"},{"categories":["Tool","Editor"],"content":"2. 序列效果 无序序列语法： * 包含的要点 * 包含的要点 - 包含的要点 - 包含的要点 无序序列效果: 包含的要点 包含的要点 包含的要点 包含的要点 有序序列语法： \\1. 第一点 \\2. 第二点 \\1. 第三点 无序序列效果: 第一点 第二点 第三点 对于想输入一些知识点的结构的情况，需要以列表的形式展示的时候，可以采用这种标记。可以根据具体的情况才有无序的列表和有序的列表。 对于无序的情况，可以输入“-”也可以输入“*”，都可以。对于有序的情况，输入对于的数字加上英文符号的点，加上空格，紧跟文本内容。其中的数字可以随意,解析的时候自动累加哪怕都写的1，根据具体的解析平台可能存在差异，故而最好能按照顺序写这个数字。 ","date":"2016-10-17","objectID":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/:3:0","tags":["Markdown"],"title":"Markdown 常用语法","uri":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/"},{"categories":["Tool","Editor"],"content":"3. 强调文字 斜体语法: *斜体文字,加载这两个星花之间都将以斜体的形式展现* 斜体效果: 斜体文字,加载这两个星花之间都将以斜体的形式展现 加粗语法: *需要加粗的文字写在这里* 加粗效果: 需要加粗的文字写在这里 文本中需要加粗来强调的内容和需要以斜体展示的内容，用星号包裹，区别就是星号的个数。 ","date":"2016-10-17","objectID":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/:4:0","tags":["Markdown"],"title":"Markdown 常用语法","uri":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/"},{"categories":["Tool","Editor"],"content":"4. 引用内容 引用语法: \u003e 引用的内容，对于一些需要标注了引用了别人的信息的情况下需要以这种形式展示，可以写在这个大于号的后面即可。 引用效果: 引用的内容，对于一些需要标注了引用了别人的信息的情况下需要以这种形式展示，可以写在这个大于号的后面即可。 ","date":"2016-10-17","objectID":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/:5:0","tags":["Markdown"],"title":"Markdown 常用语法","uri":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/"},{"categories":["Tool","Editor"],"content":"5. 超链接 超链接语法: [展示的文本]( www.baidu.com ) 超链接效果: 展示的文本 对于文本需要有超链接的情况下，可以采用这种方式。 ","date":"2016-10-17","objectID":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/:6:0","tags":["Markdown"],"title":"Markdown 常用语法","uri":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/"},{"categories":["Tool","Editor"],"content":"6. 引用外部图片 引用外部图片语法: ![图片说明展示的文本](http://pic.lvmama.com/img/v6/lv_jbr.png) 引用外部图片效果: 引用外部图片外加超链接语法: [![图片说明展示的文本](http://pic.lvmama.com/img/v6/lv_jbr.png)](http://www.lvmama.com) 引用外部图片外加超链接效果: ","date":"2016-10-17","objectID":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/:7:0","tags":["Markdown"],"title":"Markdown 常用语法","uri":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/"},{"categories":["Tool","Editor"],"content":"7. 分割线 分割线语法: \\ —- \\ **** 三个横线和三个星号都表示分割线 分割线效果： 横线分割线 星号分割线 分割线可以用来分割段落和大的模块内容。 ","date":"2016-10-17","objectID":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/:8:0","tags":["Markdown"],"title":"Markdown 常用语法","uri":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/"},{"categories":["Tool","Editor"],"content":"8. 表格 表格语法： | tab1 tab2 tab3 内容1 内容2 内容3 表格效果： tab1 tab2 tab3 内容1 内容2 内容3 用竖直的线和减号进行标示，就可以插入一个简单的表格。 ","date":"2016-10-17","objectID":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/:9:0","tags":["Markdown"],"title":"Markdown 常用语法","uri":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/"},{"categories":["Tool","Editor"],"content":"9. 引入代码块 引入代码的语法： ```java public class MainActivity extends Activity{ protected void onCreate(Bundle save){ } } ``` 引入代码的效果： public class MainActivity extends Activity{ protected void onCreate(Bundle save){ } } ","date":"2016-10-17","objectID":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/:10:0","tags":["Markdown"],"title":"Markdown 常用语法","uri":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/"},{"categories":["Tool","Editor"],"content":"对于想输入代码的时候，直接替换上面的java 即可实现代码的高亮。 ","date":"2016-10-17","objectID":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/:11:0","tags":["Markdown"],"title":"Markdown 常用语法","uri":"/2016/10/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/"},{"categories":["Tool","Git"],"content":"概述 本文记录常用 git 的功能和命令. Git实践笔记 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:0:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"Why 一年多前一边工作一边学,做的笔记,后来换了工作,改用SVN,git也就生疏了,最近公司打算换git了,正好重新整理一下笔记. ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:1:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"What git是目前最好的版本控制工具,是一种动态异步的版本控制工具,对于版本控制的发展历程,可以参考别的文章.目前各个开源管理平台基本上都是用的git,git是必备的技能. ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:2:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"简介 Linus花了两周时间自己用C写了一个分布式版本控制系统，这就是Git!大写的牛逼!一个月之内，Linux系统的源码已经由Git管理了! 起初的git只能在linux和Unix上运行。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:3:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"安装git 在Linux上安装Git 命令行下输入,sudo apt-get install git,直接安装. 在Windows上安装 从http://msysgit.github.io/下载。 在bash下输入以下命令，设置账号和邮箱。是全局的，在之后的所有git操作，都是以这个账号. $ git config --global user.name \"Your Name\" $ git config --global user.email \"email@example.com\" ** 注意：** git config命令的–global参数，用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然也可以对某个仓库指定不同的用户名和Email地址。 $ git config --global --list查看当前的所有设置清单列表。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:4:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"创建版本库（repository） 如果你使用Windows系统，为了避免遇到各种莫名其妙的问题，请确保目录名（包括父目录）不包含中文。 一共三步：初始化，添加文件，提交 $ git init $ git add readme.txt $ git commit -m \"提交的信息\" ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:5:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"查看仓库的修改状态 $ git status 这个命令会告诉我们修改了哪些文件，在知道了修改的文件之后，通过 $ git diff readme.txt 这个命令可以查看修改的具体内容。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:6:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"版本回退： 每当你觉得文件修改到一定程度的时候，就可以“保存一个快照”，这个快照在Git中被称为 commit。一旦你把文件改乱了，或者误删了文件，还可以从最近的一个commit恢复，然后继续工作。版本控制系统肯定有某个命令可以告诉我们历史记录，在Git中，我们用git log命令查看。 $ git log $ git log --pretty=oneline $ git reset --hard HEAD^（表示head指向回退到上一个版本） $ cat readme.txt $ git reset --hard 3628164 Git的版本回退速度非常快，因为Git在内部有个指向当前版本的HEAD指针，当你回退版本的时候，Git仅仅是把HEAD从指向改变了。然后顺便把工作区的文件更新了。所以你让HEAD指向哪个版本号，你就把当前版本定位在哪。 找不到新版本的commit id怎么办？ $ git reflog 总之： HEAD指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令git reset –hard commit_id。 穿梭前，用git log可以查看提交历史，以便确定要回退到哪个版本。 要重返未来，用git reflog查看命令历史，以便确定要回到未来的哪个版本。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:7:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"工作区和暂存区： 工作区：就是在电脑上能看到的目录；一般就是项目文件的根目录； 版本库：工作区有一个隐藏目录.git文件夹，属于仓库文件，不属于工作区，是Git的版本库； Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 把文件往Git版本库里添加的时候，是分两步执行的： 第一步是用git add把文件从工作区添加到暂存区，实际上就是把文件修改添加到暂存区； 第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:8:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"管理修改： 工作区的内容，必须add到暂存区以后才会在提交的时候被提交到库里。每次修改，如果不add到暂存区，那就不会加入到commit中 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:8:1","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"撤销修改： git checkout – file可以丢弃工作区的修改.把file文件在工作区的修改全部撤销，这里有两种情况： 一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态； 一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。 总之，就是让这个文件回到最近一次git commit或git add时的状态。 git reset HEAD file可以把暂存区的修改撤销掉（unstage），重新放回工作区 git reset命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用HEAD时，表示最新的版本。 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令 git checkout – file。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令 git reset HEAD file，就回到了场景1，第二步按场景1操作。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:8:2","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"删除文件： 在Git中，删除也是一个修改操作 直接在文件管理器中把没用的文件删了，Git知道你删除了文件，因此，工作区和版本库就不一致了，git status命令会立刻告诉你哪些文件被删除了。 用命令git rm删掉，并且git commit，用来从版本库中删除该文件. 用命令git checkout – file ，这样实现用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:8:3","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"远程仓库 生成公私密钥：$ ssh-keygen -t rsa -C “youremail@example.com ” 在用户目录下有.ssh目录，id_rsa和id_rsa.pub这两个文件。 id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:9:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"添加远程库 在github上新建一个仓库。 GitHub告诉我们，可以从这个仓库克隆出新的仓库，也可以把一个已有的本地仓库与之关联，然后，把本地仓库的内容推送到GitHub仓库。 $ git remote add origin git@github.com:tinggengyan/study.git 添加后，远程库的名字就是origin，这是Git默认的叫法，也可以改成别的，但是origin这个名字一看就知道是远程库。 下一步，就可以把本地库的所有内容推送到远程库上： $ git push -u origin master,把本地库的内容推送到远程，用git push命令，实际上是把当前分支master推送到远程。 由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送到远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。 从现在起，只要本地作了提交，就可以通过命令： $ git push origin master ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:10:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"小结 要关联一个远程库，使用命令 git remote add origin git@server-name:path/repo-name.git 关联后，使用命令git push -u origin master第一次推送master分支的所有内容；此后，每次本地提交后，只要有必要，就可以使用命令git push origin master推送最新修改； ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:10:1","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"远程克隆 git clone git@github.com :michaelliao/gitskills.git ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:11:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"分支创建与合并 Git里，有个分支叫主分支，即master分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。 Git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点。 当我们创建新的分支，例如dev时，Git新建了一个指针叫dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上。 当创建一个新的分支的时候，新分支的指针和旧的指针指向是同一个，同时将head的指向修改到当前的新分支的指针上，之后提交就可以提交到新的分支了。 当在新的分支上将工作完成之后，只要合并这两个分支就可以了，简单的就是讲master指向新的分支的指向。然后删除旧的分支的指针即可。 $ git checkout -b dev==={$ git branch dev；$ git checkout dev}创建一个Dev分支并切换到Dev分支。 $ git branch查看当前的分支。git branch命令会列出所有分支，当前分支前面会标一个*号。 $ git merge dev 命令用于将当前的分支和dev分支合并。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:12:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"变基操作 对于merge操作，会合并两个分支，并且产生一个新的提交，这对于整体的 log 查看并不美观。 $ git checkout experiment $ git rebase master $ git checkout master $ git merge experiment 它的原理是首先找到这两个分支（即当前分支 experiment、变基操作的目标基底分支 master）的最近共同祖先，然后对比当前分支相对于该祖先的历次提交， 提取相应的修改并存为临时文件，然后将当前分支指向目标基底, 最后以此将之前另存为临时文件的修改依序应用。 一般我们这样做的目的是为了确保在向远程分支推送时能保持提交历史的整洁才需要这么做。 $ git rebase --onto master server client 以上命令的意思是：“取出 client 分支，找出处于 client 分支和 server 分支的共同祖先之后的修改，然后把它们在 master 分支上重演一遍”。 $ git checkout master $ git merge client 切换到master分支进行合并。 $ git rebase master server 这样就可以省的切换到sever分支，直接指定rebase。 $ git checkout master $ git merge server 快速合并。 Git鼓励大量使用分支： 查看分支：git branch 创建分支：git branch 切换分支：git checkout 创建+切换分支：git checkout -b 合并某分支到当前分支：git merge 删除分支：git branch -d ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:13:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"冲突处理 Git用 \u003c\u003c\u003c\u003c\u003c\u003c\u003c，=======，\u003e\u003e\u003e\u003e\u003e\u003e\u003e 标记出不同分支的内容，通过status命令，找到冲突的内容，手动修改，处理之后，再重新提交. 用 git log --graph --pretty=oneline --abbrev-commit 命令，查看一下分支合并. https://app.yinxiang.com/Home.action#n=f311ba79-a871-47a5-bea1-0fbcb2277ea8\u0026b=403e83c5-7d1d-4991-bc1b-9a6d80235d0b\u0026ses=4\u0026sh=1\u0026sds=5\u0026 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:14:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"分支管理策略： 合并分支时，如果可能，Git会用Fast forward模式，但这种模式下，删除分支后，会丢掉分支信息。 如果要强制禁用Fast forward模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。 git merge --no-ff 方式就能实现禁用fast forward模式。 策略： 首先，master分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活；那在哪干活呢？干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本；你和你的小伙伴们每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以了。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:15:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"Bug分支： 当出现bug的时候需要修复BUG，但是此时的工作区还有文件没有提交，此时的文件又不能提交，此时可以使用git的暂存功能。Git还提供了一个stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作。 执行完stash之后的工作区就是一个干净的工作区。 git stash list 可以查看储藏的内容列表。接着就是恢复储藏的现场。 有两个办法： 一是用git stash apply恢复，但是恢复后，stash内容并不删除，你需要用 git stash drop来删除； 另一种方式是用git stash pop，恢复的同时把stash内容也删了： 可以多次stash，恢复的时候，先用 git stash list 查看，然后恢复指定的stash，用命令： $git stash apply stash@{0} ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:15:1","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"feature分支： 新增一个功能的生活，最好新建一个分支，之后再合并。没有和和分支在删除的时候，git会给出友情提醒，所以删除的时候，需要使用git branch -D 强行删除。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:15:2","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"多人协作开发： 当你从远程仓库克隆时，实际上Git自动把本地的master分支和远程的master分支对应起来了，并且，远程仓库的默认名称是origin。要查看远程库的信息，用 git remote； 用git remote -v显示更详细的信息； $ git remote -v origin git@github.com:michaelliao/learngit.git (fetch) origin git@github.com:michaelliao/learngit.git (push) 显示了可以抓取和推送的origin的地址。如果没有推送权限，就看不到push的地址。 推送分支 推送分支，就是把该分支上的所有本地提交推送到远程库。 推送时，要指定本地分支，这样，Git就会把该分支推送到远程库对应的远程分支上： $ git push origin master 把master分支推送。 $ git push origin dev 把dev分支进行推送。 在Git中，分支完全可以在本地自己藏着玩，是否推送，视你的心情而定！ ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:15:3","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"抓取分支 git pull把最新的提交从origin下相应的分支抓下来。 因此，多人协作的工作模式通常是这样： 首先，可以试图用git push origin branch-name推送自己的修改；如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并；如果合并有冲突，则解决冲突，并在本地提交；没有冲突或者解决掉冲突后，再用git push origin branch-name推送就能成功！如果git pull提示“no tracking information”，则说明本地分支和远程分支的链接关系没有创建，用命令 git branch –set-upstream branch-name origin/branch-name。 小结 查看远程库信息，使用git remote -v； 本地新建的分支如果不推送到远程，对其他人就是不可见的； 从本地推送分支，使用git push origin branch-name，如果推送失败，先用git pull抓取远程的新提交； 在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称最好一致； 建立本地分支和远程分支的关联，使用git branch –set-upstream branch-name origin/branch-name； 从远程抓取分支，使用git pull，如果有冲突，要先处理冲突。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:15:4","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"标签管理 发布一个版本时，我们通常先在版本库中打一个标签，这样，就唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以，标签也是版本库的一个快照。Git的标签虽然是版本库的快照，但其实它就是指向某个commit的指针（跟分支很像对不对？但是分支可以移动，标签不能移动），所以，创建和删除标签都是瞬间完成的。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:16:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"创建标签 git tag 就可以打一个新标签； git tag 查看所有标签； 默认标签是打在最新提交的commit上的。有时候，如果忘了打标签，可以通过 $ git log --pretty=oneline --abbrev-commit 找到历史提交的commit id。 $ git tag tagname commit id来为历史提交打上tag。 git show \u003ctagname\u003e查看标签信息. 还可以创建带有说明的标签，用-a指定标签名，-m指定说明文字： 比如： $ git tag -a v0.1 -m \"version 0.1 released\" 3628164 小结 命令git tag 用于新建一个标签，默认为HEAD，也可以指定一个commit id； git tag -a -m “blablabla…“可以指定标签信息； git tag -s -m “blablabla…“可以用PGP签名标签； 命令git tag可以查看所有标签。 操作标签 命令git push origin 可以推送一个本地标签； 命令git push origin –tags可以推送全部未推送过的本地标签； 命令git tag -d 可以删除一个本地标签； 先在本地删除一个标签，再命令git push origin :refs/tags/可以删除一个远程标签。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:16:1","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"忽略特殊文件 忽略某些文件时，需要编写.gitignore；.gitignore文件本身要放到版本库里，并且可以对.gitignore做版本管理！ ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:17:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"配置别名 $ git config --global alias.st status 是在全局，整个电脑上的所有仓库都使用st来表示status。执行 git st=git status. 加上*–global*是针对当前用户起作用的，如果不加，那只针对当前的仓库起作用。 单个仓库的Git配置文件都放在.git/config文件中。 当前用户的Git配置文件放在用户主目录下的一个隐藏文件.gitconfig中。 别名就在[alias]后面，要删除别名，直接把对应的行删掉即可。 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:18:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"搭建git服务器 后加. ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:19:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Tool","Git"],"content":"感激,非常感激，万分的感激！ 感谢以下的文章以及其作者和翻译的开发者们,排名不分先后 Pro Git Git教程 - 廖雪峰的官方网站 ","date":"2016-10-15","objectID":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/:20:0","tags":["Git"],"title":"git实践笔记","uri":"/2016/10/git%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"},{"categories":["Mobile","Android"],"content":"序 本篇分析大头鬼的 JsBridge 库. ","date":"2016-10-13","objectID":"/2016/10/jsbridge%E5%88%86%E6%9E%90/:0:0","tags":["JsBridge"],"title":"JsBridge分析","uri":"/2016/10/jsbridge%E5%88%86%E6%9E%90/"},{"categories":["Mobile","Android"],"content":"js bridge 分析大头鬼的 JS 库 主要的任务都交给了 JS 库去执行，整个框架的主要过程分为三个过程，native 通过发送消息调用 JS 方法，在 JS 层的消息处理,将消息处理完成之后返回。 ","date":"2016-10-13","objectID":"/2016/10/jsbridge%E5%88%86%E6%9E%90/:1:0","tags":["JsBridge"],"title":"JsBridge分析","uri":"/2016/10/jsbridge%E5%88%86%E6%9E%90/"},{"categories":["Mobile","Android"],"content":"Java调用JS 方法 对于 native 想要调用 JS 代码的时候，会调用自定义的 BridgeWebView 的 send 方法进行发送消息，对于消息，我们可以自定义处理器和回调处理方法，发出去的消息不是立即处理的，而是将其进行封装，成 Message 对象，如果该消息后续有回调，需要记录回调等待后续的处理，而后添加到队列中。进行排队，等待处理。 ","date":"2016-10-13","objectID":"/2016/10/jsbridge%E5%88%86%E6%9E%90/:1:1","tags":["JsBridge"],"title":"JsBridge分析","uri":"/2016/10/jsbridge%E5%88%86%E6%9E%90/"},{"categories":["Mobile","Android"],"content":"Java 消息的分发 这个消息的分发是指的 native 层面的消息分发，当页面加载 finish 之后，会调用 dispatch 方法对刚刚进入队列中的 Message 对象进行分发。解析出 Message 携带的内容，按照约定，生成对应的 JS 脚本，交由 JS 库处理。 ","date":"2016-10-13","objectID":"/2016/10/jsbridge%E5%88%86%E6%9E%90/:1:2","tags":["JsBridge"],"title":"JsBridge分析","uri":"/2016/10/jsbridge%E5%88%86%E6%9E%90/"},{"categories":["Mobile","Android"],"content":"加载 JS 库 按照流程的事件顺序上讲，这个过程应该是第一个被执行的，在加载完 HTML 页面的同时需要加载 JS 库，但是 JS 库的加载和页面的加载谁先成功，这个可能出现先后差异，所以需要在 HTML 中判断 JS 库是否加载成功，如果加载成功则进行消息处理；如果加载还未成功，则监听加载 JS 库的事件，等到加载成功之后，再进行消息的处理。这些事件的处理需要在 HTML 中处理. ","date":"2016-10-13","objectID":"/2016/10/jsbridge%E5%88%86%E6%9E%90/:1:3","tags":["JsBridge"],"title":"JsBridge分析","uri":"/2016/10/jsbridge%E5%88%86%E6%9E%90/"},{"categories":["Mobile","Android"],"content":"JS 库对消息的处理 这里处理的其实是一个 URL ，在 JS 库层面会调用相应的 JS 方法。当 Java 层调用了消息的分发命令，会通过执行 JS 脚本的方式将消息交给 JS 层，JS 层面会将需要处理的消息，添加到队列中，等待处理，这个过程又有点像 Java 层的处理方式，_handleMessageFromNative ，会将消息存入 receiveMessageQueue 中，等待处理。 当 JS 库加载成功，需要 HTML 层面可以主动的调用JS层的消息处理的方法 _dispatchMessageFromNative，遍历 receiveMessageQueue，对消息进行处理。 对于消息的业务处理，都在 JS 层面完成，JS 处理完成之后，如果有需要进行为 Java 层提供返回值的，则进行重定向，通知 Java 层返回值队列中有数据，Java 层拦截 URL 进行主动拉去数据的 JS 脚本执行，JS 层方法将返回值放入 URL 中，进行重定向，Java 层会拦截 url，根据一定的规则，从 url 中截取出数据，数据中携带了唯一的请求 ID，根据这个 ID 查找出对应的回调方法。 ","date":"2016-10-13","objectID":"/2016/10/jsbridge%E5%88%86%E6%9E%90/:1:4","tags":["JsBridge"],"title":"JsBridge分析","uri":"/2016/10/jsbridge%E5%88%86%E6%9E%90/"},{"categories":["Mobile","Android"],"content":"JS 向 native 发送消息 当 JS 想主动向 native 发送消息的时候，会主动调用 JS 库中的 send 方法，将消息放入 JS 中的 sendMessageQueue 队列中。然后像给 native 层提供返回值一样，进行 url 的重定向,然后依旧是 Java 层拦截 URL,然后主动去拉取数据。 ","date":"2016-10-13","objectID":"/2016/10/jsbridge%E5%88%86%E6%9E%90/:1:5","tags":["JsBridge"],"title":"JsBridge分析","uri":"/2016/10/jsbridge%E5%88%86%E6%9E%90/"},{"categories":["Mobile","Android"],"content":"native 处理 JS 发来的消息 当 JS 向 native 发出消息,native 收到消息后，解析成 Message 对象，根据 callid 去判断是否有特定的 handler，是否有回调,这些 handler 和 回调都是刚刚封装 Message 对象时保存的。 ","date":"2016-10-13","objectID":"/2016/10/jsbridge%E5%88%86%E6%9E%90/:1:6","tags":["JsBridge"],"title":"JsBridge分析","uri":"/2016/10/jsbridge%E5%88%86%E6%9E%90/"},{"categories":["Mobile","Android"],"content":"怎么使用 对于一般的具体应用，都是 JS 层调用 Java 层提供的方法。这时候，对于平时普通的常规调用，都是需要提前约定的，可以定义在 DefaultHandler 中。也可以根据不同的业务需要定义不同的 BridgeHandler。匿名实现 BridgeHandler 的方式只适合 java 层调用 JS 方法，这种方式不方便维护。 ","date":"2016-10-13","objectID":"/2016/10/jsbridge%E5%88%86%E6%9E%90/:2:0","tags":["JsBridge"],"title":"JsBridge分析","uri":"/2016/10/jsbridge%E5%88%86%E6%9E%90/"},{"categories":["Mobile","Android"],"content":"总结 native 层提供一些基础的方法，类似于分享操作，登录等功能。具体的业务类执行还是交由 JS 层执行，需要 native 协助的功能，以重定向 URL 的方式进行。JS 不直接调用 Java 方法，也就是没有 @JavascriptInterface 注解的方法，所有的约定,包括返回的数据,都在 URL 中。 这里会有一个缺点，虽然 http1.1 中声明 url 是没有长度的限制的，但是一般而言，服务端或者浏览器都有有长度的限制，所以，将所有的数据都通过 URL 来传递还是有不妥之处。 ","date":"2016-10-13","objectID":"/2016/10/jsbridge%E5%88%86%E6%9E%90/:3:0","tags":["JsBridge"],"title":"JsBridge分析","uri":"/2016/10/jsbridge%E5%88%86%E6%9E%90/"},{"categories":["ComputerFoundation","OS"],"content":"概述 本文记录学习 Linux 的记录. 命令 ","date":"2016-10-07","objectID":"/2016/10/linux%E5%AD%A6%E4%B9%A0%E5%A4%87%E5%BF%98/:0:0","tags":["Linux"],"title":"Linux学习备忘","uri":"/2016/10/linux%E5%AD%A6%E4%B9%A0%E5%A4%87%E5%BF%98/"},{"categories":["ComputerFoundation","OS"],"content":"软件安装 ","date":"2016-10-07","objectID":"/2016/10/linux%E5%AD%A6%E4%B9%A0%E5%A4%87%E5%BF%98/:1:0","tags":["Linux"],"title":"Linux学习备忘","uri":"/2016/10/linux%E5%AD%A6%E4%B9%A0%E5%A4%87%E5%BF%98/"},{"categories":["ComputerFoundation","OS"],"content":"deb 文件安装 直接双击,安装,ubuntu 上会自动调用软件管理器安装. ","date":"2016-10-07","objectID":"/2016/10/linux%E5%AD%A6%E4%B9%A0%E5%A4%87%E5%BF%98/:1:1","tags":["Linux"],"title":"Linux学习备忘","uri":"/2016/10/linux%E5%AD%A6%E4%B9%A0%E5%A4%87%E5%BF%98/"},{"categories":["ComputerFoundation","OS"],"content":"zip文件安装 这种是包含了源码的,通过命令解压,设置环境变量. zip zipFileName.zip ","date":"2016-10-07","objectID":"/2016/10/linux%E5%AD%A6%E4%B9%A0%E5%A4%87%E5%BF%98/:1:2","tags":["Linux"],"title":"Linux学习备忘","uri":"/2016/10/linux%E5%AD%A6%E4%B9%A0%E5%A4%87%E5%BF%98/"},{"categories":["ComputerFoundation","OS"],"content":"tar.gz 源代码安装 在终端中进行解压操作; tar -zxvf ****.tar.gz tar -jxvf ****.tar.bz(或bz2) 看是否需要设置环境变量,亦或是有.sh启动文件. 设置环境变量的方法 有三种环境变量的设置方法,一种是临时性的,只在本次的命令行中有效,一种是针对当前用户的,还有一种就是全局性的,针对所有用的. ","date":"2016-10-07","objectID":"/2016/10/linux%E5%AD%A6%E4%B9%A0%E5%A4%87%E5%BF%98/:1:3","tags":["Linux"],"title":"Linux学习备忘","uri":"/2016/10/linux%E5%AD%A6%E4%B9%A0%E5%A4%87%E5%BF%98/"},{"categories":["ComputerFoundation","OS"],"content":"rpm 文件安装 ","date":"2016-10-07","objectID":"/2016/10/linux%E5%AD%A6%E4%B9%A0%E5%A4%87%E5%BF%98/:1:4","tags":["Linux"],"title":"Linux学习备忘","uri":"/2016/10/linux%E5%AD%A6%E4%B9%A0%E5%A4%87%E5%BF%98/"},{"categories":["ComputerFoundation","OS"],"content":"卸载 apt-get autoclean: 如果你的硬盘空间不大的话，可以定期运行这个程序，将已经删除了的软件包的.deb安装文件从硬盘中删除掉。如果你仍然需要硬盘空间的话，可以试试apt-get clean，这会把你已安装的软件包的安装包也删除掉，当然多数情况下这些包没什么用了，因此这是个为硬盘腾地方的好办法。 apt-get clean: 类似上面的命令，但它删除包缓存中的所有包。这是个很好的做法，因为多数情况下这些包没有用了。但如果你是拨号上网的话，就得重新考虑了。 apt-get autoremove: 删除为了满足其他软件包的依赖而安装的，但现在不再需要的软件包。 其它： apt-get remove 软件包名称： 删除已安装的软件包（保留配置文件）。 apt-get –purge remove 软件包名称： 删除已安装包（不保留配置文件)。 ","date":"2016-10-07","objectID":"/2016/10/linux%E5%AD%A6%E4%B9%A0%E5%A4%87%E5%BF%98/:2:0","tags":["Linux"],"title":"Linux学习备忘","uri":"/2016/10/linux%E5%AD%A6%E4%B9%A0%E5%A4%87%E5%BF%98/"},{"categories":["Tool","Gradle"],"content":"概述 本文介绍 AndroidStudio 项目如何如何进行 aar 包依赖. AndroidStudio如何引用aar依赖 ","date":"2016-08-10","objectID":"/2016/08/androidstudio%E5%BC%95%E5%85%A5aar%E4%BE%9D%E8%B5%96/:0:0","tags":["aar"],"title":"AndroidStudio引入AAR依赖","uri":"/2016/08/androidstudio%E5%BC%95%E5%85%A5aar%E4%BE%9D%E8%B5%96/"},{"categories":["Tool","Gradle"],"content":"未成功方案 google 了一圈，网上的方法基本都是以下这种，在 module/build.gradle 文件中添加如下代码.同时将 aar 文件 copy 到 libs 文件夹下. repositories { flatDir { dirs 'libs' } } compile(name:'aarName', ext:'aar') 我尝试了很多次,没有成功. ","date":"2016-08-10","objectID":"/2016/08/androidstudio%E5%BC%95%E5%85%A5aar%E4%BE%9D%E8%B5%96/:1:0","tags":["aar"],"title":"AndroidStudio引入AAR依赖","uri":"/2016/08/androidstudio%E5%BC%95%E5%85%A5aar%E4%BE%9D%E8%B5%96/"},{"categories":["Tool","Gradle"],"content":"亲测有效方案 采用了以下方法成功了,和上面的内容一致,只是位置不一样. project 目录下新建一个目录 aars(名字应该随意),新建的 aars 文件夹是用来存放需要 aar 包的. 在 project 下的 build.gradle 中添加代码. allprojects { repositories { jcenter() //为了添加aar依赖 flatDir { dirs '../aars' } } } 注意: 是在根目录下的 build.gradle 文件中修改,添加的节点是在 allprojects 的 repositories 下. 在需要引用的地方添加引用,格式如下. compile(name:'aarNameWithoutExtention', ext:'aar') 添加依赖,依赖的格式是 aar 包文件的名字(不带后缀),ext 注明后缀即可. 采取如上步骤之后,即可成功添加依赖. ","date":"2016-08-10","objectID":"/2016/08/androidstudio%E5%BC%95%E5%85%A5aar%E4%BE%9D%E8%B5%96/:2:0","tags":["aar"],"title":"AndroidStudio引入AAR依赖","uri":"/2016/08/androidstudio%E5%BC%95%E5%85%A5aar%E4%BE%9D%E8%B5%96/"},{"categories":["Tool","IDE"],"content":"概述 本文记录在 DDMS 如何查看线程的状态,以及状态表达的含义. 使用 DDMS 查看进程中的线程状态 ","date":"2016-07-20","objectID":"/2016/07/ddms-threads/:0:0","tags":["DDMS"],"title":"DDMS_Threads的简单使用","uri":"/2016/07/ddms-threads/"},{"categories":["Tool","IDE"],"content":"简介 DDMS(Dalvik Debug Monitor Service),是 Android 开发的调试工具。 ","date":"2016-07-20","objectID":"/2016/07/ddms-threads/:1:0","tags":["DDMS"],"title":"DDMS_Threads的简单使用","uri":"/2016/07/ddms-threads/"},{"categories":["Tool","IDE"],"content":"如何工作 在 Android 系统中每个应用都是在单独的一个进程中运行，DDMS 可以将一个进程通过 adb 和 IDE 连接，进行调试。 ","date":"2016-07-20","objectID":"/2016/07/ddms-threads/:2:0","tags":["DDMS"],"title":"DDMS_Threads的简单使用","uri":"/2016/07/ddms-threads/"},{"categories":["Tool","IDE"],"content":"面板讲解 ","date":"2016-07-20","objectID":"/2016/07/ddms-threads/:3:0","tags":["DDMS"],"title":"DDMS_Threads的简单使用","uri":"/2016/07/ddms-threads/"},{"categories":["Tool","IDE"],"content":"Threads 在左侧选中想要监控的进程，点击上方左起第五个图标(Update Threads) ,在对应的右侧打开 Threads 面板，就可以看到当前进程中的 线程状态。 字段讲解 ID: 线程ID，是当前进程分配的唯一的线程ID.在 Dalvik 虚拟机中，这些值是从奇数3开始计数。 Tid: Linux 线程 ID， 对于一个进程的主线程而言，这个 ID 对应了进程 ID 。 Status: 该线程在进程中的状态，守护进程(Daemon thread)前面被标记了一个星号 ( * ) 。状态可取的值: running: 正在运行的线程。 sleeping: 休眠的，等待被唤醒的线程。 monitor: 监视，正在等待获取一个监控锁。 wait: 执行了wait方法，释放了对象锁。 native: 正在执行 native 代码。 vmwait: 正在等待虚拟机的资源。 zombie: 僵尸线程，即将销往的进程的线程。 init : 初始化中的线程(理论上不应该看得到) starting : 即将启动的线程(理论上不应该看得到) utime: 花费在用户代码所花的累计时间，一小会儿(通常是10ms)。只有在linux环境下，才能看到。PS:windows 下。 DDMS 看得到，不知道他这里有啥特别的含义。 stime : 花费在系统代码上的累计时间，一小会儿(通常是10ms)。 Name: 线程名。 “ID” 和 “Name” 是在线程启动的时候被设置的。其他的字段是每过一段时间就更新一下(默认是4秒) ","date":"2016-07-20","objectID":"/2016/07/ddms-threads/:3:1","tags":["DDMS"],"title":"DDMS_Threads的简单使用","uri":"/2016/07/ddms-threads/"},{"categories":["Tool","IDE"],"content":"VM Heap 展示一些堆的统计数据，在 gc 的过程中会进程更新。如果选中一个 进程的时候，堆信息视图提示堆更新不可用，点击工具栏左上角的 “Show heap updates” 按钮，再回到 VM 堆视图，点击 “Cause GC” 进行垃圾回收，更新堆统计信息。 ","date":"2016-07-20","objectID":"/2016/07/ddms-threads/:3:2","tags":["DDMS"],"title":"DDMS_Threads的简单使用","uri":"/2016/07/ddms-threads/"},{"categories":["Tool","IDE"],"content":"参考文献 Using Dalvik Debug Monitor Service (DDMS) ","date":"2016-07-20","objectID":"/2016/07/ddms-threads/:4:0","tags":["DDMS"],"title":"DDMS_Threads的简单使用","uri":"/2016/07/ddms-threads/"},{"categories":["Mobile","Android"],"content":"概述 本文记录点击 Notification ,然后停留在 APP 内,而不是返回主页. 背景: 一个App会通过通知(Notification)的形式推广自己产品的内容，点击通知，想要看到推送的详情页，点击返回的时候，我们想让用户返回的是App的主页，而不是桌面。这样可以提高转化率等。以前的实现方式是通过重写了每个activity的返回键的响应，现在可以通过TaskStackBuilder 来实现。在网上查看了很多资料，真正正确的倒是没找到。 ","date":"2016-07-13","objectID":"/2016/07/notification-1/:0:0","tags":["Notification"],"title":"Notification_之利用TaskStackBuilder返回App主页","uri":"/2016/07/notification-1/"},{"categories":["Mobile","Android"],"content":"TaskStackBuilder 简介 Utility class for constructing synthetic back stacks for cross-task navigation on Android 3.0 and newer.是一个能够构造返回栈，来实现跨task导航的一个工具类。因为可以构造任务栈，所以，我们可以轻松的实现一个activity返回的上一个任务是什么。 ","date":"2016-07-13","objectID":"/2016/07/notification-1/:1:0","tags":["Notification"],"title":"Notification_之利用TaskStackBuilder返回App主页","uri":"/2016/07/notification-1/"},{"categories":["Mobile","Android"],"content":"实现步骤 1.首先创建一个点击了notification之后跳转到的详情页的intent对象。 Intent resultIntent = new Intent(this, ResultActivity.class); 2.在manifest中声明详情页ResultActivity的栈中前一个activity，声明的这个activity就是详情页点击返回键所要跳转的activity。 \u003cactivity android:name=\"cn.steve.notification.ResultActivity\" android:parentActivityName=\"cn.steve.notification.NotificationHandlerActivity\"\u003e \u003cmeta-data android:name=\"android.support.PARENT_ACTIVITY\" android:value=\"cn.steve.notification.NotificationHandlerActivity\"/\u003e \u003c/activity\u003e 创建一个PendingIntent对象，这个是创建notification的必备。 PendingIntent pendingIntent = TaskStackBuilder.create(this) .addNextIntentWithParentStack(resultIntent) .getPendingIntent(0, PendingIntent.FLAG_UPDATE_CURRENT); 剩下的就是正常的启动一个notification了。 // new notification NotificationCompat.Builder mBuilder = new NotificationCompat.Builder(this); mBuilder.setSmallIcon(android.R.drawable.ic_dialog_email); mBuilder.setContentTitle(\"My Notification!\"); mBuilder.setContentText(\"Hello World!\"); mBuilder.setContentIntent(pendingIntent); NotificationManager mNotificationManager = (NotificationManager) getSystemService(Context.NOTIFICATION_SERVICE); mNotificationManager.notify(0, mBuilder.build()); ","date":"2016-07-13","objectID":"/2016/07/notification-1/:2:0","tags":["Notification"],"title":"Notification_之利用TaskStackBuilder返回App主页","uri":"/2016/07/notification-1/"},{"categories":["Mobile","Android"],"content":"总结 实现的要点在于notification的设置。 ","date":"2016-07-13","objectID":"/2016/07/notification-1/:3:0","tags":["Notification"],"title":"Notification_之利用TaskStackBuilder返回App主页","uri":"/2016/07/notification-1/"},{"categories":null,"content":"title: androidarchitecture date: 2016-04-08 23:26:20 tags: [architecture] categories: [Mobile,Android] 概述 本文记录 Android 官方关于项目架构的文章. Android Architecture Blueprints [beta] 当我们开始明确如何组织和架构一个AndroidApp的时候，Android Framework层提供了很强大的可伸缩性。 这份自由虽然很有价值，但是同时也导致一个APP内存在如过重的类，命名体系不一样，架构导致难以测试，维护和扩展苦难等问题。 Android架构蓝图打算演示解决这类通用问题可能的方法。 在这个项目中，我们会提供一个机遇不同架构概念和不同工具的同一个项目实现。 你可以使用这些例子作为你创建自己的APP的一个参考，或者直接作为一个基础。本篇集中于代码结构，架构，测试和维护性。 然而，铭记于心的是，利用这些架构和工具，创建一个APP有很多方式，取决于你的侧重点。所以，这些架构不应该被当做是经典案例。 本篇例子中UI刻意保持了简单。 beat版的意义 我们一直在做一些可能会影响我们所有例子的决定。所以我们会在发布正式版之前，一直保持初始化的版本号。 例子 所有的例子都发布在他们对应的分支上。查看对应项目上看的README 以获取详细信息。 -todo-mvp/- 基本的MVP架构 -todo-mvp-loaders/- 基于todo-mvp，使用loaders来获取数据 -todo-mvp-databinding/-基于odo-mvp，使用databinding库 ##　还在进行中的 todo-mvp-contentproviders - 基于todo-mvp-loaders, 使用Content Providers todo-mvp-clean - 基于todo-mvp, 使用Clean Architecture的概念 todo-mvp-dagger - 基于todo-mvp, 使用Dagger2来进行依赖注入 此外，还有很多计划中的例子。 为何是一个待做的项目 这个APP的目的是能够简单快速的理解，而不是增加演示这个复杂的设计和测试方案的复杂性。 可以查看这个APP的规格。 此外，还有一个类似的JavaScript的项目框架，叫TodoMVC。 我应该为我的APP选择哪个例子 每个例子，都有一个选择的尺度，和比较客观的评估，你可以根据你的实际情况选择。 你可能要考虑到你APP的大小，你整个团队的经验，你预估的维护成本，考虑你是否需要为平板，多平台适配，以及自己的框架偏好。 TODO-MVP ","date":"0001-01-01","objectID":"/1/01/androidarchitecture/:1:0","tags":null,"title":"","uri":"/1/01/androidarchitecture/"},{"categories":null,"content":"总概 这个例子是其他变种版本的基础。这个例子展示MVP模式的一个简单的实现，没有参杂其他的架构框架。 这个例子，使用手动注入依赖的方式来提供本地和远端的数据。异步的任务是通过callback实现的。 注意：在MVP的上下文中，属于view是被重新重载了。 android.view.View被称作\"Android View\",在MVP中接受presenter发送命令的view被简单的称为\"view\". ","date":"0001-01-01","objectID":"/1/01/androidarchitecture/:2:0","tags":null,"title":"","uri":"/1/01/androidarchitecture/"},{"categories":null,"content":"Fragments 使用fragment有两个理由： activity和fragment进行隔离，非常适合用来实现MVP。 activity作为一个控制器，用来创建和控制view和presenter。 可以充分利用fragment框架进行平板和多屏幕适配。 ","date":"0001-01-01","objectID":"/1/01/androidarchitecture/:3:0","tags":null,"title":"","uri":"/1/01/androidarchitecture/"},{"categories":null,"content":"关键概念 在这个APP中有四个特点： 任务 任务详细 添加编辑任务 数据统计 每个特点有: 约定view和presenter的定义 activity负责产生fragment和presenter fragment实现view中的接口 presenter实现presenter定义的接口 总之，业务逻辑在presenter中，并且依赖于实现UI工作的view。 view层几乎是不包含业务逻辑的，只负责将presenter中的UI指令转换成UI表现，并且监听用户的UI操作，然后传递给presenter层。 通过接口来约定view和presenter之间的连接。 ","date":"0001-01-01","objectID":"/1/01/androidarchitecture/:4:0","tags":null,"title":"","uri":"/1/01/androidarchitecture/"},{"categories":null,"content":"依赖 常用的Android官方support包(com.android.support.*) Android测试包(Espresso, AndroidJUnitRunner…) Mockito Guava (null checking) ","date":"0001-01-01","objectID":"/1/01/androidarchitecture/:5:0","tags":null,"title":"","uri":"/1/01/androidarchitecture/"},{"categories":null,"content":"特点 ","date":"0001-01-01","objectID":"/1/01/androidarchitecture/:6:0","tags":null,"title":"","uri":"/1/01/androidarchitecture/"},{"categories":null,"content":"复杂性 - 这个比较容易理解 frameworks/libraries/tools的框架使用 还没有 概念复杂性 这个比较低，作为一个纯MVP实现。 ","date":"0001-01-01","objectID":"/1/01/androidarchitecture/:6:1","tags":null,"title":"","uri":"/1/01/androidarchitecture/"},{"categories":null,"content":"可测试性 Unit testing 高，presenter可以作为仓库和数据源进行单元测试。 UI testing 高, 注入一个假的的module，允许进行假数据进行测试。 ","date":"0001-01-01","objectID":"/1/01/androidarchitecture/:6:2","tags":null,"title":"","uri":"/1/01/androidarchitecture/"},{"categories":null,"content":"Code metrics 和传统没有架构的项目相比， 这个例子简绍了额外的类和接口:presenter，仓库，接口等等，所以在MVP中无论是代码的行数还是类的数量都比较高。 ","date":"0001-01-01","objectID":"/1/01/androidarchitecture/:6:3","tags":null,"title":"","uri":"/1/01/androidarchitecture/"},{"categories":null,"content":"维护性 易于修改和添加新特性 高。 学习成本 低。项目特点明确，责任清晰明确。开发人员不需要了解项目中的外部依赖。 ","date":"0001-01-01","objectID":"/1/01/androidarchitecture/:6:4","tags":null,"title":"","uri":"/1/01/androidarchitecture/"},{"categories":null,"content":"title: DataBinding 入门简介 date: 2016-02-20 22:53:36 tags: [DataBinding] categories: [Mobile,Android] 概述 本文介绍 DataBinding 的基本概念和接入流程 DataBinding出现的背景 作为一种 MVVM 的实现方式出现. 概念 将数据的 provider 和 consumer 进行绑定，而后进行二者之间同步的一种技术。实现逻辑层和表现层的绑定。 ","date":"0001-01-01","objectID":"/1/01/databinding/:1:0","tags":null,"title":"","uri":"/1/01/databinding/"},{"categories":null,"content":"注意事项： 使用的编译工具必须是 gradle，并且使用的 Android gradle 插件版本依旧官方所说，不能低于 Android Plugin for Gradle 1.3.0-beta4； 在使用的 module 的 gradle 文件中添加 apply plugin: ‘com.android.databinding’； 以上部分是 beta 1.3 版本的环境搭建以下是 1.5 的 使用gradle for android 1.5 在 APP module 的 gradle 中添加代码段 dataBinding { enabled = true } 如何使用 ","date":"0001-01-01","objectID":"/1/01/databinding/:1:1","tags":null,"title":"","uri":"/1/01/databinding/"},{"categories":null,"content":"工作的流程原理 在编译的时候，dataBinding 回去布局文件中进行文件的解析，然后获取关于 dataBinding 的设置，然后为对应的 view 设置 tag， 然后删除关于 dataBinding 的所有内容。 对于属性中引用 java 变量的值的地方，原理都是调用的对应的 java 的 set 方法进行设置，比如 TextView 的属性 text 对应了 setText();对于 ImageView 的 src 属性 通过一些注解，让其对应 setImageResource @BindingMethod( type = android.widget.ImageView.class, attribute = \"android:src\", method = \"setImageResource\") dataBinding 的 BaseObservable，继承的类，通过注解 @Bindable 注解对应属性的 get 方法可以在属性变化的时候及时的通知布局中更新 UI。 BindingAdapter 方法，用在 adapter 中的 @BindingAdapter(\"android:src\") public static void setImageUrl(ImageView view, String url) { Picasso.with(view.getContext()).load(url).into(view); } 1.额外的属性,同样是 adapter 中 \u003cImageView … android:src=\"@{contact.largeImageUrl}\" app:placeHolder=\"@{R.drawable.contact_placeholder}\"/\u003e @BindingAdapter(value = {\"android:src\", \"placeHolder\"},requireAll = false) public static void setImageUrl(ImageView view, String url,int placeHolder) { RequestCreator requestCreator =Picasso.with(view.getContext()).load(url); if (placeHolder != 0) { requestCreator.placeholder(placeHolder); } requestCreator.into(view); } 参考官方指导： https://developer.android.com/tools/data-binding/guide.html 同时发现，敲完代码发现这个demo写的很详细： https://github.com/LyndonChin/MasteringAndroidDataBinding ","date":"0001-01-01","objectID":"/1/01/databinding/:2:0","tags":null,"title":"","uri":"/1/01/databinding/"},{"categories":null,"content":"title: 标题：Hello World date: 2016-02-07 21:44:26 thumbnail: https://developers.google.cn/china/images/android.png 序言：Hello World.新的一年，希望有一个新的开始。 开个博客，方便自己平时写总结，公司内部也有分享，这样一举两得，而且用的是markdown，对于我这样懒惰的人，减轻了很多排版的烦恼。 希望我的内容不会浪费大家的时间，不会增加大家筛选有用信息的时间。 规则 之后所有的总结分享类的文章脉络，应该遵循Why-\u003eWhat-\u003eHow的原则总结。 ","date":"0001-01-01","objectID":"/1/01/hello-world/:1:0","tags":null,"title":"","uri":"/1/01/hello-world/"},{"categories":null,"content":"title: LayoutInflater中inflate的使用方法 date: 2016-02-23 22:25:09 tags: [LayoutInflater] categories: [Mobile,Android] 概述 本文记录 LayoutInflater 的 inflate 方法的三个参数的含义. 常常需要使用 LayoutInflater 中 inflate 方法。这个方法有两个重载的版本，一个是含有三个参数的，一个是两个参数的。 //resource 代表了要被加载的布局文件的 ID，root 是待附加的父布局 public View inflate (int resource, ViewGroup root) //前两个是一样的，最后一个 attachToRoot 代表是否加载到父布局的树形结构中 public View inflate (int resource, ViewGroup root, boolean attachToRoot) 我们使用最频繁的地方应该就是在 adapter 的 getView 方法中，将 root 值设为 null，或者设一个 parent，将 attachToRoot 设为 false。一般没有特殊的需求的话，这样就可以了。 @Override public View getView(int position, View convertView, ViewGroup parent) { View root; ViewHolder viewHolder; if (convertView == null) { viewHolder = new ViewHolder(); //加载布局 root = LayoutInflater.from(mContext).inflate(R.layout.listitem_campaign, parent, false); //加载布局，上面是含有第三个参数的版本，下面是含有两个参数的版本。和上面的效果是一样的； //root = LayoutInflater.from(mContext).inflate(R.layout.listitem_campaign,null); viewHolder.time = (TextView) root.findViewById(R.id.campaignItemTimeTextView); viewHolder.imageView = (ImageView) root.findViewById(R.id.campaignItemImageView); viewHolder.title = (TextView) root.findViewById(R.id.campaignItemTitleTextView); viewHolder.desc = (TextView) root.findViewById(R.id.campaignItemDescTextView); viewHolder.redCircle = (ImageView) root.findViewById(R.id.redCircleImageView); root.setTag(viewHolder); } else { root = convertView; viewHolder = (ViewHolder) root.getTag(); } Campaign campaign = data.get(position); viewHolder.time.setText(campaign.getTime()); viewHolder.title.setText(campaign.getTitle()); viewHolder.desc.setText(campaign.getDescription()); viewHolder.time.setText(campaign.getTime()); viewHolder.redCircle.setVisibility(campaign.isRead() ? View.INVISIBLE : View.VISIBLE); return root; } 当 parent 为 null 的时候，attachToRoot 就为 false。 public View inflate(@LayoutRes int resource, @Nullable ViewGroup root) { return inflate(resource, root, root != null); } 再看下 inflate 方法的关键部分。 // Temp is the root view that was found in the xml final View temp = createViewFromTag(root, name, inflaterContext, attrs); ViewGroup.LayoutParams params = null; if (root != null) { if (DEBUG) { System.out.println(\"Creating params from root: \" + root); } // Create layout params that match root, if supplied params = root.generateLayoutParams(attrs); if (!attachToRoot) { // Set the layout params for temp if we are not // attaching. (If we are, we use addView, below) temp.setLayoutParams(params); } } if (DEBUG) { System.out.println(\"-----\u003e start inflating children\"); } // Inflate all children under temp against its context. rInflateChildren(parser, temp, attrs, true); if (DEBUG) { System.out.println(\"-----\u003e done inflating children\"); } // We are supposed to attach all the views we found (int temp) // to root. Do that now. if (root != null \u0026\u0026 attachToRoot) { root.addView(temp, params); } // Decide whether to return the root that was passed in or the // top view found in xml. if (root == null || !attachToRoot) { result = temp; } } 当 root 为空的时候，直接返回了 temp (temp是从xml布局文件中加载的view)，而当 root 不为空的时候，会将 root 作为父布局，根据 xml 解析布局文件中的节点，获取属性元素，重新生成 temp 的布局参数 params (此时假如 attachToRoot 为 false，则会将 temp 的布局参数设置成生成的布局参数 params),而后根据 temp 重新inflate temp 中的子 view，该设置 params 的设置 params。而后如果 parent 不为空，attachToRoot 为 true，就会将整个布局中的所有元素挨个添加到 parent 中。最后返回的是 parent。 那么当 parent 为空的时候，又是什么个情况呢？因为 parent 为空，也就是 xml 文件根布局没有 parent 作为参照，解析的时候，他的高无论节点上设置的是什么都会默认是 wrap_content，宽都会是 match_parent。 假设目前有个布局文件为 \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cTextView xmlns:android=\"http://schemas.android.com/apk/res/android\" android:layout_width=\"25dp\" android:layout_height=\"25dp\" android:background=\"#ff0000\" android:text=\"red\"/\u003e 这里我们指定了 textview 的宽高。这里的 textview 就一个布局文件的跟布局。看下下面的代码，adapter 的 item 的布局也是类似的，原理一样。 public class LayoutInflaterActivity extends AppCompatActivity { private View view = null; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_layoutinflater_main);","date":"0001-01-01","objectID":"/1/01/layoutinflater%E4%B8%ADinflate%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/:1:0","tags":null,"title":"","uri":"/1/01/layoutinflater%E4%B8%ADinflate%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"},{"categories":null,"content":"总结 所以，要能在 getview 中，自定义宽高，办法有两个，一个是在最外层再套一层布局，然后 parent 设为 null。另一个是指定 parent，将 attachToRoot 设为 false。 ","date":"0001-01-01","objectID":"/1/01/layoutinflater%E4%B8%ADinflate%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/:2:0","tags":null,"title":"","uri":"/1/01/layoutinflater%E4%B8%ADinflate%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"},{"categories":null,"content":"title: RxAndroid入门分享(一) date: 2016-02-08 21:44:26 tags: [RxJava,Android,RxAndroid] categories: [Mobile,Android] 概述 本文记录 RxJava 的概念. RxJava 以及响应式函数思想篇 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:1:0","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"Why 技术产生的背景 在编程中，经常需要切换线程，为了能对结果进行相应处理，经常需要进行回调，随着业务需求的增加，嵌套的回调也会随之增加，不仅增加了代码量，也增加了逻辑的复杂性，增加了理解和维护的难度。 所以就需要一种 既能方便切换线程 又能即是相应变化 又可以简化代码的逻辑，方便维护， 还不需要回调。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:2:0","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"What ReactiveX是什么 Reactive Extensions,简称 RX，原来只是微软开发的一个 LINQ 的一个扩展。 微软给的定义是，Rx 是一个函数库，让开发者可以利用可观察序列和LINQ风格查询操作符来编写异步和基于事件的程序，使用 Rx，开发者可以用Observables 表示异步数据流，用 LINQ 操作符查询异步数据流，用 Schedulers 参数化异步数据流的并发处理，Rx 可以这样定义：Rx = Observables + LINQ + Schedulers。 ReactiveX.io 给的定义是，Rx 是一个使用可观察数据流进行异步编程的编程接口，ReactiveX 结合了观察者模式、迭代器模式和函数式编程的精华。 看完微软给的定义已经很详细了，开源组织给的更加精简，里面提到了数据流还有事件，我们来自己看看怎么理解。 这里得提到响应式编程的概念，其中有两个关键点， 事件，事件可以被观察，等待，过滤，响应，也可以触发其他的事件，事件通过数据流的形式对外呈现。 数据流，数据流就像一条河：它可以被观测，被过滤，被操作，或者与另外一条流合并为一条新的流来给新的消费者消费。 所以，响应式编程就是一种基于异步数据流概念的编程模式。其实 EventBus 还有其他的点击事件一样，本质上就是异步的数据流，我们可以为任何的事件创建数据流。比如我们可以为登录操作创建数据流，然后监听这个数据流，进行登录验证这样的响应操作。 主要特点有： 易于并发从而更好的利用服务器的能力。 易于有条件的异步执行。 一种更好的方式来避免回调地狱。 一种响应式方法。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:3:0","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"RxJava与传统的Java的不同 在 Rx 中，开发者用 Observables 模拟可被观察的异步数据流，从纯 Java 的观点看，RxJava 的 Observable 类源自于经典的 Gang Of Four 的观察者模式。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:4:0","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"与传统观察者的不同 它添加了三个缺少的功能： 生产者在没有更多数据可用时能够发出信号通知：onCompleted()事件。 生产者在发生错误时能够发出信号通知：onError()事件。 RxJava Observables 能够组合而不是嵌套，从而避免开发者陷入回调地狱。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:4:1","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"与传统的Iterable的不同 Observables 和 IterablesAPI 是很相似的：我们在 Iterable 可以执行的许多操作也都同样可以在 Observables 上执行。当然，由于 Observables 流的本质，没有如Iterable.remove() 这样相应的方法,因为数据可能已经发射出去了，remove 也没有任何意义。 使用 Iterable 时，消费者从生产者那里以同步的方式得到值，在这些值得到之前线程处于阻塞状态。相反，使用 Observable 时，生产者以异步的方式把值 push 给观察者，无论何时，这些值都是可用的。这种方法之所以更灵活是因为即便值是同步或异步方式到达，消费者在这两种场景都可以根据自己的需要来处理。 Pattern 一个返回值 多个返回值 Synchronous T getData() Iterable Asynchronous Future getData() Observable getData() Observable 的生命周期包含了三种可能的易于与 Iterable 生命周期事件相比较的事件，下表展示了如何将 Observable async/push 与 Iterable sync/pull 相关联起来。 Event Iterable(pull) Observable(push) 检索数据 T next() onNext(T) 发现错误 throws Exception onError(Throwable) 完成 !hasNext() onCompleted() 所以，由以上这些新增的特点，开发者只要简单的去请求，当请求完成的时候，会得到一个通知。开发者需要对可能发生的每个事件提供一个清晰的响应链。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:4:2","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"举个例子： 用户提交完用户名和密码，我们可以用 observable 模拟这个登录的数据流，而后我们需要对可能发生的情况进行定义； 用户名密码正确，登录成功，转到登录成功界面。 用户名和密码匹配不成功，登录失败，给用户个提示。 这样，我们不需要等待结果，等到有结果的时候，会有通知，这个过程是异步的。这中间可以做很多其他的事情，保存到缓存，显示进度条等等。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:4:3","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"概念 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:5:0","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"Observable 当我们异步执行一些复杂的事情，Java 提供了传统的类，例如 Thread、Future、FutureTask、CompletableFuture 来处理这些问题。当复杂度提升，这些方案就会变得麻烦和难以维护。最糟糕的是，它们都不支持链式调用。RxJava Observables 可以解决这些问题。它可以作用于单个结果程序上，也可以作用于序列上。无论何时你想发射单个标量值，或者一连串值，甚至是无穷个数值流，你都可以使用 Observable。和传统的观察者模式一样，也有冷热之分。 热的 observable，只要创建了 observable，就开始发射数据了，所以，后续订阅他的 observer 可能从中间某个位置开始接收数据。 冷的 observable，等到有订阅的时候才开始发射数据。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:5:1","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"Observer 观察者，订阅 observable 发射的数据，对其做出相应，对可能出现的情况的定义就在这里。 三个重要的回调方法 (onNext, onCompleted, onError) 通过Subscribe方法可以将观察者连接到 Observable，观察者需要实现以下方法的一个子集: onNext(T item):Observable 调用这个方法发射数据，方法的参数就是 Observable 发射的数据，这个方法可能会被调用多次，取决于你的实现。 onError(Exception ex):当 Observable 遇到错误或者无法返回期望的数据时会调用这个方法，这个调用会终止 Observable，后续不会再调用 onNext 和 onCompleted，onError 方法的参数是抛出的异常。 onComplete:正常终止，如果没有遇到错误，Observable 在最后一次调用 onNext 之后调用此方法。 根据 Observable 协议的定义，onNext 可能会被调用零次或者很多次，最后会有一次 onCompleted 或 onError 调用（不会同时），传递数据给 onNext 通常被称作发射，onCompleted 和 onError 被称作通知。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:5:2","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"Subscriber Observers 和 Subscribers 是两个“消费”实体。Subscriber 是一个实现了 Observer 的一个抽象类。相对于基本的 Observer，提供了手动解开订阅的方法 unsubscribe 和在 subscribe 刚开始，而事件还未发送之前被调用的方法 onStart。其他的使用方式是一样的。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:5:3","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"Subjects Subject = Observable + Observer。 subject 是一个神奇的对象，它可以是一个 Observable 同时也可以是一个 Observer：它作为连接这两个世界的一座桥梁。一个 Subject 可以订阅一个 Observable，就像一个观察者，并且它可以发射新的数据，或者传递它接受到的数据，就像一个 Observable。很明显，作为一个 Observable，观察者们或者其它 Subject 都可以订阅它。 一旦 Subject 订阅了 Observable，它将会触发 Observable 开始发射。如果原始的 Observable 是“冷”的，这将会对订阅一个“热”的 Observable 变量产生影响。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:5:4","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"How怎么使用 接下来讨论他的具体使用方法。首先是需要搭建环境，我们就以 AS 为例。 因为就是为了 Android 开发所学的，在 module 的 gradle 中添加 RxAndroid 的仓库地址,RxAndroid 本身是依赖 RxJava 的，所以会自动下载 RxJava 的依赖包。 compile 'io.reactivex:rxandroid:1.1.0' ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:6:0","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"创建Observable Create之从头创建 这个操作符传递一个含有观察者作为参数的函数的对象，编写这个函数让它的行为表现为一个 Observable –恰当的调用观察者的 onNext，onError 和 onCompleted 方法。下面是个非常简单的一个例子，先有个直观的大致的认识。 Observable.OnSubscribe\u003cString\u003e f = new Observable.OnSubscribe\u003cString\u003e() { @Override public void call(Subscriber\u003c? super String\u003e o) { //完全自己决定发射数据给subscriber和通知subscriber的时机以及方式 o.onNext(\"发射的数据\"); o.onCompleted(); } }; Observable observable = Observable.create(f); //创建订阅者 Subscriber subscriber = new Subscriber() { @Override public void onCompleted() { //正常结束，收到发射的通知 } @Override public void onError(Throwable e) { //出现了错误的通知 } @Override public void onNext(Object o) { //收到observable发射的数据 } }; //订阅，一旦订阅发生，observable将开始发射数据 observable.subscribe(subscriber); From 这个操作符需要传入数组或者列表等可以迭代的类型，将会返回一个 Observable 对象，这个 Observable 会迭代列表里的数据，然后将数据一个一个的发射出去。 Just 这个操作符会返回一个 Observable，这个 Observable 将传入的对象直接发射出去。这个操作符对于进行旧版本的改造非常有用，对于暂时不想做过多操作的函数，可以直接传入到 just 操作符中，这样就自动构造出了一个数据流。 Repeat 这个操作符需要一个整形数字作为参数，代表了重复发射的次数，比如发射“123”三次，就会变成发射\"123123123\"。 defer 这个操作符可以延迟 Observable 的创建，当有订阅者的时候才开始创建，这个对于一些不是每次都需要创建的数据流而言，很有用。怎么理解呢，我们简单的看个例子。 public class MainActivity extends AppCompatActivity { private Subscriber subscriber; private Observable simpleObservable; private String doSomeThing() { System.out.println(\"在执行just的时候，这里需要执行的操作已经执行结束了。。。\"); return \"SteveYan\"; } @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); simpleObservable = Observable.just(doSomeThing()); subscriber = new Subscriber() { @Override public void onCompleted() { //正常结束，收到发射的通知 System.out.println(\"onCompleted\"); } @Override public void onError(Throwable e) { //出现了错误的通知 } @Override public void onNext(Object o) { //收到observable发射的数据 System.out.println(\"Receive \" + o.toString()); } }; init(); } private void init() { findViewById(R.id.button).setOnClickListener(new View.OnClickListener() { @Override public void onClick(View v) { //每次点击的时候都进行订阅 simpleObservable.subscribe(subscriber); } }); } } 在上面的例子中，每次点击就进行一次订阅，在 onCreate 方法里，在执行 just 的时候，doSomeThing 已经执行完了， 但是并未发射数据，但是假如使用 defer 操作符的话，doSomeThing 则会等到点击的时候才执行。 修改成的 defer 操作符的 public class MainActivity extends AppCompatActivity { private Subscriber subscriber; private Observable simpleObservable; private String doSomeThing() { System.out.println(\"Do Some\"); return \"SteveYan\"; } @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); simpleObservable = Observable.defer(new Func0\u003cObservable\u003cString\u003e\u003e() { @Override public Observable\u003cString\u003e call() { return Observable.just(doSomeThing()); } }); subscriber = new Subscriber() { @Override public void onCompleted() { //正常结束，收到发射的通知 System.out.println(\"onCompleted\"); } @Override public void onError(Throwable e) { //出现了错误的通知 } @Override public void onNext(Object o) { //收到observable发射的数据 System.out.println(\"Receive \" + o.toString()); } }; init(); } private void init() { findViewById(R.id.button).setOnClickListener(new View.OnClickListener() { @Override public void onClick(View v) { //每次点击的时候都进行订阅 simpleObservable.subscribe(subscriber); } }); } } range 从一个指定的数字X开始发射N个数字 range() 函数用两个数字作为参数：第一个是起始点，第二个是我们想发射数字的个数。目前未发现在实际项目中的用处。 interval 重复轮训操作 interval() 函数的两个参数：一个指定两次发射的时间间隔，另一个是用到的时间单位。需要创建一个轮询程序时非常好用 timer 一段时间之后才发射的Observable 接受两个参数，一个是延迟发射的时间，第二个参数是时间的。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:6:1","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"可观测序列的本质：过滤 过滤：如何从发射的 Observable 中选取我们想要的值，如何获取有限个数的值，如何处理溢出的场景，以及更多的有用的技巧。 filter函数，进行内容的过滤 接受一个参数，对数据流中的每个数据进行过滤。 Take,取序列的前N个元素 take() 函数用整数N来作为一个参数，从原始的序列中发射前 N 个元素 takeLast,取序列的最后的N个元素 如果我们想要最后 N 个元素，接给 takeLast 函数传入 N 作为参数。有一点值得注意，为了得到最后的数据，所以 takeLast 方法只能作用于一组有限的序列（发射元素），它只能应用于一个完整的序列。否则他无从知晓最后到哪。 Distinct 有且仅有一个 distinct 函数去掉重复的。就像 takeLast 一样，distinct 也必须作用于一个完整的序列，然后得到重复的过滤项，它需要记录每一个发射的值。如果你在处理一大堆序列或者大的数据记得关注内存使用情况。 DistinctUntilsChanged 改变的时候就记录 如果我们想在一个可观测序列发射一个不同于之前的一个新值时，让我们得到通知，就可以用这个操作符。 First And Last 从 Observable 中只发射第一个元素或者最后一个元素。这两个都可以传 Func1 作为参数，：一个可以确定我们感兴趣的第一个或者最后一个的谓词。 与 first()和 last()相似的变量有：firstOrDefault() 和 lastOrDefault().这两个函数当可观测序列完成时不再发射任何值时用得上。在这种场景下，如果 Observable 不再发射任何值时我们可以指定发射一个默认的值 Skip And SkipLast 它们用整数 N 作参数，从本质上来说，它们不让 Observable 发射前 N 个或者后 N 个值。这个和上面的 First 和 Last 正好相反。 elementAt 观察指定位置的数据 elementAt() 函数仅从一个序列中发射第 n 个元素然后就完成了。 如果我们想查找第五个元素但是可观测序列只有三个元素可供发射时该怎么办？我们可以使用 elementAtOrDefault()。 sample 每隔一段时间取最近的数据 创建一个新的可观测序列，它将在一个指定的时间间隔里由 Observable 发射最近一次的数值。 如果我们想让它定时发射第一个元素而不是最近的一个元素，我们可以使用 throttleFirst()。 timeout 超时操作 使用 timeout() 函数来监听源可观测序列,就是在我们设定的时间间隔内如果没有得到一个值则发射一个错误。 debounce 除去发射过快的数据 debounce() 函数过滤掉由 Observable 发射的速率过快的数据；如果在一个指定的时间间隔过去了仍旧没有发射一个，那么它将发射最后的那个。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:6:2","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"转换Observables Map 转换发射的数据，将发射数据 A 的 Observable 变换成发射数据 B 的 Observable。适用于对数据的再加工场景。 FlatMap 铺平序列 这样的 Observable：它发射一个数据序列，这些数据本身也可以发射 Observable。等于是说发射的数据可以再发射数据。flatMap 函数提供一种铺平序列的方式，然后合并这些 Observables 发射的数据，最后将合并后的结果作为最终的 Observable. 当我们在处理可能有大量的 Observables 时，重要是记住任何一个 Observables 发生错误的情况，flatMap 将会触发它自己的 onError 函数并放弃整个链。 重要的一点提示是关于合并部分：它允许交叉。正如上图所示，这意味着 flatMap 不能够保证在最终生成的 Observable 中源 Observables 确切的发射顺序。 ConcatMap 保证有序的铺平 和上面的 FlatMap 一样，就是弥补了交叉这个一个特点。 FlatMapIterable 它将源数据两两结成对并生成 Iterable，而不是原始数据项和生成的 Observables。 SwitchMap 切换数据流(喜新厌旧) switchMap() 和 flatMap() 很像，除了一点：每当源 Observable 发射一个新的数据项（Observable）时，它将取消订阅并停止监视之前那个数据项产生的 Observable，并开始监视当前发射的这一个。 Scan RxJava 的 scan() 函数可以看做是一个累积函数。scan 函数对原始 Observable 发射的每一项数据都应用一个函数，计算出函数的结果值，并将该值填充回可观测序列，等待和下一次发射的数据一起使用。简单的说是每次可以处理的数据有本次的和上次的数据。 groupBy 分组 接受一个方法，在方法里进行分组操作，返回一个自定义的值，系统将根据这个值将进行分组。 buffer 每次发射一组值，是一个列表，而不是一个个的发射。接受一个整形参数 N，表示 N 个一组进行发射。也可以接受两个参数，SKIP，表示 SKIP 个值中取 N 个一组进行发射。 window 和 buffer 类似，但是他发射的不是一个列表，而是一个 Observable。 cast 和 map 类似，不同的是将数据进行转换成一个新的类型。TODO 目前测试未发现怎么使用。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:6:3","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"组合Observable 以上的内容是对 Observable 的发射数据进行过滤，接下来谈谈怎么组合数据流。 merge 将多个 Observable 发射的值进行合并成一个新的 Observable 然后再发射。中途合并的时候出现任何一个错误都会导致链条断裂，如果想延迟这样的错误处理，可以用 mergeDelayError。 zip 这个操作符和 merge 一样，也是合并两个 Observable 的数据；不一样的是，他是将两个未进行打包的数据根据传入的谓词规则进行合并成一个新的数据,再进行发射。值得注意的是，两个数据流的长度必须一样，多余的数据将会因为不能打包而得不到发射。 join TODO 待详细验证用途 有四个参数， 第一个参数为，Observable，表示和源 Observable 结合的数据流。 Func1参数：在指定的由时间窗口定义时间间隔内，源 Observable 发射的数据和从第二个 Observable 发射的数据相互配合返回的 Observable。 Func1参数：在指定的由时间窗口定义时间间隔内，第二个 Observable 发射的数据和从源 Observable 发射的数据相互配合返回的 Observable。 Func2参数：定义已发射的数据如何与新发射的数据项相结合。 combineLatest 和 Zip 一样，去组合两个数据流发射的数据，并且进行组合，合并成一个新的数据进行发射，不同的是，Zip 发射的是最近未进行打包的，而 combineLatest 走的是相反的路线，打包最近发射的数据，不管是否已经打包过了。这样的话，就会弥补 Zip 的长度限制，全部得到发射。 startWith Observable 开始发射他们的数据之前， startWith() 通过传递一个参数来先发射一个数据序列。 表示发射之前先将传入的参数法发射出去。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:6:4","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"Schedulers 随时切换运行的线程 这里大致说一下有哪几种情况，因为在 Java 中的情况和 Android 稍有差异，并且必须结合实例才能明白这个好处。 RxJava提供的五种调度器 .io() 这个调度器时用于 I/O 操作。它基于根据需要，增长或缩减来自适应的线程池。由于它专用于 I/O 操作，所以并不是 RxJava 的默认方法；正确的使用它是由开发者决定的。重点需要注意的是线程池是无限制的，大量的 I/O 调度操作将创建许多个线程并占用内存。 .computation() 这个是计算工作默认的调度器，与I/O 操作无关。也是许多 RxJava 方法的默认调度器：buffer(),debounce(),delay(),interval(),sample(),skip()。所以可以将一些耗时的，但是与 IO 无关的一些操作。 .immediate() 这个调度器允许你立即在当前线程执行你指定的工作。它是 timeout(),timeInterval(),以及 timestamp() 方法默认的调度器。 .newThread() 这个调度器正如它所看起来的那样：它为指定任务启动一个新的线程。 .trampoline() 当我们想在当前线程执行一个任务时，并不是立即，我们可以用 .trampoline 将它入队。这个调度器将会处理它的队列并且按序运行队列中每一个任务。它是 repeat()和 retry() 方法默认的调度器。 SubscribeOn and ObserveOn，指定线程，线程切换 subscribeOn() 方法来用于每个 Observable 对象。subscribeOn() 方法用 Scheduler 来作为参数并在这个 Scheduler 上执行 Observable 调用。 observeOn() 方法将会在指定的调度器上返回结果。observeOn() 方法用 Scheduler 来作为参数，在指定的线程上返回结果，观察者在返回结果的线程上消费这个结果。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:6:5","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"Retrofit Retrofit 完美的支持 Rx 编程，可以完美的结合。 ##感激,非常感激，万分的感激！ 感谢以下的文章以及其作者和翻译的开发者们,排名不分先后 RxJava Essentials 中文翻译版 ReactiveX文档中文翻译 给 Android 开发者的 RxJava 详解 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction1/:6:6","tags":null,"title":"","uri":"/1/01/rxandroidintroduction1/"},{"categories":null,"content":"title: RxAndroid入门分享(二) date: 2016-02-26 22:50:26 tags: [RxJava,Android,RxAndroid] categories: [Mobile,Android] 概述 本文记录 RxJava 中在 Android 中的应用,介绍 RxAndroid 的使用. More RxJava 及其在Android上的应用 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:1:0","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"开发环境 在 module 的 gradle 中添加 RxAndroid 的相关依赖，如果想体验 rx 在 Android 上的更方便的功能。可以添加 Jake 大神的兼容包 RxBinding。 //RXAndroid compile 'io.reactivex:rxandroid:1.1.0' //RxBinding compile 'com.jakewharton.rxbinding:rxbinding:0.3.0' compile 'com.jakewharton.rxbinding:rxbinding-support-v4:0.3.0' compile 'com.jakewharton.rxbinding:rxbinding-appcompat-v7:0.3.0' compile 'com.jakewharton.rxbinding:rxbinding-design:0.3.0' compile 'com.jakewharton.rxbinding:rxbinding-recyclerview-v7:0.3.0' //compile 'com.jakewharton.rxbinding:rxbinding-leanback-v17:0.3.0' ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:2:0","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"以下开始用一个demo来演示 目的地有三个 tab，每个 tab 内的详情用 RecyclerView 展示，下拉刷新用 SwipeRefreshLayout。 布局界面如下 \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cFrameLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\"\u003e \u003candroid.support.v4.widget.SwipeRefreshLayout android:id=\"@+id/destinationSwipeRefreshLayout\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\"\u003e \u003candroid.support.v7.widget.RecyclerView android:id=\"@+id/destinationRecyclerView\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:clipToPadding=\"false\"\u003e \u003c/android.support.v7.widget.RecyclerView\u003e \u003c/android.support.v4.widget.SwipeRefreshLayout\u003e \u003c/FrameLayout\u003e 开始 RxAndroid 的编写，我们开始考虑在目的地页面需要有的步骤 网络请求数据(放在 IO 线程)； 填充网络请求返回的数据到页面(UI 线程展示)； RxAndroid 是基于响应式的编程，我们考虑将以上的网络请求产生的结果作为一个事件，他产生的数据就可以定义为数据流了。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:3:0","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"Observable\u0026\u0026create //网络请求，从头开始，自定义创建一个数据流。自主决定数据流的发射时机。 private Observable\u003cDestinationDataModel\u003e getDestinationDataObservable(final String url) { return Observable.create(new Observable.OnSubscribe\u003cDestinationDataModel\u003e() { @Override public void call(Subscriber\u003c? super DestinationDataModel\u003e subscriber) { Gson gson = new Gson(); Request request = new Request.Builder().url(url).build(); Response response = null; try { response = client.newCall(request).execute(); DestinationDataModel destinationDataModel = gson.fromJson(response.body().string(), DestinationDataModel.class); if (subscriber.isUnsubscribed()){//判断连接是否断开，避免无谓的操作 return; } subscriber.onNext(destinationDataModel); if (!subscriber.isUnsubscribed()){ subscriber.onCompleted(); } } catch (IOException e) { e.printStackTrace(); } } }); } 这里我们定义了一个方法，这个方法返回一个 Observable，里面封装了数据流,其实不是很计较的情况下，我们先将 Observable 事件等价(自我的理解，未在官方文档找到合适的解释，如有找到望不吝赐教)，事件对外以数据流的形式展现，这个事件就是在发射数据，然后发射结束就通知，失败了也通知。此处我们用到了操作符 create，一种创建操作符，这种操作的扩展性极大，但是我们也需要自己负责发射数据。全程的执行规范都在你的手里。 这里可能会有误区，数据流，不一定是多个，非要像 list，数组似的，那种有多个值，像弹珠似的连续发射。像上面的代码，我们只是发射了一个 destinationDataModel 对象，这个也是数据流，即，你发射出去的就是数据流的子集。 现在，我们有数据流了，就需要在某个适当的地方进行响应。我们思考，需要响应什么？对一个事件可能存在三种情况，事件对应的数据发射失败了( onError )，发射成功了( onCompleted ),还有接收到了发射来的数据( onNext )。 有点需要注意，这里的失败，以及成功，这两个回调，只是一个通知而已。 Subscriber\u003cDestinationDataModel\u003e subscriber = new Subscriber\u003cDestinationDataModel\u003e() { @Override public void onStart() { super.onStart(); } @Override public void onCompleted() { Toast.makeText(getActivity(), \"onCompleted\", Toast.LENGTH_SHORT).show(); destinationSwipeRefreshLayout.setRefreshing(false); } @Override public void onError(Throwable e) { e.printStackTrace(); destinationSwipeRefreshLayout.setRefreshing(false); } @Override public void onNext(DestinationDataModel destinationDataModel) { destinationRecyclerView.setAdapter(new DestinationRecyclerAdapter(getActivity(), destinationDataModel.getDatas())); } }; 我们定义了一个 Subscriber 对象，在上篇中讲到了什么是 Subscriber。这个是对数据流发射的相应，差不多对应了观察者模式中的观察者。当得到失败和成功的通知的时候，我们这里进行 log 的输出并且显示刷新的图标。当接收到数据的时候，我们就创建 recyclerview 的 adapter，进行列表的填充显示。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:3:1","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"subscribe 一旦我们订阅，就会执行数据的发射，默认的情况下，没有订阅操作，数据是不会被发射的。 getDestinationDataObservable(url).subscribe(subscriber); 以上的操作就会完成订阅，正常的数据产生，发射，相应都会发生。但是，真当我们允许的时候，就会报错，原因是我们都知道，对 UI 的操作都必须在 UI 主线程中。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:3:2","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"subscribeOn \u0026\u0026 observeOn 指定数据产生发射的线程和订阅响应的线程。 getDestinationDataObservable(url).subscribeOn(Schedulers.io()).observeOn(AndroidSchedulers.mainThread()).subscribe(subscriber); subscribeOn 表示 Observable 执行所在的线程，这里指的是网络请求，请求的数据进行 gson 解析，再将数据发射的线程。 observeOn 表示的订阅响应的线程，这里指的是填充发射过来的数据到列表中。 运行就能看到我们想要的效果。到此我们学会了最基本的一些使用，基本上掌握了这几个就可以轻松地展开工作了。当然还有很多其他的技巧。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:3:3","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"From \u0026\u0026 Just 我们刚刚有说过，数据流不一定是连续的，那么肯定存在连续的，连续不断的弹射，更符合官方文档那种弹珠示意图。from 就是一个这样的操作符。 这个目前未想到在当前这个模块的应用场景。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:3:4","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"repeat 这个是重复，我们让当前的列表中的数据重复发送两次。 getDestinationDataObservableByCreate(url).repeat(2) .subscribeOn(Schedulers.io()).observeOn(AndroidSchedulers.mainThread()) .subscribe(subscriber); 修改下subscriber @Override public void onNext(DestinationDataModel destinationDataModel) { if (destinationRecyclerView.getAdapter() == null) { DestinationRecyclerAdapter adapter = new DestinationRecyclerAdapter(getActivity(), destinationDataModel.getDatas()); destinationRecyclerView.setAdapter(adapter); } else { DestinationRecyclerAdapter adapter = (DestinationRecyclerAdapter) destinationRecyclerView.getAdapter(); adapter.datas.get(0).getInfos().addAll(destinationDataModel.getDatas().get(0).getInfos()); } } 上面的结果是，请求两次网络。我们会看到数据重复了，同样的数据被发送了两次，并且是从头到尾的重复了两次。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:3:5","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"defer 延迟操作，等到订阅的时候再准备数据流。这里尤其对 just 和 from 操作符的效果最为明显,以下是国外的一个 just 的例子说明，from 的原理一样。 借用一个国外的例子 国内的翻译 public class SomeType { private String value; public void setValue(String value) { this.value = value; } public Observable\u003cString\u003e valueObservable() { return Observable.just(value); } } 对于以下代码的调用会出现怎么样的结果呢？ SomeType instance = new SomeType(); Observable\u003cString\u003e value = instance.valueObservable(); instance.setValue(\"Some Value\"); value.subscribe(System.out::println); //订阅的时候发射数据 如果你认为会打印出 “Some Value”，那就错了。而实际打印结果是 “null”。因为在调用 Observable.just() 的时候，value 已经初始化了。 just()，from() 这类能够创建 Observable 的操作符（译者注：创建 Observable 的操作符）在创建之初，就已经存储了对象的值，而不被订阅的时候。订阅的时候只是发射数据。 这种情况，显然不是预期表现，我想要的 valueObservable() 是无论什么时候请求，都能够表现为当前值。所以我们需要延迟数据的创建直到有人订阅。有两个方法，一个是用 create 自主创建，我们可以自己精确的控制发射什么，什么时候发射，还有一个是用的 defer 延迟操作符。defer() 中的代码直到被订阅才会执行。我们只需要在请求数据的时候调用 Observable.just() 就行了，使用 defer() 操作符的唯一缺点就是，每次订阅都会创建一个新的 Observable 对象。create() 操作符则为每一个订阅者都使用同一个函数，所以，后者效率更高。 因为我学习的时候，难以想清楚延迟和 create 操作符中的 call 的时间顺序和区别，我们用另外一个例子解释一下。 private Observable\u003cInteger\u003e getInt() { SimpleDateFormat sdf = new SimpleDateFormat(\"yyyyMMdd_HHmmss\"); String currentDateandTime = sdf.format(new Date()); Log.e(\"GetInt\", currentDateandTime); return Observable.create(new Observable.OnSubscribe\u003cInteger\u003e() { @Override public void call(Subscriber\u003c? super Integer\u003e subscriber) { if (subscriber.isUnsubscribed()) { return; } subscriber.onNext(42); subscriber.onCompleted(); } }); } //simple defer private void simpleDefer() { //defer中的getInt操作等到有人订阅deferObservable的时候才会被执行 //假如这里不用defer，直接用getInt返回，那么调用simpleDefer的时候就会打印时间 deferObservable = Observable.defer(new Func0\u003cObservable\u003cInteger\u003e\u003e() { @Override public Observable\u003cInteger\u003e call() { return getInt(); } }); // deferObservable.subscribe(new Action1\u003cInteger\u003e() { // @Override // public void call(Integer integer) { // System.out.println(\"subscribe:\" + integer); // } // }); } 在不用延迟的情况下，我们调用 simpleDefer 返回一个数据流的时候就会打印时间，反之我们不用延迟的话，则会在调用 simpleDefer 的时候就已经打印了当前的时间。 所以，这里被延迟的是我们 getInt 被调用的时机。注意：create 中的发射 42 和延迟 无关，这个 call 函数就是在 发射 数据，订阅的时候才会发射数据 ，一旦订阅发生的额时候，就会发射42。 总之记住，defer 延迟的是参数 function 中的操作。只要将需要延迟创建的操作放到 function 函数中即可。这个对于数据的新鲜度有要求的操作很有用。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:3:6","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"filter 我们接受到的数据常常用些是不满足我们的需求的，这时候就可以用 filter 操作符。 getDestinationDataObservableByCreate(url).filter(new Func1\u003cDestinationDataModel, Boolean\u003e() { @Override public Boolean call(DestinationDataModel destinationDataModel) { return destinationDataModel != null; } }) .subscribeOn(Schedulers.io()).observeOn(AndroidSchedulers.mainThread()) .subscribe(subscriber); 比如我们可以对发射的数据中 null 数据进行过滤，虽然我们也可以在 onNext 或者在 subscriber 中进行过滤，那样就会破坏代码的业务逻辑，这样，每个函数只要注重自身的业务逻辑即可。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:3:7","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"Map 我们有时候随着需求的变更，版本的迭代，可能用同一套数据可能会做不用的用处，亦或者同一个功能的同一个数据源，但是上层的应用对数据结构的需求发生了变化。这时候，如果我们去变更数据提供层，或者让上层去适配，都会破坏代码逻辑。 getDestinationDataObservableByCreate(url).map(new Func1\u003cDestinationDataModel, String\u003e() { @Override public String call(DestinationDataModel destinationDataModel) { return destinationDataModel.getVersion(); } }).subscribeOn(Schedulers.io()).observeOn(AndroidSchedulers.mainThread()) .subscribe(new Action1\u003cString\u003e() { @Override public void call(String s) { System.out.println(s); } }); 看上面，我们并没有修改 getDestinationDataObservableByCreate 的业务逻辑，这样就不会影响其他的代码逻辑，也不会去贸然修改底层数据提供，用 map 操作符，我们就将 getDestinationDataObservableByCreate 发射的 DestinationDataModel 类型的数据，一个个变换成了 String 类型。 map适用于这些数据结构的变化的操作。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:3:8","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"FlatMap \u0026\u0026 ConcatMap 对于一些 Observable 本身也会返回 Observable，我们可以将这些子 Observable 发射的数据进行统一，合并这些 Observables 发射的数据，最后将合并后的结果作为最终的 Observable。 这就是为什么叫做铺平的原因。 提示：合并部分是允许交叉的。意味着 flatMap() 不能够保证在最终生成的 Observable 中源 Observables 确切的发射顺序。ConcatMap 可以保证顺序，用法和 flatMap 一样。 private Observable\u003cObservable\u003cDestinationDataModel\u003e\u003e getDestinationDataObservableByFlatMap(final String url) { return Observable.create(new Observable.OnSubscribe\u003cObservable\u003cDestinationDataModel\u003e\u003e() { @Override public void call(Subscriber\u003c? super Observable\u003cDestinationDataModel\u003e\u003e subscriber) { Gson gson = new Gson(); Request request = new Request.Builder().url(url).build(); Response response = null; try { response = client.newCall(request).execute(); DestinationDataModel destinationDataModel = gson.fromJson(response.body().string(), DestinationDataModel.class); if (subscriber.isUnsubscribed()) {//判断连接是否断开，避免无谓的操作 return; } subscriber.onNext(Observable.just(destinationDataModel)); subscriber.onNext(Observable.just(destinationDataModel)); subscriber.onCompleted(); if (!subscriber.isUnsubscribed()) { subscriber.onCompleted(); } } catch (IOException e) { e.printStackTrace(); } } }); } getDestinationDataObservableByFlatMap(url).flatMap(new Func1\u003cObservable\u003cDestinationDataModel\u003e, Observable\u003cDestinationDataModel\u003e\u003e() { @Override public Observable\u003cDestinationDataModel\u003e call(Observable\u003cDestinationDataModel\u003e destinationDataModelObservable) { return destinationDataModelObservable; } }) .subscribeOn(Schedulers.io()).observeOn(AndroidSchedulers.mainThread())subscribe(subscriber); 上面我们用 subscriber.onNext(Observable.just(destinationDataModel));模拟发送两个 Observable,然后通过 flatMap 进行扁平化处理。我们看到效果是列表中有两组相同的数据。 flatMap() 和 map() 有一个相同点：它也是把传入的参数转化之后返回另一个对象。 但需要注意，和 map() 不同的是， flatMap() 中返回的是个 Observable 对象，并且这个 Observable 对象并不是被直接发送到了 Subscriber 的回调方法中。 flatMap() 的原理是这样的： 使用传入的事件对象创建一个 Observable 对象； 并不发送这个 Observable, 而是将它激活，于是它开始发送事件； 每一个创建出来的 Observable 发送的事件，都被汇入同一个 Observable ，而这个 Observable 负责将这些事件统一交给 Subscriber 的回调方法。 这三个步骤，把事件拆成了两级，通过一组新创建的 Observable 将初始的对象『铺平』之后通过统一路径分发了下去。 而这个『铺平』就是 flatMap() 所谓的 flat。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:3:9","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"SwitchMap 和上面的操作符类似 ，都是 Observable 发射 Observable,不同的是，这个操作不会合并数据项中的所有数据，而是当遇到后一个 Observable 发射数据的时候，就停止对前一个 Observable 的接收。 getDestinationDataObservableByFlatMap(url).switchMap(new Func1\u003cObservable\u003cDestinationDataModel\u003e, Observable\u003cDestinationDataModel\u003e\u003e() { @Override public Observable\u003cDestinationDataModel\u003e call(Observable\u003cDestinationDataModel\u003e destinationDataModelObservable) { return destinationDataModelObservable; } }).subscribeOn(Schedulers.io()).observeOn(AndroidSchedulers.mainThread()) .subscribe(subscriber); 只要换个操作符即可 switchMap，这里因为发射的数据只有一个，效果不明显，如果是列表，交叉发射的话，会很明显，效果回事丢失一部分数据。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:3:10","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"GroupBy 我们对数据按照某个依据进行分组。 Observable\u003cGroupedObservable\u003cString, DestinationDataModel\u003e\u003e groupedObservableObservable = getDestinationDataObservableByCreate(url).groupBy(new Func1\u003cDestinationDataModel, String\u003e() { @Override public String call(DestinationDataModel destinationDataModel) { return destinationDataModel.getVersion(); } }); Observable.concat(groupedObservableObservable).subscribeOn(Schedulers.io()).observeOn(AndroidSchedulers.mainThread()).subscribe(subscriber); 以上依旧版本号对数据进行分组，一组的将在一起当做一个 Observable 发射。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:3:11","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"merge 对数据进行整合一起发射。 Observable\u003cDestinationDataModel\u003e merge1 = getDestinationDataObservableByCreate(url); Observable\u003cDestinationDataModel\u003e merge2 = getDestinationDataObservableByCreate(url); Observable\u003cDestinationDataModel\u003e merge = Observable.merge(merge1, merge2); merge.subscribeOn(Schedulers.io()).observeOn(AndroidSchedulers.mainThread()).subscribe(subscriber); merge 作为一个可观测序列，发射源 merge1，merge2 中的所有数据。注意发射的数据被交叉合并到一个 Observable 里面。如果同步的合并 Observable，它们将连接在一起并且不会交叉。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:3:12","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"zip $$ join \u0026\u0026 combineLatest 上面的数据，是原样的放在一个可观测序列中进行发射的，然而如果我们想对源数据中两两的进行操作后再放到一个数据列中呢？ Observable\u003cDestinationDataModel\u003e zip1 = getDestinationDataObservableByCreate(url); Observable\u003cDestinationDataModel\u003e zip2 = getDestinationDataObservableByCreate(url); Observable\u003cDestinationDataModel\u003e zip = Observable.zip(zip1, zip2, new Func2\u003cDestinationDataModel, DestinationDataModel, DestinationDataModel\u003e() { @Override public DestinationDataModel call(DestinationDataModel destinationDataModel, DestinationDataModel destinationDataModel2) { //进行数据的合并操作 destinationDataModel.setCode(destinationDataModel.getCode() + destinationDataModel2.getCode()); return destinationDataModel; } }); zip.subscribeOn(Schedulers.io()).observeOn(AndroidSchedulers.mainThread()).subscribe(subscriber); 上面在 Func2 中对两个数据源中的数据进行两两操作，我们只是简单的将 model 的 code 值相加来模拟合并操作，作为新的数据返回，假如两数据源的长度相同，则只会返回一个数据源长度的数据，假如长度不一样，以短的数据长度为准。 zip 作用于最近未打包的两个 Observables,还有一个需求就是我们不一定要非都是未打包的，并不一定要两个数据源要一定的长度相等，这个时候可以用 combineLatest，相反，combineLatest() 作用于最近发射的数据项：如果 Observable1 发射了 A 并且 Observable2 发射了 B 和 C，combineLatest() 将会分组处理 AB 和 AC。 join 操作符把类似于 combineLatest 操作符，也是两个 Observable 产生的结果进行合并，合并的结果组成一个新的 Observable，但是 join 操作符可以控制每个 Observable 产生结果的生命周期，在每个结果的生命周期内，可以与另一个 Observable 产生的结果按照一定的规则进行合并。 ","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:3:13","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"RxAndroid rxbinding Jake 为 Android 控件写的包，这个的使用就太多了。这个我们以一个登陆界面为例。 \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cLinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:id=\"@+id/linearLayoutRoot\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:orientation=\"vertical\"\u003e \u003cTextView android:id=\"@+id/textViewRxAndroid\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:text=\"Result\" /\u003e \u003cEditText android:id=\"@+id/editTextRXAndroid\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:hint=\"输入自己的内容，上面的textview会在400毫秒之后显示出来\" android:textColor=\"@color/blue_light\" /\u003e \u003cEditText android:id=\"@+id/email\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:hint=\"Email\" android:textColor=\"@color/blue_light\" /\u003e \u003cEditText android:id=\"@+id/phone\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:hint=\"Phone\" android:textColor=\"@color/blue_light\" /\u003e \u003cEditText android:id=\"@+id/username\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:hint=\"UserName\" android:textColor=\"@color/blue_light\" /\u003e \u003cButton android:id=\"@+id/LoginButton\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:enabled=\"false\" android:text=\"注册\" /\u003e \u003c/LinearLayout\u003e 我们用第一个 TextView 来演示怎么样定时操作 TextView 的响应。场景常见于搜索，智能提示，我们不能用户输入什么就不停地网络请求。比如用户停止输入的内容有变，500秒之后再进行。 //两个事件源的时间间隔小于规定的时间单位的，都会被忽略。 private void simpleDebounce() { RxTextView.textChangeEvents(editTextRXAndroid) .debounce(400, TimeUnit.MILLISECONDS) .observeOn(AndroidSchedulers.mainThread()) .subscribe(new Observer\u003cTextViewTextChangeEvent\u003e() { @Override public void onCompleted() { } @Override public void onError(Throwable e) { } @Override public void onNext(TextViewTextChangeEvent textViewTextChangeEvent) { //模拟响应 textViewRxAndroid.setText(textViewTextChangeEvent.text()); } }); } 以上的代码中，在400毫秒的时间窗口内，如若临近的事件发生间隔在400毫秒以内的，都将被忽略，当相差的时间间隔达到400毫秒到达的时候，发射最近的一次事件。 在登录的时候，必须验证三要素都齐全才能进行注册的网络请求 //使用combineLatest合并最近N个结点 private void simpleCombineLatest() { Observable\u003cCharSequence\u003e emailChangeObservable = RxTextView.textChanges(email); Observable\u003cCharSequence\u003e phoneChangeObservable = RxTextView.textChanges(phone); Observable\u003cCharSequence\u003e usernameChangeObservable = RxTextView.textChanges(username); Observable.combineLatest(emailChangeObservable, phoneChangeObservable, usernameChangeObservable, new Func3\u003cCharSequence, CharSequence, CharSequence, Boolean\u003e() { @Override public Boolean call(CharSequence charSequence, CharSequence charSequence2, CharSequence charSequence3) { if (!TextUtils.isEmpty(charSequence) \u0026\u0026 !TextUtils.isEmpty(charSequence2) \u0026\u0026 !TextUtils.isEmpty(charSequence3)) { return true; } else { return false; } } }).subscribe(new Action1\u003cBoolean\u003e() { @Override public void call(Boolean aBoolean) { if (aBoolean) { LoginButton.setEnabled(true); } else { LoginButton.setEnabled(false); } } }); } 我们使用 combineLatest 操作符，合并三个 TextView 的事件源，判断三个事件源都满足条件的时候，我们就返回 true，接着进行响应。 有时候，我们获取数据的渠道有很多，最后我们还是需要放到一起进行显示。 //使用merge合并两个数据源。 private void simpleMerge() { Observable.merge(getDataFromFile(), getDataFromNet()) .subscribeOn(Schedulers.io()) .observeOn(AndroidSchedulers.mainThread()) .subscribe(new Action1\u003cString\u003e() { @Override public void call(String s) { textViewRxAndroid.setText(s + textViewRxAndroid.getText()); } }); } 以上我们对来自于本地的和网络请求的数据进行 merge 操作，产生新的数据流。 对于数据获取，我们有时候也有优先级，先去判断内存中是否有数据，有我们取内存中的，依次接下里是本地缓存，再次我们再去请求网络获取数据。 //依次检查memory、disk、network Observable.concat(memory, disk, network) .first() .subscribeOn(Schedulers.newThread()) .subscribe(new Action1\u003cString\u003e() { @Override public void call(String s) { System.out.println(\"选择了：\" + s); } }); 使用 timer 做定时操作。当有“x秒后执行y操作”类似的需求的时候，想到使用 timer private void simpleTimer() { Observable.timer(2, TimeUnit.SECONDS) .subscribe(new Observer\u003cLong\u003e() { @Override public void onCompleted() { System.out.println(\"现在是2秒之后\"); } @Override public void onError(Throwable e) { } @Override","date":"0001-01-01","objectID":"/1/01/rxandroidintroduction2/:4:0","tags":null,"title":"","uri":"/1/01/rxandroidintroduction2/"},{"categories":null,"content":"title: RxJava源码解析(一) date: 2016-03-04 00:23:15 tags: [RxJava,Source] categories: [Mobile,Android] 概述 本文目的是从源码的角度讲解 Rxjava 的重要概念 Observable. RxJava要点解析 对于 Rxjava 还是有很多不理解的地方，加上又有点好奇心，就看看源码，记录在此，水平有限，肯定存在错误的地方，望路过的同行不吝赐教。 ","date":"0001-01-01","objectID":"/1/01/rxjavaessential1/:1:0","tags":null,"title":"","uri":"/1/01/rxjavaessential1/"},{"categories":null,"content":"lift变换操作的原理 看下lift源码,直接拷贝的源码，未做删减。 public final \u003cR\u003e Observable\u003cR\u003e lift(final Operator\u003c? extends R, ? super T\u003e operator) { return new Observable\u003cR\u003e(new OnSubscribe\u003cR\u003e() { @Override public void call(Subscriber\u003c? super R\u003e o) { try { Subscriber\u003c? super T\u003e st = hook.onLift(operator).call(o); try { // new Subscriber created and being subscribed with so 'onStart' it st.onStart(); onSubscribe.call(st); } catch (Throwable e) { // localized capture of errors rather than it skipping all operators // and ending up in the try/catch of the subscribe method which then // prevents onErrorResumeNext and other similar approaches to error handling Exceptions.throwIfFatal(e); st.onError(e); } } catch (Throwable e) { Exceptions.throwIfFatal(e); // if the lift function failed all we can do is pass the error to the final Subscriber // as we don't have the operator available to us o.onError(e); } } }); } 为了弄懂，而且变量不多，我们一个变量一个变量的看。 lift内部返回的是一个新建的observable，此时产生了一个新的OnSubscribe，此时的OnSubscribe的call方法内传入的Subscriber 变量o就是我们写在代码中的订阅者。 hook.onLift(operator).call(o);新建了一个Subscriber变量st，这个变量用的是我们传入的Subscriber变量o。 而且还是用的operator创建的，我们先不管如何实现的，待会儿我们看看这个是怎么实现的。 onSubscribe.call(st);这个onSubscribe是个final类型，因为目前我们还是处于方法内，所以这个onSubscribe还是源observable 的onSubscribe对象(比如我们自己写的发射时机等那段代码),这个时候onSubscribe会调用它的call方法，传入的是我们新建的Subscriber变量st。 接下来，新的Subscriber变量st会接收到源observable发送来的数据。我们可以自然得想到，这个新的st肯定会经过operator对象中的一些定义的方法对数据操作后，又发送到了我们传入的Subscriber变量o，实现整体的连接。 其实说白了，我们其实是在中间创建了一个代理。hook的意思不就是钩子嘛。 接下来来看刚刚未能解决的疑问，hook是怎么工作的。 public \u003cT, R\u003e Operator\u003c? extends R, ? super T\u003e onLift(final Operator\u003c? extends R, ? super T\u003e lift) { return lift; } 我们看到，并未做任何变化，直接将operator变换直接返回了。 接着我们继续看，以filter为例。 public final Observable\u003cT\u003e filter(Func1\u003c? super T, Boolean\u003e predicate) { return lift(new OperatorFilter\u003cT\u003e(predicate)); } 传入的是一个 OperatorFilter 对象。 public final class OperatorFilter\u003cT\u003e implements Operator\u003cT, T\u003e { private final Func1\u003c? super T, Boolean\u003e predicate; public OperatorFilter(Func1\u003c? super T, Boolean\u003e predicate) { this.predicate = predicate; } @Override public Subscriber\u003c? super T\u003e call(final Subscriber\u003c? super T\u003e child) { return new Subscriber\u003cT\u003e(child) { @Override public void onCompleted() { child.onCompleted(); } @Override public void onError(Throwable e) { child.onError(e); } @Override public void onNext(T t) { try { if (predicate.call(t)) { child.onNext(t); } else { // TODO consider a more complicated version that batches these request(1); } } catch (Throwable e) { Exceptions.throwOrReport(e, child, t); } } }; } } 变量predicate就是我们自己定义的过滤规则，在上面的代码中我们已经看到了，call传入的child就是我们上面分析，我们自己定义的变量o。 这下基本清晰了，每次源observable发射的数据都被OperatorFilter内新的subscriber给接收了，然后根据传入到OperatorFilter我们自己定义的过滤规则进行判断，通过的，就给child发射过去，这样实现了过滤的作用，实现了新的subscriber将数据传送到了我们自定义的subscriber。 ","date":"0001-01-01","objectID":"/1/01/rxjavaessential1/:2:0","tags":null,"title":"","uri":"/1/01/rxjavaessential1/"},{"categories":null,"content":"Scheduler 线程切换的原理 注意：以下的版本是rxjava1.1.1(上下两部分的总结时间不一样，也不去考证是哪个版本了) 上面说到了变换的时候，用到的线程的切换的问题，那到底是怎么切换的线程呢？ 说到线程切换，必须说到两个操作。 subscribeOn：指定observable调用obsubsriber发射数据所在的线程。 observeOn： 指定订阅者进行订阅处理所在的线程。 ","date":"0001-01-01","objectID":"/1/01/rxjavaessential1/:3:0","tags":null,"title":"","uri":"/1/01/rxjavaessential1/"},{"categories":null,"content":"subscribeOn分析 public final Observable\u003cT\u003e subscribeOn(Scheduler scheduler) { if (this instanceof ScalarSynchronousObservable) { return ((ScalarSynchronousObservable\u003cT\u003e)this).scalarScheduleOn(scheduler); } return create(new OperatorSubscribeOn\u003cT\u003e(this, scheduler)); } 以上是subscribeOn的源码，传入了指定的发送数据所在的线程Scheduler对象。判断当前的observable是否是一个ScalarSynchronousObservable，这个ScalarSynchronousObservable对象就是直接发射传入数据的对象，就是我们平时使用just所产生的对象。 如果是，则调用将scheduler传入scalarScheduleOn方法，创建一个新的Observable作为返回值。 public Observable\u003cT\u003e scalarScheduleOn(final Scheduler scheduler) { final Func1\u003cAction0, Subscription\u003e onSchedule; if (scheduler instanceof EventLoopsScheduler) { onSchedule = COMPUTATION_ONSCHEDULE; } else { onSchedule = new Func1\u003cAction0, Subscription\u003e() { @Override public Subscription call(final Action0 a) { final Scheduler.Worker w = scheduler.createWorker(); w.schedule(new Action0() { @Override public void call() { try { a.call(); } finally { w.unsubscribe(); } } }); return w; } }; } return create(new ScalarAsyncOnSubscribe\u003cT\u003e(t, onSchedule)); } 以上是scalarScheduleOn的源码，可以看到内部是通过Func1函数进行转换的，通过传入的scheduler创建指定的线程，在指定的线程上调用Func1中传入进来的Action0。 那么Action0代表的又是什么呢？我们看到onSchedule又作为参数去构造ScalarAsyncOnSubscribe了。 /** * The OnSubscribe implementation that creates the ScalarAsyncProducer for each * incoming subscriber. * * @param \u003cT\u003e the value type */ static final class ScalarAsyncOnSubscribe\u003cT\u003e implements OnSubscribe\u003cT\u003e { final T value; final Func1\u003cAction0, Subscription\u003e onSchedule; ScalarAsyncOnSubscribe(T value, Func1\u003cAction0, Subscription\u003e onSchedule) { this.value = value; this.onSchedule = onSchedule; } @Override public void call(Subscriber\u003c? super T\u003e s) { s.setProducer(new ScalarAsyncProducer\u003cT\u003e(s, value, onSchedule)); } } 根据代码注释，知道是为每个传入进来的subscriber创建一个ScalarAsyncProducer。看到这里的call方法，我们可以知道，这个call方法就是被Observable在create中被调用的call方法。在call方法里调用了Subscriber的setProducer方法，给它设置了一个ScalarAsyncProducer对象，这里的Subscriber对象s就是我们自定义的订阅者对象，接下来就看看ScalarAsyncProducer的源码。 /** * Represents a producer which schedules the emission of a scalar value on * the first positive request via the given scheduler callback. * * @param \u003cT\u003e the value type */ static final class ScalarAsyncProducer\u003cT\u003e extends AtomicBoolean implements Producer, Action0 { /** */ private static final long serialVersionUID = -2466317989629281651L; final Subscriber\u003c? super T\u003e actual; final T value; final Func1\u003cAction0, Subscription\u003e onSchedule; public ScalarAsyncProducer(Subscriber\u003c? super T\u003e actual, T value, Func1\u003cAction0, Subscription\u003e onSchedule) { this.actual = actual; this.value = value; this.onSchedule = onSchedule; } @Override public void request(long n) { if (n \u003c 0L) { throw new IllegalArgumentException(\"n \u003e= 0 required but it was \" + n); } if (n != 0 \u0026\u0026 compareAndSet(false, true)) { actual.add(onSchedule.call(this)); } } @Override public void call() { Subscriber\u003c? super T\u003e a = actual; if (a.isUnsubscribed()) { return; } T v = value; try { a.onNext(v); } catch (Throwable e) { Exceptions.throwOrReport(e, a, v); return; } if (a.isUnsubscribed()) { return; } a.onCompleted(); } @Override public String toString() { return \"ScalarAsyncProducer[\" + value + \", \" + get() + \"]\"; } } 注释上说，这个类是用来代表一个生产者，这个生产者通过给定的线程回调，在第一个激活的请求上发射数据。在具体看代码之前，我们可以根据注释大致猜到这个是充当了发射数据的生产者，并且要是能实现线程切换，应该是在作为构造参数传递进来的onSchedule上进行调用和回调的。看下里面的源码，在request方法中，这里的actual就是刚刚传入的自定义订阅者对象s,我们看到call方法中就是直接调用了actual的onNext方法，将数据传递到订阅者。 再看重点，request方法，有个参数n代表一次性请求的数据的数量，actual.add(onSchedule.call(this))；这个命令我们看到有调用onSchedule的call方法，那么经过这么长时间下来，这个call方法又是啥玩意？这个onSchedule就是我们在scalarScheduleOn中定义的Func1，这个也就是说在这里调用了Func1的call方法，传递进去的按理说是Action0对象，我们注意到ScalarAsyncProducer已经实现了Action0接口。也就是说这里调用了ScalarAsyncProducer(生产者)的call方法。当前ScalarAsyncProducer的call方法就是直接调用自定义订阅者的onNext发射数据。我们在上面说了Func1的call方法会在一个新建的线程中调用call方法传递进来的action0对象(就是此处实现Action0接口的ScalarAsyncProducer)的call方法。到目前为止，关于ScalarSynchronousObservable对象的线程切换的原理就分析结束了。 接下来看下，如果不是ScalarSynchronousObservable对象调用subscribeOn方法又会是什么逻辑呢？ 再贴下subscribeOn的源码。 public final Observable\u003cT\u003e subscribeOn(Scheduler","date":"0001-01-01","objectID":"/1/01/rxjavaessential1/:3:1","tags":null,"title":"","uri":"/1/01/rxjavaessential1/"},{"categories":null,"content":"observeOn分析 接下来分析observeOn,了解在异步线程上分发事件就可以知道线程切换的大致原理了。 public final Observable\u003cT\u003e observeOn(Scheduler scheduler) { if (this instanceof ScalarSynchronousObservable) { return ((ScalarSynchronousObservable\u003cT\u003e)this).scalarScheduleOn(scheduler); } return lift(new OperatorObserveOn\u003cT\u003e(scheduler, false)); } 可以看到假如是 ScalarSynchronousObservable 实例的话，操作和 subscribeOn 是一样的。直接看看第二种不是 ScalarSynchronousObservable 的情况。 我们看到使用的是 lift 操作符，Operator 的构造方式和上面的 filter 有点不一样，传入了 scheduler 和一个 false 。看下这个 OperatorObserveOn 的代码。按照刚刚 lift 操作的原理，操作符中的 call 方法是关键，是会被代理调用的。这边的代码太长，贴关键部分的代码，上面的都是全的。 @Override public Subscriber\u003c? super T\u003e call(Subscriber\u003c? super T\u003e child) { if (scheduler instanceof ImmediateScheduler) { // avoid overhead, execute directly return child; } else if (scheduler instanceof TrampolineScheduler) { // avoid overhead, execute directly return child; } else { ObserveOnSubscriber\u003cT\u003e parent = new ObserveOnSubscriber\u003cT\u003e(scheduler, child, delayError); parent.init(); return parent; } } 根据上面的经验，这里的返回的 Subscriber 的将会在 lift 新创建的 observable 中的 OnSubscribe 对象的 call 方法中被原始自定义的 OnSubscribe 当做参数传递给它自身的 call 方法中，这里有点乱，但是是和上面的 lift 是一样的，可以回到上面看看 lift 的分析。所以数据会先通过这里创建的 ObserveOnSubscriber ，也就是这里返回的 child 或者 parent。child 的应该比较简单，是直接返回自定义的 Subscriber，这样在 lift 中的情况也一样，其实是直接发给了原始的 observable，相当于没做任何的线程变换。 那么重点就是在 ObserveOnSubscriber 上了，这个应该是在做线程的切换了。 void init() { // don't want this code in the constructor because `this` can escape through the // setProducer call Subscriber\u003c? super T\u003e localChild = child; localChild.setProducer(new Producer() { @Override public void request(long n) { if (n \u003e 0L) { BackpressureUtils.getAndAddRequest(requested, n); schedule(); } } }); localChild.add(recursiveScheduler); localChild.add(this); } @Override public void onNext(final T t) { if (isUnsubscribed() || finished) { return; } if (!queue.offer(on.next(t))) { onError(new MissingBackpressureException()); return; } schedule(); } 上面看到，在创建 parent的时候，会调用 init 方法，在 init 方法中为 child (自定义的 subscriber )设置了 Producer，在 request 里调用了 schedule 方法， schedule 方法就是执行在指定的异步线程上的。我们看到在 onNext 方法中，又调用了 schedule 方法，这样就实现了循环分发的效果，直到把所有的数据分发完。 protected void schedule() { if (counter.getAndIncrement() == 0) { recursiveScheduler.schedule(this); } } schedule方法里是将当前的对象加入到任务安排中，我们知道schedule方法的参数是一个Action0对象，所以需要看下当前对象实现Action0接口中的call方法。 @Override public void call() { long emitted = 0L; long missed = 1L; // these are accessed in a tight loop around atomics so // loading them into local variables avoids the mandatory re-reading // of the constant fields final Queue\u003cObject\u003e q = this.queue; final Subscriber\u003c? super T\u003e localChild = this.child; final NotificationLite\u003cT\u003e localOn = this.on; // requested and counter are not included to avoid JIT issues with register spilling // and their access is is amortized because they are part of the outer loop which runs // less frequently (usually after each RxRingBuffer.SIZE elements) for (;;) { if (checkTerminated(finished, q.isEmpty(), localChild, q)) { return; } long requestAmount = requested.get(); boolean unbounded = requestAmount == Long.MAX_VALUE; long currentEmission = 0L; while (requestAmount != 0L) { boolean done = finished; Object v = q.poll(); boolean empty = v == null; if (checkTerminated(done, empty, localChild, q)) { return; } if (empty) { break; } localChild.onNext(localOn.getValue(v)); requestAmount--; currentEmission--; emitted++; } if (currentEmission != 0L \u0026\u0026 !unbounded) { requested.addAndGet(currentEmission); } missed = counter.addAndGet(-missed); if (missed == 0L) { break; } } if (emitted != 0L) { request(emitted); } } 可以看到上面其实和 Android 本身的 looper 一样，也是一个循环发射的一个过程，checkTerminated 根据当前发射的完成状况和 subscriber 的订阅状态判断是否需要停止。不去过多的理解这个，看重点for循环。 在 for 循环里还有一个 while 循环，在 while 中给 Subscriber 对象发射数据。这样就是在 recursiveScheduler 中新的线程中发射的数据。这样就实现了 observeOn 中的线程切换。 observeOn总结 observeOn 的线程切换也是通过给自定义的 Subscriber 设置新的 Producer，在新的 Producer中 指定分发(subscriber.onNext())调用的线程,这样就实现了 observeOn 线程的切换。 ","date":"0001-01-01","objectID":"/1/01/rxjavaessential1/:3:2","tags":null,"title":"","uri":"/1/01/rxjavaessential1/"},{"categories":null,"content":"subscribe分析 再看看订阅的执行流程。 public final Subscription subscribe(Subscriber\u003c? super T\u003e subscriber) { return Observable.subscribe(subscriber, this); } private static \u003cT\u003e Subscription subscribe(Subscriber\u003c? super T\u003e subscriber, Observable\u003cT\u003e observable) { // validate and proceed if (subscriber == null) { throw new IllegalArgumentException(\"observer can not be null\"); } if (observable.onSubscribe == null) { throw new IllegalStateException(\"onSubscribe function can not be null.\"); } // new Subscriber so onStart it subscriber.onStart(); // if not already wrapped if (!(subscriber instanceof SafeSubscriber)) { // assign to `observer` so we return the protected version subscriber = new SafeSubscriber\u003cT\u003e(subscriber); } // The code below is exactly the same an unsafeSubscribe but not used because it would // add a significant depth to already huge call stacks. try { // allow the hook to intercept and/or decorate hook.onSubscribeStart(observable, observable.onSubscribe).call(subscriber); return hook.onSubscribeReturn(subscriber); } catch (Throwable e) { // special handling for certain Throwable/Error/Exception types Exceptions.throwIfFatal(e); // if an unhandled error occurs executing the onSubscribe we will propagate it try { subscriber.onError(hook.onSubscribeError(e)); } catch (Throwable e2) { Exceptions.throwIfFatal(e2); // if this happens it means the onError itself failed (perhaps an invalid function implementation) // so we are unable to propagate the error correctly and will just throw RuntimeException r = new RuntimeException(\"Error occurred attempting to subscribe [\" + e.getMessage() + \"] and then again while trying to pass to onError.\", e2); // TODO could the hook be the cause of the error in the on error handling. hook.onSubscribeError(r); // TODO why aren't we throwing the hook's return value. throw r; } return Subscriptions.unsubscribed(); } } 我们看到hook.onSubscribeStart(observable, observable.onSubscribe).call(subscriber);这就是所谓的只要在订阅的时候才会发射数据的原因。 subscriber 作为参数传递到调用 subscribe 方法的 observable 中 onSubscribe 的 call 方法了。也就是说最终的subscriber是被传递给了最后一个调用它的 observable 了，因为我们知道在整个操作链中，每个操作符都会返回一个新的 observable ，并且内部都是创建了一个新的 subscriber ，利用代理的方式调用我们自定义的 subscriber。 ","date":"0001-01-01","objectID":"/1/01/rxjavaessential1/:3:3","tags":null,"title":"","uri":"/1/01/rxjavaessential1/"},{"categories":null,"content":"实例讲解流程 private void simpleFilter() { Observable.create(new Observable.OnSubscribe\u003cInteger\u003e() { @Override public void call(Subscriber\u003c? super Integer\u003e subscriber) { System.out.println(\"Observable:\" + Thread.currentThread()); for (int i = 0; i \u003c 10; i++) { subscriber.onNext(i); } subscriber.onCompleted(); } }) // 决定了最终在哪个线程调用OnSubscribe的call方法，这会让源observable订阅subscribeOn内新创建的subscriber, // 内部新的subscriber会在指定的IO线程上执行。 .subscribeOn(Schedulers.io()) // filter会返回一个 observable，这个observable会订阅后面的subscriber，接收到之后交给Operator，Operator调用Func1操作完之后再交给调用这个filter // 的observable中的OnSubscribe调用，运行在调用这个filter的observable的call方法运行的线程上。 .filter(new Func1\u003cInteger, Boolean\u003e() { @Override public Boolean call(Integer integer) { System.out.println(\"filter:\" + Thread.currentThread()); if (integer \u003e 2) { return true; } else { return false; } } }) // 指定subscriber中的call方法运行的线程，内部也是通过lift操作实现的，也新建了一个subscriber， // 这个新的subscriber为后面订阅的subscriber设置了新producer， // 新的producer指定了后面订阅的subscriber的分发数据的线程，也就是订阅的subscriber调用onNext的线程。 .observeOn(AndroidSchedulers.mainThread()) //订阅，直接运行，分发数据 .subscribe(new Action1\u003cInteger\u003e() { @Override public void call(Integer integer) { System.out.println(\"Action1:\" + Thread.currentThread()); textViewMain.setText(integer.toString()); } }); } 具体的解释就在上面的注释部分了，暂时rxjava部分的解析先暂停，以上的内容，还有许多待斟酌的，遇到错误，看到的希望指教。 ","date":"0001-01-01","objectID":"/1/01/rxjavaessential1/:3:4","tags":null,"title":"","uri":"/1/01/rxjavaessential1/"},{"categories":null,"content":"title: 一个例子说明如何使用 RxJava 进行线程切换 date: 2016-06-14 16:07:10 tags: [RxJava,Source,Thread] categories: [Mobile,Android] 概述 本文仅作记录如何在上层使用代码进行 RxJava 的线程切换. RxJava 线程管理 RxJava 中通过两个关键的方法 subscribeOn 和 observeOn 实现线程的切换，都说 RxJava 是可以任性的随意切换线程，到底可以多任性呢，在哪任性呢，代码上怎么体现呢？下面通过一个非常简单的例子 演示一下如何使用，源码讨论请移步另一篇文章。 ##　测试代码 //验证多线程切换的情况 private void multiThreadSwitch() { Observable.create(new Observable.OnSubscribe\u003cString\u003e() { @Override public void call(Subscriber\u003c? super String\u003e subscriber) { //受subscribeOn的影响，另起一个线程 Log.e(TAG, \"create \" + Thread.currentThread().toString()); subscriber.onNext(\"hello world\"); } }) .subscribeOn(Schedulers.newThread()) .doOnSubscribe(new Action0() { @Override public void call() { //和上一个doOnSubscribe运行在同一个线程中,因为中间并未切换线程 Log.e(TAG, \"doOnSubscribe4 \" + Thread.currentThread().toString()); } }) .doOnSubscribe(new Action0() { @Override public void call() { //受subscribeOn的影响，另起一个线程 Log.e(TAG, \"doOnSubscribe3 \" + Thread.currentThread().toString()); } }) .subscribeOn(Schedulers.newThread()) .map(new Func1\u003cString, String\u003e() { @Override public String call(String s) { //和create在同一个线程执行 Log.e(TAG, \"map1 \" + Thread.currentThread().toString()); return s; } }) .observeOn(Schedulers.newThread()) .doOnSubscribe(new Action0() { @Override public void call() { //受subscribeOn的影响，另起一个线程 Log.e(TAG, \"doOnSubscribe2 \" + Thread.currentThread().toString()); } }) .map(new Func1\u003cString, String\u003e() { @Override public String call(String s) { //受observeOn的影响，另起一个线程 Log.e(TAG, \"map2 \" + Thread.currentThread().toString()); return s; } }) .subscribeOn(Schedulers.newThread()) .doOnSubscribe(new Action0() { @Override public void call() { //作为消息发送发送的第一站，没有通过subscribeOn指定发送消息的线程，故而这个会在调用subscribe方法的线程上执行,这里是主线程 Log.e(TAG, \"doOnSubscribe1 \" + Thread.currentThread().toString()); } }) .observeOn(Schedulers.newThread()) .subscribe(new Action1\u003cString\u003e() { @Override public void call(String s) { // 受observeOn的影响，另起一个线程 // 假如没有observeOn，则运行在离这 最近 的observeOn，或者 最远(物理位置最远，按照消息自下往上的顺序，其实也是最近) 的subscribeOn线程上 Log.e(TAG, \"subscribe \" + Thread.currentThread().toString()); } }); } ","date":"0001-01-01","objectID":"/1/01/rxjavathreaddemo/:1:0","tags":null,"title":"","uri":"/1/01/rxjavathreaddemo/"},{"categories":null,"content":"日志输出 对于直接运行测试代码，产生的log日志是如下的。 06-14 16:36:09.315 5471-5471/ cn.steve.study E/RXJavaActivity: doOnSubscribe1 Thread[main,5,main] 06-14 16:36:09.319 5471-12993/cn.steve.study E/RXJavaActivity: doOnSubscribe2 Thread[RxNewThreadScheduler-7,5,main] 06-14 16:36:09.323 5471-12995/cn.steve.study E/RXJavaActivity: doOnSubscribe3 Thread[RxNewThreadScheduler-9,5,main] 06-14 16:36:09.323 5471-12995/cn.steve.study E/RXJavaActivity: doOnSubscribe4 Thread[RxNewThreadScheduler-9,5,main] 06-14 16:36:09.327 5471-12996/cn.steve.study E/RXJavaActivity: create Thread[RxNewThreadScheduler-10,5,main] 06-14 16:36:09.327 5471-12996/cn.steve.study E/RXJavaActivity: map1 Thread[RxNewThreadScheduler-10,5,main] 06-14 16:36:09.329 5471-12994/cn.steve.study E/RXJavaActivity: map2 Thread[RxNewThreadScheduler-8,5,main] 06-14 16:36:09.331 5471-12992/cn.steve.study E/RXJavaActivity: subscribe Thread[RxNewThreadScheduler-6,5,main] 对于去掉两个observeOn，产生的log日志是如下的。 06-14 16:43:42.001 18160-18160/cn.steve.study E/RXJavaActivity: doOnSubscribe1 Thread[main,5,main] 06-14 16:43:42.002 18160-19180/cn.steve.study E/RXJavaActivity: doOnSubscribe2 Thread[RxNewThreadScheduler-4,5,main] 06-14 16:43:42.006 18160-19181/cn.steve.study E/RXJavaActivity: doOnSubscribe3 Thread[RxNewThreadScheduler-5,5,main] 06-14 16:43:42.006 18160-19181/cn.steve.study E/RXJavaActivity: doOnSubscribe4 Thread[RxNewThreadScheduler-5,5,main] 06-14 16:43:42.023 18160-19182/cn.steve.study E/RXJavaActivity: create Thread[RxNewThreadScheduler-6,5,main] 06-14 16:43:42.024 18160-19182/cn.steve.study E/RXJavaActivity: map1 Thread[RxNewThreadScheduler-6,5,main] 06-14 16:43:42.024 18160-19182/cn.steve.study E/RXJavaActivity: map2 Thread[RxNewThreadScheduler-6,5,main] 06-14 16:43:42.024 18160-19182/cn.steve.study E/RXJavaActivity: subscribe Thread[RxNewThreadScheduler-6,5,main] ","date":"0001-01-01","objectID":"/1/01/rxjavathreaddemo/:2:0","tags":null,"title":"","uri":"/1/01/rxjavathreaddemo/"},{"categories":null,"content":"结论 ","date":"0001-01-01","objectID":"/1/01/rxjavathreaddemo/:3:0","tags":null,"title":"","uri":"/1/01/rxjavathreaddemo/"},{"categories":null,"content":"说明 这里约定一下描述的规则，我们接下来讲的远近，上下指的是代码物理位置上。 响应式编程有个消息的概念，这里消息的产生是从下往上的，当调用了subscribe 的时候，就会产生，接着往上，我们可以通过代码和log可以看出，依次执行了 doOnSubscribe1 - doOnSubscribe4，最后到达create处。 对于数据流，则是从上往下的，经过每个继承 lift 产生的操作符，例如map, reduce,filter等。 ","date":"0001-01-01","objectID":"/1/01/rxjavathreaddemo/:3:1","tags":null,"title":"","uri":"/1/01/rxjavathreaddemo/"},{"categories":null,"content":"所以 要想指定create所在的线程，需要在create的下方调用 subscribeOn 方法，他受他下方遇到的第一个 subscribeOn 的影响，反正也可以说subscribeOn影响的是在他上方的消息传递的线程，直到遇到下一个subscribeOn为止。假如全程没有一处调用subscribeOn，则消息的传递是在调用subscribe所在的线程。 要想指定 map 等lift操作符和Subscriber中的执行线程，则需要在它上方调用observeOn方法；反之observeOn影响的是他下方的lift操作符直到遇到下一个observeOn位置。假如整个代码中未指明observeOn方法，则运行在整个代码中第一个subscribeOn指定的线程，也可以理解成运行在create所在的线程。 至于二者均未指定，则可以推导出运行在调用subscribe所在的线程。 ","date":"0001-01-01","objectID":"/1/01/rxjavathreaddemo/:3:2","tags":null,"title":"","uri":"/1/01/rxjavathreaddemo/"},{"categories":null,"content":"结尾 至于源码解释参见另外一篇。 ","date":"0001-01-01","objectID":"/1/01/rxjavathreaddemo/:4:0","tags":null,"title":"","uri":"/1/01/rxjavathreaddemo/"},{"categories":null,"content":"title: Service之IntentService date: 2016-07-02 21:35:56 tags: [Service,IntentService] categories: [Mobile,Android] 概述 本文记录 IntentService 的使用方式,以及可能产生的问题. IntentService 关于IntentService本身的使用很简单，官方的解释也说的很清楚。IntentService是Service类的子类，用来处理异步请求。和正常启动一个Service一样，可以通过startService(Intent)方法启动一个IntentService，同时通过Intent传递数据。IntentService在onCreate()函数中通过HandlerThread开启一个线程来处理Intent请求对象，这样就可以在非主线程执行任务。这里处理消息的时候，也是通过为新创建的线程新建了Handler和Looper对象从消息队列中取出消息进行执行。处理每个Intent所对应的事务都需要调用 onHandleIntent 这个抽象方法。所以，将对不同任务的不同操作通过实现 onHandleIntent 方法就可完成。 执行完这个任务(Intent)就会自动停止 Service 。这里有一点需要注意，如果这个任务的执行本身就是异步的，所以，假如添加的任务也是异步的，很难保证能正常执行结束。 private final class ServiceHandler extends Handler { public ServiceHandler(Looper looper) { super(looper); } @Override public void handleMessage(Message msg) { onHandleIntent((Intent)msg.obj); stopSelf(msg.arg1); } } 从代码可以看出，每执行一次onHandleIntent 都会调用执行 stopSelf 来停止当前的service。也就是假如子类实现的 onHandleIntent 中执行的是异步任务，异步任务可能得不到预期的结果。 举个例子: public static void startActionBaz(Context context, String param1, String param2) { Intent intent = new Intent(context, MyIntentService.class); intent.setAction(ACTION_BAZ); intent.putExtra(EXTRA_PARAM1, param1); intent.putExtra(EXTRA_PARAM2, param2); context.startService(intent); } @Override public void onDestroy() { super.onDestroy(); Log.d(TAG, \"onDestroy() dead\"); } @Override protected void onHandleIntent(Intent intent) { if (intent != null) { final String action = intent.getAction(); if (ACTION_BAZ.equals(action)) { final String param1 = intent.getStringExtra(EXTRA_PARAM1); final String param2 = intent.getStringExtra(EXTRA_PARAM2); handleActionBaz(param1, param2); } } } private void handleActionBaz(String param1, String param2) { Log.d(TAG, \"handleActionBaz() called with: \" + \"param1 = [\" + param1 + \"], param2 = [\" + param2 + \"]\"); new Thread(new Runnable() { @Override public void run() { try { //这里的代码是无法执行的。 Thread.sleep(3000); Log.d(TAG, \"handleActionBaz() called at Thread\"); } catch (InterruptedException e) { e.printStackTrace(); } } }); } 以上代码中的 Runnable 中的代码是不会执行的。 看下启动两次 IntentService 的log输出。 07-02 10:04:03.799 4785-4785/cn.steve.study D/MyIntentService: MyIntentService() called with: cn.steve.service.MyIntentService@f26cde3 07-02 10:04:03.811 4785-5288/cn.steve.study D/MyIntentService: handleActionBaz() called with: param1 = [], param2 = [] 07-02 10:04:03.840 4785-4785/cn.steve.study D/MyIntentService: onDestroy() dead 07-02 10:04:04.079 4785-4785/cn.steve.study D/MyIntentService: MyIntentService() called with: cn.steve.service.MyIntentService@47d6d5e 07-02 10:04:04.089 4785-5293/cn.steve.study D/MyIntentService: handleActionBaz() called with: param1 = [], param2 = [] 07-02 10:04:04.114 4785-4785/cn.steve.study D/MyIntentService: onDestroy() dead 发现每次都是新建 IntentService 对象，执行完后就会销往。 总结 系统为我们提供这个 IntentService 能在完成任务后自动停止销往，不需要我们手动停止，但是这个特性只能对一些简单的同步任务而已，对于异步任务，还是需要我们手动去 stop 。 ","date":"0001-01-01","objectID":"/1/01/service%E4%B9%8Bintentservice/:1:0","tags":null,"title":"","uri":"/1/01/service%E4%B9%8Bintentservice/"},{"categories":null,"content":"title: Ubuntu下SublimeText3中文输入法修复 date: 2016-10-07 14:09:09 tags: [Ubuntu,SublimeText3,输入法] categories: [ComputerFoundation,OS] 概述 本文记录在 ubuntu 如何修复 Sublime Text 不能输入中文的问题. 问题 在 ubuntu 下安装完 Sublime Text之后,发现不能输入中文,也不能正常的切换成中文输入法.google 了一圈之后,看到网上的解决方案,记录下来,方便日后使用. 解决方案 ","date":"0001-01-01","objectID":"/1/01/ubuntu%E4%B8%8Bsublimetext3%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95%E4%BF%AE%E5%A4%8D/:1:0","tags":null,"title":"","uri":"/1/01/ubuntu%E4%B8%8Bsublimetext3%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95%E4%BF%AE%E5%A4%8D/"},{"categories":null,"content":"1. 编译一段C代码.保存以下的代码,并将文件命名为 sublime-imfix.c /* sublime-imfix.c Use LD_PRELOAD to interpose some function to fix sublime input method support for linux. By Cjacker Huang gcc -shared -o libsublime-imfix.so sublime-imfix.c `pkg-config --libs --cflags gtk+-2.0` -fPIC LD_PRELOAD=./libsublime-imfix.so subl */ #include #include typedef GdkSegment GdkRegionBox; struct _GdkRegion { long size; long numRects; GdkRegionBox *rects; GdkRegionBox extents; }; GtkIMContext *local_context; void gdk_region_get_clipbox (const GdkRegion *region, GdkRectangle *rectangle) { g_return_if_fail (region != NULL); g_return_if_fail (rectangle != NULL); rectangle-\u003ex = region-\u003eextents.x1; rectangle-\u003ey = region-\u003eextents.y1; rectangle-\u003ewidth = region-\u003eextents.x2 - region-\u003eextents.x1; rectangle-\u003eheight = region-\u003eextents.y2 - region-\u003eextents.y1; GdkRectangle rect; rect.x = rectangle-\u003ex; rect.y = rectangle-\u003ey; rect.width = 0; rect.height = rectangle-\u003eheight; //The caret width is 2; //Maybe sometimes we will make a mistake, but for most of the time, it should be the caret. if(rectangle-\u003ewidth == 2 \u0026\u0026 GTK_IS_IM_CONTEXT(local_context)) { gtk_im_context_set_cursor_location(local_context, rectangle); } } //this is needed, for example, if you input something in file dialog and return back the edit area //context will lost, so here we set it again. static GdkFilterReturn event_filter (GdkXEvent *xevent, GdkEvent *event, gpointer im_context) { XEvent *xev = (XEvent *)xevent; if(xev-\u003etype == KeyRelease \u0026\u0026 GTK_IS_IM_CONTEXT(im_context)) { GdkWindow * win = g_object_get_data(G_OBJECT(im_context),\"window\"); if(GDK_IS_WINDOW(win)) gtk_im_context_set_client_window(im_context, win); } return GDK_FILTER_CONTINUE; } void gtk_im_context_set_client_window (GtkIMContext *context, GdkWindow *window) { GtkIMContextClass *klass; g_return_if_fail (GTK_IS_IM_CONTEXT (context)); klass = GTK_IM_CONTEXT_GET_CLASS (context); if (klass-\u003eset_client_window) klass-\u003eset_client_window (context, window); if(!GDK_IS_WINDOW (window)) return; g_object_set_data(G_OBJECT(context),\"window\",window); int width = gdk_window_get_width(window); int height = gdk_window_get_height(window); if(width != 0 \u0026\u0026 height !=0) { gtk_im_context_focus_in(context); local_context = context; } gdk_window_add_filter (window, event_filter, context); } ","date":"0001-01-01","objectID":"/1/01/ubuntu%E4%B8%8Bsublimetext3%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95%E4%BF%AE%E5%A4%8D/:2:0","tags":null,"title":"","uri":"/1/01/ubuntu%E4%B8%8Bsublimetext3%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95%E4%BF%AE%E5%A4%8D/"},{"categories":null,"content":"2. 因为要编译C代码,所以需要安装C的编译环境 打开命令行,安装编译环境 sudo apt-get install build-essential sudo apt-get install libgtk2.0-dev ","date":"0001-01-01","objectID":"/1/01/ubuntu%E4%B8%8Bsublimetext3%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95%E4%BF%AE%E5%A4%8D/:3:0","tags":null,"title":"","uri":"/1/01/ubuntu%E4%B8%8Bsublimetext3%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95%E4%BF%AE%E5%A4%8D/"},{"categories":null,"content":"3. 编译如上说的C代码,会在当前目录下生成libsublime-imfix.so文件,并将libsublime-imfix.so复制到/opt/sublime_text/目录下. gcc -shared -o libsublime-imfix.so sublime-imfix.c `pkg-config --libs --cflags gtk+-2.0` -fPIC ","date":"0001-01-01","objectID":"/1/01/ubuntu%E4%B8%8Bsublimetext3%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95%E4%BF%AE%E5%A4%8D/:4:0","tags":null,"title":"","uri":"/1/01/ubuntu%E4%B8%8Bsublimetext3%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95%E4%BF%AE%E5%A4%8D/"},{"categories":null,"content":"4. 修改/usr/share/applications/sublime_text.desktop vim sublime_text.desktop 然后修改对应的内容 [Desktop Entry] [...] Exec=env LD_PRELOAD=/opt/sublime_text/libsublime-imfix.so /opt/sublime_text/sublime_text %F [...] [Desktop Action Window] [...] Exec=env LD_PRELOAD=/opt/sublime_text/libsublime-imfix.so /opt/sublime_text/sublime_text -n [...] [Desktop Action Document] [...] Exec=env LD_PRELOAD=/opt/sublime_text/libsublime-imfix.so /opt/sublime_text/sublime_text --command new_file [...] 参考 完美解决 Linux 下 Sublime Text 中文输入 ","date":"0001-01-01","objectID":"/1/01/ubuntu%E4%B8%8Bsublimetext3%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95%E4%BF%AE%E5%A4%8D/:5:0","tags":null,"title":"","uri":"/1/01/ubuntu%E4%B8%8Bsublimetext3%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95%E4%BF%AE%E5%A4%8D/"}]